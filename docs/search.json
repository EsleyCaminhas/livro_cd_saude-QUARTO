[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ciência de Dados Aplicada à Saúde Materno-Infantil",
    "section": "",
    "text": "Prefácio"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introdução",
    "section": "",
    "text": "Os dados considerados nas aplicações deste livro são provenientes do Sistema de Informação da Vigilância Epidemiológica da Gripe (SIVEP-Gripe), sistema oficial para o registro de casos e óbitos por Síndrome Respiratória Aguda Grave (SRAG) disponibilizado pelo Ministério da Saúde, e correspondem a registros de gestantes e puérperas de 10 a 55 anos hospitalizadas com SRAG por COVID-19 confirmada por teste de PCR. Dois conjuntos de dados diferentes são utilizados para ilustrar e demonstrar diversos aspectos dos conceitos abordados no texto.\n\n\nEssa base consiste em 11.485 de registros de gestantes e puérperas diagnosticadas com COVID-19 no período de março de 2020 a dezembro de 2021. Alguns estudos conduzidos pelo OOBr usaram esses dados, dentre os quais podem ser citados: Características demográficas e epidemiológicas sobre mulheres grávidas e puérperas que morreram de Síndrome Respiratória Aguda Grave no Brasil, Mortalidade materna associada à COVID-19 no Brasil em 2020 e 2021: comparação com mulheres não grávidas e homens e Desfechos da COVID-19 em puérperas, gestantes e mulheres não gestantes e nem puérperas hospitalizadas.\nO dicionários das variáveis a ser considerado neste livro está na Table 1.1.\n\n\nTable 1.1: Dicionário das variáveis da base de dados de COVID-19 em gestantes e puérperas.\n\n\n\n\n\n\n\nVariável\nDescrição\nValores\n\n\n\n\nsem_pri\nSemana epidemiológia dos primeiros sintomas\n1 a 52\n\n\nidade_anos\nIdade, em anos, da gestante ou puérpera\n10 a 55\n\n\nsg_uf\nSigla da Unidade Federativa de residência da gestante ou puérpera\nCódigo definido pelo IBGE\n\n\nid_mn_resi\nNome do município de residência da gestante ou puérpera\nNomes padronizados pelo IBGE\n\n\nco_mun_res\nCódigo do município de residência da gestante ou puérpera\nCódigo definido pelo IBGE\n\n\nco_mu_inte\nCódigo do município onde está localizado a Unidade de Saúde onde a gestante ou puérpera internou\nCódigo definido pelo IBGE\n\n\ndt_sin_pri\nData de primeiros sintomas do caso\nDia/Mês/Ano\n\n\ndt_evoluca_2\nData da alta ou do óbito da gestante ou puérpera\nAno/Mês/Dia\n\n\nano\nAno da infecção pelo COVID-19\n2020; 2021\n\n\nclassi_gesta_puerp\nIdade gestacional da gestante e puerpério\n1tri- 1° trimestre; 2tri- 2° trimestre; 3tri- 3° trimestre; puerp- puérpera\n\n\nraca\nRaça da gestante ou puérpera\namarela; branca; indígena; parda; preta\n\n\nescol\nNível de escolaridade da gestante ou puérpera\nsem escol- sem escolaridade (analfabeto); fund1- fundamental 1° ciclo (1ª a 5ª série); fund2- fundamental 2 (6ª a 9ª série); medio (1° ao 3° ano); superior\n\n\nmudou_muni\nSe gestante ou puérpera precisou se deslocar para outro município para realizar atendimento\nsim; não\n\n\nzona\nTipo de zona de residência da gestante ou puérpera\nrural; urbana; periurbana\n\n\nfaixa_et\nFaixa etária da gestante ou puérpera\n<20; 20-34; >=35\n\n\nhospital\nSe gestante ou puérpera foi hospitalizada\nsim; não\n\n\nhist_viagem\nSe gestante ou puérpera fez viagem internacional até 14 dias antes do início dos sintomas\nsim; não\n\n\nsg_para_srag\nSe o caso é proveniente de síndrome gripal (SG) que evoluiu para síndrome respiratória aguda grave (SRAG)\nsim; não\n\n\ninf_inter\nSe trata-se de caso nosocomial (infecção adquirida no hospital)\nsim; não\n\n\ncont_ave_suino\nSe a gestante ou puérpera trabalha ou tem contato direto com aves, suínos ou outros animais\nsim; não\n\n\nvacina\nSe a gestante ou puérpera recebeu vacina contra influenza\nsim; não\n\n\nvacina_cov\nSe a gestante ou puérpera recebeu vacina contra COVID-19\nsim; não\n\n\nantiviral\nQual antiviral que gestante ou puérpera usou para gripe\nOseltamivir; Zanamivir\n\n\nfebre\nSe gestante ou puérpera manifestou sintoma de febre\nsim; não\n\n\ntosse\nSe gestante ou puérpera manifestou sintoma de tosse\nsim; não\n\n\ngarganta\nSe gestante ou puérpera manifestou sintoma de dor de garganta\nsim; não\n\n\ndispneia\nSe gestante ou puérpera manifestou sintoma de dispneia\nsim; não\n\n\ndesc_resp\nSe gestante ou puérpera manifestou sintoma de desconforto respiratório\nsim; não\n\n\nsaturacao\nSe gestante ou puérpera manifestou sintoma de saturação\nsim; não\n\n\ndiarreia\nSe gestante ou puérpera manifestou sintoma de diarreia\nsim; não\n\n\nvomito\nSe gestante ou puérpera manifestou sintoma de vômito\nsim; não\n\n\ndor_abd\nSe gestante ou puérpera manifestou sintoma de dor abdominal\nsim; não\n\n\nfadiga\nSe gestante ou puérpera manifestou sintoma de fadiga\nsim; não\n\n\nperd_olft\nSe gestante ou puérpera manifestou sintoma de perda de olfato\nsim; não\n\n\nperd_pala\nSe gestante ou puérpera manifestou sintoma de perda de paladar\nsim; não\n\n\ncardiopati\nSe gestante ou puérpera tem doença cardiovascular crônica\nsim; não\n\n\nhematologi\nSe gestante ou puérpera tem doença hematológica crônica\nsim; não\n\n\nhepatica\nSe gestante ou puérpera tem doença hepática crônica\nsim; não\n\n\nasma\nSe gestante ou puérpera tem asma\nsim; não\n\n\ndiabetes\nSe gestante ou puérpera tem diabetes mellitus\nsim; não\n\n\nneuro\nSe gestante ou puérpera tem doença neurológica\nsim; não\n\n\npneumopati\nSe gestante ou puérpera tem outra pneumopatia crônica\nsim; não\n\n\nimunodepre\nSe gestante ou puérpera tem imunodeficiência ou imunodepressão (diminuição da função do sistema imunológico)\nsim; não\n\n\nrenal\nSe gestante ou puérpera tem doença renal crônica\nsim; não\n\n\nobesidade\nSe gestante ou puérpera tem obesidade\nsim; não\n\n\nuti\nSe gestante ou puérpera foi internada na UTI\nsim; não\n\n\nsuport_ven\nSe gestante ou puérpera precisou de ventilação mecânica; se sim, se foi invasiva ou não\nnão; sim, não invasivo; sim, invasivo\n\n\nevolucao\nEvolução do caso da gestante ou puérpera\ncura; óbito\n\n\nvariante\nVariante do vírus SARS-CoV-2 (vírus do COVID-19)\noriginal; delta; gama; omicron"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "intro.html#base-de-dados",
    "href": "intro.html#base-de-dados",
    "title": "1  Introdução",
    "section": "1.1 Base de dados",
    "text": "1.1 Base de dados\nOs dados que consideramos nas aplicações deste livro são baseados em gestantes e puérperas de 10 a 55 anos hospitalizadas com Síndrome Respiratória Aguda Grave (SRAG) por COVID-19, confirmada por teste de PCR, no período de março de 2020 a dezembro de 2021, disponíveis no Sistema de Informação da Vigilância Epidemiológica da Gripe (SIVEP-Gripe), sistema oficial para o registro dos casos e óbitos por SRAG disponibilizado pelo Ministério da Saúde.\nNa base dados_covid estão contidas 11.485 observações e 50 variáveis. Assim, são as características observadas:\n\n\n\n\n\n\n\nVariável\nDescrição\n\n\n\n\nsem_pri\nSemana epidemiológia dos primeiros sintomas.\n\n\nidade_anos\nIdade, em anos, da gestante ou puérpera.\n\n\nsg_uf\nSigla da Unidade Federativa de residência da gestante ou puérpera.\n\n\nid_mn_resi\nMunicípio de residência da gestante ou puérpera.\n\n\nco_mun_res\nCódigo do município de residência da gestante ou puérpera.\n\n\nco_mu_inte\nCódigo do município onde está localizado a Unidade de Saúde onde a gestante ou puérpera internou.\n\n\ndt_sin_pri\nData de primeiros sintomas do caso.\n\n\ndt_evoluca_2\nData da alta ou do óbito da gestante ou puérpera.\n\n\nano\nAno da infecção pelo COVID-19.\n\n\nclassi_gesta_puerp\nIdade gestacional da gestante e puerpério.\n\n\nraca\nRaça da gestante ou puérpera.\n\n\nescol\nNível de escolaridade da gestante ou puérpera.\n\n\nmudou_muni\nSe gestante ou puérpera precisou se deslocar para outro município para realizar atendimento.\n\n\nzona\nTipo de zona de residência da gestante ou puérpera.\n\n\nfaixa_et\nFaixa etária da gestante ou puérpera.\n\n\nhospital\nSe gestante ou puérpera foi hospitalizada.\n\n\nhist_viagem\nSe gestante ou puérpera fez viagem internacional até 14 dias antes do início dos sintomas.\n\n\nsg_para_srag\nSe o caso é proveniente de síndrome gripal (SG) que evoluiu para síndrome respiratória aguda grave (SRAG).\n\n\ninf_inter\nSe trata-se de caso nosocomial (infecção adquirida no hospital).\n\n\ncont_ave_suino\nSe a gestante ou puérpera trabalha ou tem contato direto com aves, suínos ou outros animais.\n\n\nvacina\nSe a gestante ou puérpera recebeu vacina contra influenza.\n\n\nvacina_cov\nSe a gestante ou puérpera recebeu vacina contra COVID-19.\n\n\nantiviral\nSe gestante ou puérpera usou antiviral para gripe e qual antiviral.\n\n\nfebre\nSe gestante ou puérpera manifestou sintoma de febre.\n\n\ntosse\nSe gestante ou puérpera manifestou sintoma de tosse.\n\n\ngarganta\nSe gestante ou puérpera manifestou sintoma de dor de garganta.\n\n\ndispneia\nSe gestante ou puérpera manifestou sintoma de dispneia.\n\n\ndesc_resp\nSe gestante ou puérpera manifestou sintoma de desconforto respiratório.\n\n\nsaturacao\nSe gestante ou puérpera manifestou sintoma de saturação.\n\n\ndiarreia\nSe gestante ou puérpera manifestou sintoma de diarreia.\n\n\nvomito\nSe gestante ou puérpera manifestou sintoma de vômito.\n\n\ndor_abd\nSe gestante ou puérpera manifestou sintoma de dor abdominal.\n\n\nfadiga\nSe gestante ou puérpera manifestou sintoma de fadiga.\n\n\nperd_olft\nSe gestante ou puérpera manifestou sintoma de perda de olfato.\n\n\nperd_pala\nSe gestante ou puérpera manifestou sintoma de perda de paladar.\n\n\ncardiopati\nSe gestante ou puérpera tem doença cardiovascular crônica.\n\n\nhematologi\nSe gestante ou puérpera tem doença hematológica crônica.\n\n\nhepatica\nSe gestante ou puérpera tem doença hepática crônica.\n\n\nasma\nSe gestante ou puérpera tem asma.\n\n\ndiabetes\nSe gestante ou puérpera tem diabetes mellitus.\n\n\nneuro\nSe gestante ou puérpera tem doença neurológica.\n\n\npneumopati\nSe gestante ou puérpera tem outra pneumopatia crônica.\n\n\nimunodepre\nSe gestante ou puérpera tem imunodeficiência ou imunodepressão (diminuição da função do sistema imunológico).\n\n\nrenal\nSe gestante ou puérpera tem doença renal crônica.\n\n\nobesidade\nSe gestante ou puérpera tem obesidade.\n\n\nuti\nSe gestante ou puérpera foi internada na UTI.\n\n\nsuport_ven\nSe gestante ou puérpera precisou de ventilação mecânica; se sim, se foi invasiva ou não.\n\n\nevolucao\nEvolução do caso da gestante ou puérpera.\n\n\nvariante\nVariante do vírus SARS-CoV-2 (vírus do COVID-19)."
  },
  {
    "objectID": "tutorialr.html#sobre-o-software-r",
    "href": "tutorialr.html#sobre-o-software-r",
    "title": "Appendix A — Tutorial de R",
    "section": "A.1 Sobre o software R",
    "text": "A.1 Sobre o software R\nR é um ambiente computacional e uma linguagem de programação para manipulação, análise e visualização de dados. Para essas finalidades, ele é considerado um dos melhores e um dos mais utilizados dentre os ambientes computacionais disponíveis. O R é mantido pela R Development Core Team e está disponível para diferentes sistemas operacionais: Linux, Mac e Windows.\nO software é livre, ou seja, gratuito, com código aberto em uma linguagem acessível. Nele, estão implementadas muitas metodologias estatísticas. Muitas dessas fazem parte do ambiente base do R e outras acompanham o ambiente sob a forma de pacotes, o que o torna altamente flexível. Os pacotes são bibliotecas com funções extras devidamente documentadas criadas para ajudar a resolver problemas de diferentes áreas do conhecimento.\nO R possui uma comunidade extremamente ativa, engajada desde o aprimoramento de ferramentas e desenvolvimento de novas bibliotecas, até o suporte aos usuários. Sobre o desenvolvimento de novas bibliotecas, um pesquisador em Estatística que desenvolve um novo modelo estatístico pode disponibilizá-lo em um pacote acessível aos usuários que se interessem pelo modelo, por exemplo. Além disso, a disponibilidade e compartilhamento da pesquisa em um pacote no R é uma boa prática quando falamos de reprodutibilidade na ciência. Ainda nesse ponto, realizar as análises de uma pesquisa aplicada em um programa livre e acessível a todos é um dos principais pontos para permitir reprodutibilidade.\nOptar por programar em R também implica na escolha de uma IDE (Integrated Development Environment). Uma IDE é um ambiente de desenvolvimento integrado onde podem ser combinadas ferramentas utilizadas no desenvolvimento de aplicações, como um editor de código ou uma ferramenta de preenchimento inteligente de código. Para o R, a IDE mais popular entre os usuários é o RStudio. O RStudio é um conjunto de ferramentas integradas projetadas para editar e executar os códigos em R. Assim, quando for o interesse utilizar o R, basta abrir o RStudio (R é automaticamente carregado)."
  },
  {
    "objectID": "instalar.html#instalação-r",
    "href": "instalar.html#instalação-r",
    "title": "3  Instalação R e RStudio",
    "section": "3.1 Instalação R",
    "text": "3.1 Instalação R\nNessa Seção, vamos apresentar como instalar o R e o RStudio para os três sistemas operacionais: Windows, MAC e Linux, respectivamente.\n\n3.1.1 Para Windows\nOs passos para instalar o R quando o sistema operacional é Windows são os seguintes:\n\nEntre neste link para acessar a página do R e clique em Download, como no link destacado em retângulo vermelho na Figura @ref(fig:windows1). Note que o 3.6.1 é o número da versão mais recente disponível no momento da construção desse material (5/7/19).\n\n\n\n\n\n\nDownload R para Windows\n\n\n\n\n\nSalve o arquivo de instalação em algum caminho de interesse do seu computador. Por exemplo, na Figura @ref(fig:windows2) mostra que a pasta é “Downloads”.\n\n\n\n\n\n\nInstalador\n\n\n\n\n\nClique duas vezes com o botão esquerdo no instalador para iniciar a instalação. O próximo passo é escolher a língua para instalação. Na Figura @ref(fig:windows3) abaixo é português.\n\n\n\n\n\n\nEscolha da lingua para instalação\n\n\n\n\n\nClique em “Próximo” nas próximas janelas, como nas Figuras @ref(fig:windows4) a @ref(fig:windows9).\n\n\n\n\n\n\nPróximo\n\n\n\n\n\n\n\n\n\nPróximo\n\n\n\n\n\n\n\n\n\nPróximo\n\n\n\n\n\n\n\n\n\nPróximo\n\n\n\n\n\n\n\n\n\nPróximo\n\n\n\n\n\n\n\n\n\nPróximo\n\n\n\n\n\nPronto, agora o software R será instalado, como na Figura @ref(fig:windows10). Quando terminar, aparecerá uma janela como apresentado na Figura @ref(fig:windows11).\n\n\n\n\n\n\nInstalação do R\n\n\n\n\n\n\n\n\n\nPronto: R instalado\n\n\n\n\n\n\n3.1.2 Para MAC\nOs passos para instalar o R quando o sistema operacional é OS X (Mac) são os seguintes:\n\nEntre no site e clique em Download R for (MAC) OS X, conforme destacado abaixo em retângulo vermelho na Figura @ref(fig:mac1).\n\n\n\n\n\n\n Download R para Mac\n\n\n\n\n\nBaixe o pacote R-3.6.1.pkg clicando no link indicado no retângulo vermelho na Figura @ref(fig:mac2). Note que o 3.6.1 é o número da versão mais recente disponível no momento da confecção deste material.\n\n\n\n\n\n\n Download R para Mac\n\n\n\n\n\nCaso você não tenha configurado a pasta de descargas, o pacote será baixado na pasta “Downloads”, como mostrado na seguinte Figura @ref(fig:mac3). Observe que dois arquivos são baixados, clique duas vezes no arquivo “R-3.6.1.pkg” para abrir o assistente de instalação que o guiará durante o processo.\n\n\n\n\n\n\n Pasta para instalação\n\n\n\n\n\nAcompanhe os passos indicados pelo instalador (Figura @ref(fig:mac4)).\n\n\n\n\n\n\n Instalação\n\n\n\n\n\nDeve concordar com os termos da licença, clique em “Agree” (Figura @ref(fig:mac5)).\n\n\n\n\n\n\n Instalação\n\n\n\n\n\nSelecione o lugar onde instalará o programa, no caso de ter o disco particionado e assim desejar instalar em uma parte específica. Caso contrário, continue (Figura @ref(fig:mac6) e @ref(fig:mac7)).\n\n\n\n\n\n\n Instalação\n\n\n\n\n\n\n\n\n\n Instalação\n\n\n\n\n\nPara finalizar a instalação, o assistente lhe pedirá nome de usuário e senha do seu notebook, como apresentado na Figura @ref(fig:mac8).\n\n\n\n\n\n\n Instalação\n\n\n\n\n\nPronto, agora o software R será instalado, como na Figura @ref(fig:mac9). Quando terminar, aparecerá uma janela como apresentado na Figura @ref(fig:mac10).\n\n\n\n\n\n\n Instalação\n\n\n\n\n\n\n\n\n\n Instalação\n\n\n\n\n\n\n3.1.3 Para Linux\nA instalação do R no Linux depende da distribuição utilizada. Entre neste link para acessar a página do R e clique em Download R for Linux, como no link destacado em retângulo vermelho na Figura @ref(fig:linux1). Em seguida, clique no link referente à distribuição utilizada (Figura @ref(fig:linux2)).\n\n\n\n\n\nDownload em Linux\n\n\n\n\n\n\n\n\n\nDownload em Linux"
  },
  {
    "objectID": "instalar.html",
    "href": "instalar.html",
    "title": "Appendix B — Instalação R",
    "section": "",
    "text": "Nessa Seção, vamos apresentar como instalar o R e o RStudio para os três sistemas operacionais: Windows, MAC e Linux, respectivamente.\n\nB.0.1 Para Windows\nOs passos para instalar o R quando o sistema operacional é Windows são os seguintes:\n\nEntre neste link para acessar a página do R e clique em Download, como no link destacado em retângulo vermelho na Figura @ref(fig:windows1). Note que o 3.6.1 é o número da versão mais recente disponível no momento da construção desse material (5/7/19).\n\n\n\n\n\n\nDownload R para Windows\n\n\n\n\n\nSalve o arquivo de instalação em algum caminho de interesse do seu computador. Por exemplo, na Figura @ref(fig:windows2) mostra que a pasta é “Downloads”.\n\n\n\n\n\n\nInstalador\n\n\n\n\n\nClique duas vezes com o botão esquerdo no instalador para iniciar a instalação. O próximo passo é escolher a língua para instalação. Na Figura @ref(fig:windows3) abaixo é português.\n\n\n\n\n\n\nEscolha da lingua para instalação\n\n\n\n\n\nClique em “Próximo” nas próximas janelas, como nas Figuras @ref(fig:windows4) a @ref(fig:windows9).\n\n\n\n\n\n\nPróximo\n\n\n\n\n\n\n\n\n\nPróximo\n\n\n\n\n\n\n\n\n\nPróximo\n\n\n\n\n\n\n\n\n\nPróximo\n\n\n\n\n\n\n\n\n\nPróximo\n\n\n\n\n\n\n\n\n\nPróximo\n\n\n\n\n\nPronto, agora o software R será instalado, como na Figura @ref(fig:windows10). Quando terminar, aparecerá uma janela como apresentado na Figura @ref(fig:windows11).\n\n\n\n\n\n\nInstalação do R\n\n\n\n\n\n\n\n\n\nPronto: R instalado\n\n\n\n\n\n\nB.0.2 Para MAC\nOs passos para instalar o R quando o sistema operacional é OS X (Mac) são os seguintes:\n\nEntre no site e clique em Download R for (MAC) OS X, conforme destacado abaixo em retângulo vermelho na Figura @ref(fig:mac1).\n\n\n\n\n\n\n Download R para Mac\n\n\n\n\n\nBaixe o pacote R-3.6.1.pkg clicando no link indicado no retângulo vermelho na Figura @ref(fig:mac2). Note que o 3.6.1 é o número da versão mais recente disponível no momento da confecção deste material.\n\n\n\n\n\n\n Download R para Mac\n\n\n\n\n\nCaso você não tenha configurado a pasta de descargas, o pacote será baixado na pasta “Downloads”, como mostrado na seguinte Figura @ref(fig:mac3). Observe que dois arquivos são baixados, clique duas vezes no arquivo “R-3.6.1.pkg” para abrir o assistente de instalação que o guiará durante o processo.\n\n\n\n\n\n\n Pasta para instalação\n\n\n\n\n\nAcompanhe os passos indicados pelo instalador (Figura @ref(fig:mac4)).\n\n\n\n\n\n\n Instalação\n\n\n\n\n\nDeve concordar com os termos da licença, clique em “Agree” (Figura @ref(fig:mac5)).\n\n\n\n\n\n\n Instalação\n\n\n\n\n\nSelecione o lugar onde instalará o programa, no caso de ter o disco particionado e assim desejar instalar em uma parte específica. Caso contrário, continue (Figura @ref(fig:mac6) e @ref(fig:mac7)).\n\n\n\n\n\n\n Instalação\n\n\n\n\n\n\n\n\n\n Instalação\n\n\n\n\n\nPara finalizar a instalação, o assistente lhe pedirá nome de usuário e senha do seu notebook, como apresentado na Figura @ref(fig:mac8).\n\n\n\n\n\n\n Instalação\n\n\n\n\n\nPronto, agora o software R será instalado, como na Figura @ref(fig:mac9). Quando terminar, aparecerá uma janela como apresentado na Figura @ref(fig:mac10).\n\n\n\n\n\n\n Instalação\n\n\n\n\n\n\n\n\n\n Instalação\n\n\n\n\n\n\nB.0.3 Para Linux\nA instalação do R no Linux depende da distribuição utilizada. Entre neste link para acessar a página do R e clique em Download R for Linux, como no link destacado em retângulo vermelho na Figura @ref(fig:linux1). Em seguida, clique no link referente à distribuição utilizada (Figura @ref(fig:linux2)).\n\n\n\n\n\nDownload em Linux\n\n\n\n\n\n\n\n\n\nDownload em Linux"
  },
  {
    "objectID": "instalarstudio.html",
    "href": "instalarstudio.html",
    "title": "Appendix C — Instalação RStudio",
    "section": "",
    "text": "O RStudio é um conjunto de ferramentas integradas projetadas (IDE - Integrated Development Environment) da linguagem R para auxiliar na produtividade ao utilizar o R.\n\nC.0.1 Para Windows\n\nEntre neste link e clique em Download como em destaque na Figura @ref(fig:rswindows1).\n\n\n\n\n\n\nSite para download do RStudio\n\n\n\n\n\nClique no instalador em destaque na Figura @ref(fig:rswindows2).\n\n\n\n\n\n\nLink para download do RStudio\n\n\n\n\n\nAo clicar no link, será feito o download do instalador e salvo na pasta de interesse. No caso da Figura @ref(fig:rswindows3), o instalador está na pasta Downloads. Dê dois cliques no botão esquerdo no arquivo para iniciar o download do arquivo.\n\n\n\n\n\n\n Instalador\n\n\n\n\n\nClique em “Próximo” nas próximas janelas e na última “Instalar”, como nas Figuras @ref(fig:rswindows4) a @ref(fig:rswindows6).\n\n\n\n\n\n\n Instalação\n\n\n\n\n\n\n\n\n\n Instalação\n\n\n\n\n\n\n\n\n\n Instalação\n\n\n\n\n\nPronto, a instalação será iniciada, como na Figura @ref(fig:rswindows7).\n\n\n\n\n\n\n Instalação\n\n\n\n\n\n\nC.0.2 Para MAC\n\nEntre neste link e clique em Download como em destaque na Figura @ref(fig:rsmac1).\n\n\n\n\n\n\nSite para download do RStudio\n\n\n\n\n\nClique no instalador como destacado na Figura @ref(fig:rsmac2).\n\n\n\n\n\n\nSite para download do RStudio para Mac\n\n\n\n\n\nAo clicar no link, será feito o download do instalador e salvo na pasta de interesse. Caso você não tenha configurado a pasta de descargas, o instalador ficará na pasta “Downloads”, como na Figura @ref(fig:rsmac3).\n\n\n\n\n\n\n Instalador salvo em pasta\n\n\n\n\n\nClicando duas vezes no arquivo “RStudio-1.2.1335.dmg” (versãos mais atual do RStudio), será feita a descarga do mesmo abrindo a janela conforme na Figura @ref(fig:rsmac4). Clique no aplicativo de RStudio destacado em vermelho também na Figura @ref(fig:rsmac4).\n\n\n\n\n\n\n Instalação\n\n\n\n\n\nO instalador pode perguntar se está seguro que o aplicativo será baixado da internet e clique em “Open” (Figura @ref(fig:rsmac5)).\n\n\n\n\n\n\n Instalação\n\n\n\n\n\nPronto! Imediatamente abre o RStudio, como na Figura @ref(fig:rsmac6), e você já pode utilizá-lo.\n\n\n\n\n\n\n Instalação\n\n\n\n\n\n\nC.0.3 Para Linux\n\nEntre neste link e clique em Download como em destaque na Figura @ref(fig:rslinux1).\n\n\n\n\n\n\nSite para download do RStudio\n\n\n\n\n\nClique no link referente à distribuição utilizada (Figura @ref(fig:rslinux2)).\n\n\n\n\n\n\n Download do RStudio"
  },
  {
    "objectID": "comecando_rstudio.html",
    "href": "comecando_rstudio.html",
    "title": "Appendix D — Primeiros passos no RStudio",
    "section": "",
    "text": "O RStudio é um conjunto de ferramentas integradas projetadas (IDE - Integrated Development Environment) da linguagem R para editar e executar os códigos em R.\nTem quatro áreas, conforme a Figura @ref(fig:telarstudio1).\n\n\n\n\n\n Visualização do RStudio\n\n\n\n\nA seguir descrevemos melhor os painéis e abas do RStudio:\n\nEditor/Scripts: é onde escrever os códigos. Arquivos do tipo .R.\nConsole: executar os comandos e ver os resultados.\nEnviroment: painel com todos os objetos criados.\nHistory: história dos comandos executados.\nFiles: navegar em pastas e arquivos.\nPlots: onde os gráficos serão apresentados.\nPackages: pacotes instalados (sem ticar) e habilitados (ticados).\nHelp: retorna o tutorial de ajuda do comando solicitado com help() ou ?comando. Ver melhor como pedir ajuda no R no final deste capítulo.\n\nO usuário pode alterar a aparência do RStudio, como fonte e cor. Como exemplo, as Figuras @ref(fig:telarstudio2) e @ref(fig:telarstudio3) apresentam os passos para mudar o tema do script. No exemplo, deixar com fundo preto.\n\n\n\n\n\n Ferramentas de aparência do RStudio\n\n\n\n\n\n\n\n\n\n Ferramentas de aparência do RStudio\n\n\n\n\nAinda no menu Tools –> Global Options –> Pane Layout, o usuário pode organizar a ordem dos quadrantes do RStudio, como apresentado nas Figuras @ref(fig:telarstudio4), @ref(fig:telarstudio5) e @ref(fig:telarstudio6). No exemplo, o painel Console foi transferido para o lado do painel Script, o que facilita a visualização dos comandos rodados.\n\n\n\n\n\n Ferramentas de aparência do RStudio\n\n\n\n\n\nD.0.1 Projetos\nUma funcionalidade importante é a criação de projetos, permitindo dividir o trabalho em múltiplos ambientes, cada um com o seu diretório, documentos e workspace.\nPara criar um projeto, os seguintes passos podem ser seguidos:\n\nClique na opção “File” do menu, e então em “New Project”.\nClique em “New Directory”.\nClique em “New Project”.\nEscreva o nome do diretório (pasta) onde deseja manter seu projeto, exemplo: “my_project”.\nClique no botão “Create Project”.\n\nPara criar um novo script para escrever os códigos, vá em File -> New File -> R Script\n\n\nD.0.2 Boas práticas\nComente bem o seu código: é possível fazer comentários usando o símbolo ‘#’. É sempre bom explicar o que uma variável armazena, o que uma função faz, por que alguns parâmetros são passados para uma determinada função, qual é o objetivo de um trecho de código etc.\nEvite linhas de código muito longas: usar linhas de código mais curtas ajuda na leitura do código.\nEscreva um código organizado. Por exemplo, adote um padrão no uso de minúsculas e maiúsculas, uma lógica única na organização de pastas e arquivos, pode ser adotada uma breve descrição (como comentário) indicando o que um determinado script faz.\nCarregue todos os pacotes que irá usar sempre no início do arquivo: quando alguém abrir o seu código será fácil identificar quais são os pacotes que devem ser instalados e quais dependências podem existir."
  },
  {
    "objectID": "comecando_r.html#como-obter-ajuda-no-r",
    "href": "comecando_r.html#como-obter-ajuda-no-r",
    "title": "Appendix E — Primeiros passos no R",
    "section": "E.13 Como obter ajuda no R",
    "text": "E.13 Como obter ajuda no R\nListamos aqui 3 maneiras para buscar ajuda no R:\n\nHelp/documentação do R (comandos help(nome_da_funcao) ou ?nome_da_funcao). Como exemplo,\n\n\nhelp(mean) #ou\n?mean\n\n\nGoogle Na Figura @ref(fig:help) está o exemplo de busca de ajuda no Google. Repare no ‘r’ no início da busca, isso pode ajudar.\n\n\n\n\n\n\nPesquisa no Google\n\n\n\n\n\nComunidade O Stack Overflow e o Stack Overflow em Português são sites de Pergunta e Resposta amplamente utilizados por todas as linguagens de programação, e o R é uma delas."
  },
  {
    "objectID": "comecando_r.html#pacotes",
    "href": "comecando_r.html#pacotes",
    "title": "Appendix E — Primeiros passos no R",
    "section": "E.14 Pacotes",
    "text": "E.14 Pacotes\nComo dito quando falamos “Sobre o R”, o R apresenta funções na sua base e também em forma de pacotes (conjunto de funções bem documentado), que precisam ser instalados (uma vez no seu computador) e carregados na sessão de utilização do R (carregado em toda sessão aberta).\nDificilmente você vai fazer uma análise apenas com as funções básicas do R e dificilmente não vai existir um pacote com as funções que você precisa. Por esse motivo, falamos a seguir em como instalar e carregar pacotes.\n\nE.14.1 Instalação de pacotes\n\nVia CRAN:\n\n\ninstall.packages(\"nome-do-pacote\")\n\nExemplo: Instalação do pacote dplyr.\n\ninstall.packages(\"dplyr\")\n\nNote que o nome do pacote está entre aspas.\n\nVia Github: Para instalar via Github, precisa primeiramente instalar o pacote devtools.\n\n\ndevtools::install_github(\"nome-do-repo/nome-do-pacote\")\n\nExemplo:\n\ndevtools::install_github(\"tidyverse/dplyr\")\n\n\n\nE.14.2 Carregar pacotes\nUma vez que um pacote de interesse está instalado em sua máquina, para carregá-lo na sessão atual do R é só rodar a seguinte linha de comando:\n\nlibrary(nome-do-pacote)\n\nVeja que para carregar o pacote não se usa aspas.\nComo exemplo, o carregamento do pacote dplyr:\n\nlibrary(dplyr)\n\nSó é necessário instalar o pacote uma vez, mas é necessário carregá-lo toda vez que começar uma nova sessão.\nDado que o pacote está carregado ao rodar a função library(), todas as funções desse pacote podem ser usadas sem problemas.\nCaso você não queira carregar o pacote e apenas usar uma função específica do pacote, você pode usar nome-do-pacote::nome-da-funcao. Por exemplo:\n\ndplyr::distinct(...)\n\nSe você tivesse carregado o pacote dplyr anteriormente (pela função library()), não seria necessário colocar dplyr:: antes da função distinct do pacote."
  },
  {
    "objectID": "comecando_r.html#materiais-complementares",
    "href": "comecando_r.html#materiais-complementares",
    "title": "Appendix E — Primeiros passos no R",
    "section": "E.15 Materiais complementares",
    "text": "E.15 Materiais complementares\n\nCritical Thinking in Clinical Research. Felipe Fregni & Ben M. W. Illigens. 2018.\nSites:\n\nhttps://www.bmj.com/about-bmj/resources-readers/publications/statistics-square-one/1-data-display-and-summary\nhttp://www.sthda.com/english/wiki/statistical-tests-and-assumptions\n\nCHAPTER 3: Selecting the Study Population. In: Critical Thinking in Clinical Research by Felipe Fregni and Ben Illigens. Oxford University Press 2018.\nFandino W. Formulating a good research question: Pearls and pitfalls. Indian J Anaesth. 2019;63(8):611–616. doi:10.4103/ija.IJA_198_19\nRiva JJ, Malik KM, Burnie SJ, Endicott AR, Busse JW. What is your research question? An introduction to the PICOT format for clinicians. J Can Chiropr Assoc. 2012;56(3):167–171.\nExternal validity, generalizability, and knowledge utilization. Ferguson L1. J Nurs Scholarsh. 2004;36(1):16-22.\nPeter M Rothwell; Commentary: External validity of results of randomized trials: disentangling a complex concept, International Journal of Epidemiology, Volume 39, Issue 1, 1 February 2010, Pages 94–96, https://doi.org/10.1093/ije/dyp305"
  },
  {
    "objectID": "comecando_r.html#r-como-calculadora",
    "href": "comecando_r.html#r-como-calculadora",
    "title": "Appendix E — Primeiros passos no R",
    "section": "E.1 R como calculadora",
    "text": "E.1 R como calculadora\n\nOperadores\n\n\n#adição\n10+15\n\n[1] 25\n\n#subtração\n10-2\n\n[1] 8\n\n#multiplicação\n2*10\n\n[1] 20\n\n#divisão\n30/2\n\n[1] 15\n\n#raiz quadrada\nsqrt(4)\n\n[1] 2\n\n#potência\n2^2\n\n[1] 4\n\n\nSe você digitar um comando incompleto, como 10 *, o R mostrará um +. Isso não tem a ver com a soma e apenas que o R está esperando você completar seu comando. Termine seu comando ou aperte Esc para recomeçar.\nVale também ressaltar que se você digitar um comando que o R não reconhece, ele retornará uma mensagem de erro e você pode digitar outro comando normalmente em seguida."
  },
  {
    "objectID": "comecando_r.html#atribuição",
    "href": "comecando_r.html#atribuição",
    "title": "Appendix E — Primeiros passos no R",
    "section": "E.2 Atribuição",
    "text": "E.2 Atribuição\nPodemos salvar valores dentro de um objeto, que é simplemente um nome que guarda um valor, vetor, matriz, lista ou base de dados.\nPara atribuir a um objeto, o sinal de atribuição é = ou <- (preferível).\nExemplos:\n\nx <- 10/2\nx\n\n[1] 5\n\nX\n\nError in eval(expr, envir, enclos): object 'X' not found\n\n\nPor que tivemos um erro acima?\nO R é case sensitive, isto é, faz a diferenciação entre as letras minúsculas e maiúsculas. Portanto, x é diferente de X."
  },
  {
    "objectID": "comecando_r.html#objetos-em-r",
    "href": "comecando_r.html#objetos-em-r",
    "title": "Appendix E — Primeiros passos no R",
    "section": "E.3 Objetos em R",
    "text": "E.3 Objetos em R\nExistem cinco classes básicas no R:\n\ncharacter: “UAH!”\nnumeric: 0.95 (números reais)\ninteger: 100515 (inteiros)\ncomplex: 2 + 5i (números complexos, a + bi)\nlogical: TRUE (booleanos, TRUE/FALSE)\n\nVamos atribuir a x a string banana.\n\nx <- banana \n\nError in eval(expr, envir, enclos): object 'banana' not found\n\nx <- \"banana\"\nx\n\n[1] \"banana\"\n\n\nO primeiro caso (x <- banana) não deu certo, pois ele entendeu que estamos atribuindo a x outro objeto banana, que não foi declarado. Para atribuir o string banana a x, precisamos colocar entre aspas ou aspas simples. Uma string sem aspas é entendido como um objeto, veja abaixo:\n\nbanana <- 30\nx <- banana\nx\n\n[1] 30\n\n\nPara saber a classe de um objeto, use a função class().\n\ny <- \"ola\"\nclass(y)\n\n[1] \"character\"\n\nx <- 2.5\nclass(x)\n\n[1] \"numeric\"\n\n\n\nE.3.1 Apagar objetos\nE se eu quiser apagar um objeto?\n\nx <- 20\nx\n\n[1] 20\n\nremove(x)\nx\n\nError in eval(expr, envir, enclos): object 'x' not found\n\n\nE se eu quiser limpar o console - apaga todos os objetos atribuídos até aqui:\n\nrm(list=ls())"
  },
  {
    "objectID": "comecando_r.html#vetores",
    "href": "comecando_r.html#vetores",
    "title": "Appendix E — Primeiros passos no R",
    "section": "E.4 Vetores",
    "text": "E.4 Vetores\nComo atribuir vários valores a um objeto? Para entrar com vários números (ou nomes, ou qualquer outro grupo de coisas), precisamos usar uma função para dizer ao programa que os valores serão combinados em um único vetor.\n\nx <- c(2,3,4)\nx\n\n[1] 2 3 4\n\ny <- seq(1,10)\ny\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nz <- rep(1,10)\nz\n\n [1] 1 1 1 1 1 1 1 1 1 1\n\na <- 1:10\na\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nbicho <-c(\"macaco\",\"pato\",\"galinha\",\"porco\")\nbicho\n\n[1] \"macaco\"  \"pato\"    \"galinha\" \"porco\"  \n\n\nE se quisermos visualizar o conteúdo da posição 2 no vetor bicho?\n\nbicho[2]\n\n[1] \"pato\"\n\n\nAs operações vetoriais podem ser realizadas de maneira bastante intuitiva. Como exemplos:\n\nx <- c(2,3,4)\nx\n\n[1] 2 3 4\n\nops <- x-1\nops\n\n[1] 1 2 3\n\nk <- x*2\nk\n\n[1] 4 6 8\n\n\nVamos agora considerar um vetor de pesos em kg e altura em metros de 6 pessoas.\n\npeso <- c(62, 70, 52, 98, 90, 70)\npeso\n\n[1] 62 70 52 98 90 70\n\naltura <- c(1.70, 1.82, 1.75, 1.94, 1.84, 1.61)\naltura\n\n[1] 1.70 1.82 1.75 1.94 1.84 1.61\n\n\nVale mencionar que o separador de decimais no R é . (ponto)!\nComo calcularia o IMC? Lembrando que o IMC é dado pelo peso (em kg) dividido pela altura (em metros) ao quadrado.\n\nimc <- peso/(altura^2)\nimc\n\n[1] 21.45329 21.13271 16.97959 26.03890 26.58318 27.00513\n\n\nPara saber o tamanho do vetor, use a função length().\n\nlength(imc)\n\n[1] 6"
  },
  {
    "objectID": "comecando_r.html#matrizes",
    "href": "comecando_r.html#matrizes",
    "title": "Appendix E — Primeiros passos no R",
    "section": "E.5 Matrizes",
    "text": "E.5 Matrizes\nMatrizes são vetores numéricos com duas dimensões, que são simplesmente a linha e a coluna às quais o elemento pertence.\n\nx <- matrix(seq(1,16), nrow=4,ncol=4)\nx\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\n\nNote que os números de 1 a 16 foram dispostos na matriz coluna por coluna ou seja, preenchendo de cima para baixo e depois da esquerda para a direita.\nComo sei qual elemento está na segunda linha e terceira coluna da matriz x?\n\nx[2,3]\n\n[1] 10\n\nx[3,  ]   # seleciona a 3ª linha\n\n[1]  3  7 11 15\n\nx[ , 2]   # seleciona a 2ª coluna\n\n[1] 5 6 7 8\n\nx[1, 2]   # seleciona o elemento da primeira linha e segunda coluna\n\n[1] 5\n\n\nE se eu quiser substituir a primeira linha por (13,15,19,30)?\n\nx[1,] <- c(13,15,19,30)\n\nx\n\n     [,1] [,2] [,3] [,4]\n[1,]   13   15   19   30\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\n\nSeja o vetor d:\n\nd <- c(128,124,213,234)\n\nE se quisermos substituir a terceira coluna por d?\n\nx[,3] <- d\n\nQual a dimensão da matriz x?\nVimos que para vetor usamos o comando length(). Serve para matriz também? Vamos testar!\n\nlength(x)\n\n[1] 16\n\n\nNote que retorna o número de colunas vezes o número de linhas (4*4=16). Mas o que quero saber é o numero de linhas e de colunas. Para isso, o comando é dim().\n\ndim(x)\n\n[1] 4 4\n\n\nPara concatenar linhas em uma matriz, podemos usar o comando rbind():\n\nvet <- c(2,20,12,34)\nx2 <- rbind(x,vet)\nx2\n\n    [,1] [,2] [,3] [,4]\n      13   15  128   30\n       2    6  124   14\n       3    7  213   15\n       4    8  234   16\nvet    2   20   12   34\n\n\nPara concatenar colunas em uma matriz, podemos usar o comando cbind():\n\nv2 <- c(25,10,15,4) \nx3 <- cbind(x,v2)\nx3\n\n                  v2\n[1,] 13 15 128 30 25\n[2,]  2  6 124 14 10\n[3,]  3  7 213 15 15\n[4,]  4  8 234 16  4"
  },
  {
    "objectID": "comecando_r.html#fatores",
    "href": "comecando_r.html#fatores",
    "title": "Appendix E — Primeiros passos no R",
    "section": "E.6 Fatores",
    "text": "E.6 Fatores\nFatores podem ser vistos como vetores de inteiros que possuem rótulos (labels). Eles são úteis para representar uma variável categórica (nominal e ordinal).\n\nsexo <- c(\"M\", \"H\", \"H\", \"H\", \"M\", \"M\", \"H\")\nsex <- as.factor(sexo)\nsex\n\n[1] M H H H M M H\nLevels: H M\n\nlevels(sex)\n\n[1] \"H\" \"M\""
  },
  {
    "objectID": "comecando_r.html#data-frame",
    "href": "comecando_r.html#data-frame",
    "title": "Appendix E — Primeiros passos no R",
    "section": "E.7 Data frame",
    "text": "E.7 Data frame\nTrata-se de uma “tabela de dados” onde as colunas são as variáveis e as linhas são os registros. Essas colunas podem ser de classes diferentes.\nEssa é a grande diferença entre data.frame’s e matrizes (matriz é só numerica).\nPosso criar um data frame no R com os vetores, por exemplo:\n\nID <- seq(1,6)\npes <- c(62, 70, 52, 98, 90, 70)\nalt <- c(1.70, 1.82, 1.75, 1.94, 1.84, 1.61)\nimc <- pes/(alt^2)\ndados <- data.frame(ID=ID,peso=pes,altura=alt, imc=imc)\ndados\n\n  ID peso altura      imc\n1  1   62   1.70 21.45329\n2  2   70   1.82 21.13271\n3  3   52   1.75 16.97959\n4  4   98   1.94 26.03890\n5  5   90   1.84 26.58318\n6  6   70   1.61 27.00513\n\n\nPosso pensar que o data frame tem a mesma ideia de matriz. Quero olhar os dados de altura, que sei que está na coluna 3.\n\ndados[,3]\n\n[1] 1.70 1.82 1.75 1.94 1.84 1.61\n\n\nMas existe uma maneira mais fácil de selecionar a variável de interesse sem ter que saber em qual coluna ela está.\nPor ser um data frame, posso usar $ da seguinte maneira:\n\ndados$altura\n\n[1] 1.70 1.82 1.75 1.94 1.84 1.61\n\n\nPutz, esqueci de colocar a variável de grupo no data frame. Tenho que criar tudo de novo? Não:\n\ngr <- c(rep(1,3),rep(2,3))\ndados$grupo <- gr\n\ndados\n\n  ID peso altura      imc grupo\n1  1   62   1.70 21.45329     1\n2  2   70   1.82 21.13271     1\n3  3   52   1.75 16.97959     1\n4  4   98   1.94 26.03890     2\n5  5   90   1.84 26.58318     2\n6  6   70   1.61 27.00513     2\n\n\nVeja que no “dados$grupo” foi inserido o objeto “gr”. Se “gr” não tivesse o mesmo número de linhas do data frame retornaria um erro.\nFunções úteis para data.frame:\nAinda não falamos com muito detalhes sobre funções no R, faremos isso mais adiante. Mas por enquanto, considere que sejam nomes já salvos no R e que, ao colocar o objeto da base de dados (no nosso exemplo é dados) dentro dos parênteses, retorna algumas informações úteis sobre a base de dados. São algumas delas:\n\nhead() - Mostra as primeiras 6 linhas.\ntail() - Mostra as últimas 6 linhas.\ndim() - Número de linhas e de colunas.\nnames() - Os nomes das colunas (variáveis).\nstr() - Estrutura do data.frame. Mostra, entre outras coisas, as classes de cada coluna.\n\n\nhead(dados)\n\n  ID peso altura      imc grupo\n1  1   62   1.70 21.45329     1\n2  2   70   1.82 21.13271     1\n3  3   52   1.75 16.97959     1\n4  4   98   1.94 26.03890     2\n5  5   90   1.84 26.58318     2\n6  6   70   1.61 27.00513     2\n\ndim(dados)\n\n[1] 6 5\n\nnames(dados)\n\n[1] \"ID\"     \"peso\"   \"altura\" \"imc\"    \"grupo\" \n\nstr(dados)\n\n'data.frame':   6 obs. of  5 variables:\n $ ID    : int  1 2 3 4 5 6\n $ peso  : num  62 70 52 98 90 70\n $ altura: num  1.7 1.82 1.75 1.94 1.84 1.61\n $ imc   : num  21.5 21.1 17 26 26.6 ...\n $ grupo : num  1 1 1 2 2 2"
  },
  {
    "objectID": "comecando_r.html#operadores-lógicos",
    "href": "comecando_r.html#operadores-lógicos",
    "title": "Appendix E — Primeiros passos no R",
    "section": "E.8 Operadores lógicos",
    "text": "E.8 Operadores lógicos\nA operação lógica nada mais é do que um teste que retorna verdadeiro (TRUE) ou falso (FALSE). Esses dois valores recebem uma classe especial: logical.\n\nIgual a: ==\n\nVamos testar se um valor é igual ao outro.\nExemplo:\n\n10==11\n\n[1] FALSE\n\n11==11\n\n[1] TRUE\n\n\nNo primeiro retornou FALSE, pois realmente 10 não é igual a 11 e no segundo caso acima retornou TRUE, pois realmente 11 é igual a 11.\nDe maneira análoga funciona para os operadores abaixo:\n\nDiferente de: !=\n\nExemplo:\n\n10!=11\n\n[1] TRUE\n\n\n\nMaior que: >\nMaior ou igual: >=\nMenor que: <\nMenor ou igual: <=\n\nExemplos:\n\n10>5\n\n[1] TRUE\n\n10>=10\n\n[1] TRUE\n\n4<4\n\n[1] FALSE\n\n4<=4\n\n[1] TRUE\n\n\n\nUm outro operador muito útil é o %in%. Com ele, podemos verificar se um valor está dentro de um vetor.\n\n\nex <- 1:15\n3 %in% ex\n\n[1] TRUE\n\n\n\nE: & - será verdadeiro se os dois forem TRUE.\n\n\nx <- 15\nx > 10 & x < 30\n\n[1] TRUE\n\nx < 10 & x < 30\n\n[1] FALSE\n\n\n\nOU: | - será verdadeiro se um dos dois forem TRUE.\n\n\nx <- 15\nx > 10 | x < 30\n\n[1] TRUE\n\nx < 10 | x < 30\n\n[1] TRUE\n\n\n\nNegação: !\n\n\nx <- 15\n!x<30\n\n[1] FALSE"
  },
  {
    "objectID": "comecando_r.html#dados-faltantes-infinitos-e-indefinições-matemáticas",
    "href": "comecando_r.html#dados-faltantes-infinitos-e-indefinições-matemáticas",
    "title": "Appendix E — Primeiros passos no R",
    "section": "E.9 Dados faltantes, infinitos e indefinições matemáticas",
    "text": "E.9 Dados faltantes, infinitos e indefinições matemáticas\n\nNA (Not Available): dado faltante/indisponível. Exemplo:\n\n\nx <- c(1,6,9)\nx[4]\n\n[1] NA\n\n\nRetornou NA porque não há elemento na posição 4 do vetor x.\n\nNaN (Not a Number): indefinições matemáticas. Como 0/0 e log(-1). Exemplo:\n\n\nlog(-10)\n\n[1] NaN\n\n\n\nInf (Infinito): número muito grande ou o limite matemático. Aceita sinal negativo (-Inf). Exemplo:\n\n\n10^14321\n\n[1] Inf"
  },
  {
    "objectID": "comecando_r.html#condicionamento-if-e-else",
    "href": "comecando_r.html#condicionamento-if-e-else",
    "title": "Appendix E — Primeiros passos no R",
    "section": "E.10 Condicionamento: If e else",
    "text": "E.10 Condicionamento: If e else\nAs estruturas if e else servem para executar um código apenas se uma condição (teste lógico) for satisfeita.\n\na <- 224\nb <- 225\nif (a==b) { \n  v <- 10\n} else {\n  v <- 15\n  }\nv\n\n[1] 15\n\n\nVeja que o R só executa o conteúdo das chaves {} se a expressão dentro dos parênteses () retornar TRUE.\nNote que a condição de igualdade é representada por dois iguais (==). Como dito anteriormente, apenas um igual (=) é símbolo de atribuição (preferível <-).\nVeja outro exemplo:\n\na <- 224\nb <- 225\nif (a==b) { \n  v <- 10\n} else if (a > b) {\n  v <- 15\n  } else {\n    v <- 25\n    }\nv\n\n[1] 25\n\n\nVeja que nesse exemplo gostaria de usar mais de duas condições, e por isso usamos a estrutura intermediária else if."
  },
  {
    "objectID": "comecando_r.html#iterador-for",
    "href": "comecando_r.html#iterador-for",
    "title": "Appendix E — Primeiros passos no R",
    "section": "E.11 Iterador for",
    "text": "E.11 Iterador for\nO for serve para repetir uma mesma tarefa para um conjunto de valores diferentes. Cada repetição é chamada de iteração.\nComo exemplo, considere o vetor atribuído ao objeto m como segue:\n\nm <- c(1,20,50,60,100)\n\nQuero criar um novo vetor, p digamos, que seja formado por cada elemento de m dividido por sua posição.\n\np <- NULL\nfor (i in 1: length(m)){\n  p[i] <- m[i]/i\n}\np\n\n[1]  1.00000 10.00000 16.66667 15.00000 20.00000\n\n\nNote que primeiro definimos o objeto p, recebendo NULL. O NULL representa a ausência de um objeto e serve para já declarar algum objeto que receberá valor na sequência. No caso, ao rodar o for, o p é um vetor de tamanho 5 (tamanho do vetor m).\nNo exemplo, temos 5 iterações e para cada valor de i, correndo de 1 até 5 (tamanho de m), pegamos o valor de m na posição i e dividimos por sua posição. Assim, formamos o vetor p."
  },
  {
    "objectID": "comecando_r.html#funções",
    "href": "comecando_r.html#funções",
    "title": "Appendix E — Primeiros passos no R",
    "section": "E.12 Funções",
    "text": "E.12 Funções\nFunções no R são nomes que guardam um código de R. A ideia é que sempre que rodar a função com os seus argumentos, o código que ela guarda será executado e o resultado será retornado.\nJá usamos anteriormente algumas funções que estão na base do R. Por exemplo, quando usamos class() para entender a classe do objeto que o R está entendendo. Colocamos um argumento dentro do parênteses e o R retornou qual a classe do objeto em questão. Relembre o que falamos ao perguntar ao R qual a classe do vetor oi criado:\n\noi <- c(10,20,2,1,0.5)\nclass(oi)\n\n[1] \"numeric\"\n\n\nAgora vamos conversar sobre outra função já criada e disponibilizada na base do R: mean. Essa função retorna a média do vetor que está em seu argumento. Vamos calcular a média dos valores do vetor oi:\n\nmean(oi)\n\n[1] 6.7\n\n\nConsidere que, por algum motivo, tenha no vetor oi uma observação faltante. No R, dado faltante é caracterizado por NA.\n\noi <- c(10,20,2,1,0.5,NA)\n\nPerceba que, apesar de NA ser um texto, não coloquei entre aspas porque quero falar para o R que naquela posição não tem valor e o R entende isso ao ler NA (sem aspas). Se colocar entre aspas, ele entenderá como sendo um texto e não mais como valor faltante.\n\nmean(oi)\n\n[1] NA\n\n\nComo não sabemos o valor do elemento na posição 6 do vetor oi, o R não teria como calcular a média de todos os 6 valores e por isso devolve NA. No entanto, queremos calcular a média dos elementos de oi ao retirar os valores faltantes, ou seja, queremos fazer: (10+20+2+1+0.5)/5. Então devemos falar para o R o que queremos, e para isso podemos utilizar o argumento na.rm = TRUE:\n\nmean(oi,na.rm = TRUE)\n\n[1] 6.7\n\n\nImportantes:\n\nSe a função tiver mais de um argumento, eles são sempre separados por vírgulas;\nCada função tem os seus próprios argumentos. Para saber quais são e como usar os argumentos de uma função, basta acessar a sua documentação. Uma forma de fazer isso é pela função help, cujo argumento é o nome da função que precisa de ajuda:\n\n\nhelp(mean)\n\nVeja que abrirá a documentação sobre a função mean no menu “Help” do RStudio, e lá é possível ver os argumentos e exemplos de uso da função em questão.\nAinda sobre funções já presentes no R, vamos considerar agora a função sample. Veja a documentação dessa função para ver o que ela faz:\n\nhelp(sample)\n\nA função sample retorna uma amostra de um vetor com tamanho especificado em um de seus argumentos com ou sem reposição. Ela apresenta quatro argumentos: sample(x, size, replace = FALSE, prob = NULL), em que: x é o vetor do qual será amostrado o número de elementos especificado no argumento size, seja com ou sem reposição (argumento replace) e com dadas probabilidades de seleção, especificadas em prob.\nQuero usar essa função para amostrar do objeto oi (x=oi) dois elementos (size=2) em uma seleção com reposição (replace = TRUE) e que a probabilidade de seleção seja a mesma para todos os elementos do vetor oi. No caso da probabilidade, como podemos ver na documentação da função sample, o default (padrão se o usuário não mudar o argumento) é ser a mesma probabilidade de seleção para todos os elementos. Assim, se o usuário nada especificar para esse argumento, o R entenderá o seu default. O mesmo vale para o argumento replace: caso fosse o interesse fazer a seleção sem reposição, não precisaríamos colocar esse argumento porque seu default é FALSE.\n\n\n\n\nsample(x=oi,size=2,replace=TRUE) #não colocamos argumento prob porque vamos usar o seu default (probs iguais).\n\n[1] 20 20\n\n\nTambém poderíamos usar a mesma função sem colocar o nome dos argumentos:\n\nsample(oi,2,TRUE) \n\n[1] 20 10\n\n\nMas, nesse caso, é importante que se respeite a ordem dos argumentos: o vetor tem que ser o primeiro, o segundo argumento é size e assim por diante.\nVale ressaltar que as duas últimas saídas não necessariamente serão as mesmas, porque é feito um sorteio aleatório de dois elementos de oi em cada uma delas.\nAlém de usar funções já prontas, podemos criar novas funções. Suponha que queremos criar uma função de dois argumentos que retorna o primeiro mais três vezes o segundo argumento. Criamos a função no que segue:\n\nf_conta <- function(x,y) {\n  out <- x+3*y\n  return(out)\n}\n\nA função acima tem:\n\no nome: f_conta;\nos argumentos: x e y;\no corpo out: <- x+3*y; e\no que retorna: return(out).\n\nSuponha que eu queira fazer a conta 10+3*20. Podemos fazer isso ao chamar a função criada f_conta.\n\nf_conta(x=10,y=20)\n\n[1] 70\n\n\nVeja que o cálculo acima retorna exatamente o mesmo que o seguinte:\n\nf_conta(y=20,x=10)\n\n[1] 70\n\n\nIsso acontece porque mudei a ordem dos argumentos, mas acompanhado com os nomes dos argumentos. Se eu não quiser colocar os nomes dos argumentos, precisa tomar cuidado para não errar a ordem deles. Pois:\n\nf_conta(10,20)\n\n[1] 70\n\n\né diferente de\n\nf_conta(20,10)\n\n[1] 50"
  },
  {
    "objectID": "tutorialr.html",
    "href": "tutorialr.html",
    "title": "Tutorial de R",
    "section": "",
    "text": "R é um ambiente computacional e uma linguagem de programação para manipulação, análise e visualização de dados. É considerado um dos melhores ambiente computacional para essa finalidade. O R é mantido pela R Development Core Team e está disponível para diferentes sistemas operacionais: Linux, Mac e Windows.\nO software é livre, ou seja, gratuito, com código aberto em uma linguagem acessível. Nele, estão implementadas muitas metodologias estatísticas. Muitas dessas fazem parte do ambiente base de R e outras acompanham o ambiente sob a forma de pacotes, o que torna o R altamente expansível. Os pacotes são bibliotecas com dados e funções para diferentes áreas do conhecimento relacionados à estatística e áreas afins, devidamente documentados.\nO R possui uma comunidade extremamente ativa, engajada desde o aprimoramento de ferramentas e desenvolvimento de novas bibliotecas, até o suporte aos usuários. Sobre o desenvolvimento de novas bibliotecas, um pesquisador em Estatística que desenvolve um novo modelo estatístico pode disponibilizá-lo em um pacote acessível a que se interessam pelo modelo.\nAlém disso, a disponibilidade e compartilhamento da pesquisa em um pacote no R é uma boa prática quando falamos de reprodutibilidade na Ciência. Ainda nesse ponto, realizar as análises de uma pesquisa aplicada em um programa livre e acessível a todos é um dos principais pontos para permitir reprodutibilidade.\nAo optar por programar em R também implica na escolha de uma IDE (Integrated Development Environment) que, na grande maioria dos casos, será o RStudio. O RStudio é um conjunto de ferramentas integradas projetadas para editar e executar os códigos em R. Assim, quando for o interesse utilizar o R, só precisa abrir o RStudio (R é automaticamente carregado).\nPara instalação do R e do RStudio, veja a Seção que segue."
  },
  {
    "objectID": "intro.html#bases-de-dados",
    "href": "intro.html#bases-de-dados",
    "title": "1  Introdução",
    "section": "1.1 Bases de dados",
    "text": "1.1 Bases de dados\nOs dados considerados nas aplicações deste livro são provenientes do Sistema de Informação da Vigilância Epidemiológica da Gripe (SIVEP-Gripe), sistema oficial para o registro dos casos e óbitos por Síndrome Respiratória Aguda Grave (SRAG) disponibilizado pelo Ministério da Saúde. Os dados correspondem a registros de gestantes e puérperas de 10 a 55 anos hospitalizadas com SRAG por COVID-19 confirmada por teste de PCR. O conjunto de dados é utilizado para ilustrar e demonstrar diversos aspectos dos conceitos abordados no texto, e pode ser baixado em https://github.com/observatorioobstetrico/dados_livro_cd_saude.\n\n1.1.1 Dados de COVID-19 em gestantes e puérperas\nEssa base consiste em 11.523 registros de gestantes e puérperas diagnosticadas com COVID-19 no período de março de 2020 a dezembro de 2021. Alguns estudos conduzidos pelo OOBr usaram esses dados, dentre os quais podem ser citados: Características demográficas e epidemiológicas sobre mulheres grávidas e puérperas que morreram de Síndrome Respiratória Aguda Grave no Brasil, Mortalidade materna associada à COVID-19 no Brasil em 2020 e 2021: comparação com mulheres não grávidas e homens e Desfechos da COVID-19 em puérperas, gestantes e mulheres não gestantes e nem puérperas hospitalizadas.\nO dicionários das variáveis a ser considerado neste livro está na Tabela 1.1.\n\n\nTabela 1.1: Dicionário das variáveis da base de dados de COVID-19 em gestantes e puérperas.\n\n\n\n\n\n\n\nVariável\nDescrição\nValores\n\n\n\n\nDT_NOTIFIC\nData de preenchimento da ficha de notificação\nDia/Mês/Ano\n\n\nDT_SIN_PRI\nData de primeiros sintomas do caso\nDia/Mês/Ano\n\n\nDT_NASC\nData de nascimento da gestante ou puérpera\nDia/Mês/Ano\n\n\nDT_INTERNA\nData em que gestante ou puérpera foi hospitalizada\nDia/Mês/Ano\n\n\nSEM_PRI\nSemana epidemiológica do início dos sintomas\n1 a 52\n\n\nCS_RACA\nRaça da gestante ou puérpera\n1- branca; 2- preta; 3- amarela; 4- parda; 5-indígena; 9- ignorado\n\n\nCS_ESCOL_N\nNível de escolaridade da gestante ou puérpera\n0- sem escolaridade (analfabeto); 1- fundamental 1° ciclo (1ª a 5ª série); 2- fundamental 2 (6ª a 9ª série); 3- medio (1° ao 3° ano); 4- superior; 5- não se aplica; 9- ignorado\n\n\nidade\nIdade, em anos, da gestante ou puérpera\n10 a 55\n\n\nCS_GESTANT\nMomento gestacional ou puerpério\n1- 1° trimestre; 2- 2° trimestre; 3- 3° trimestre; 4- idade gestacional ignorada; 5- não; 9- ignorado\n\n\nPUERPERA\nSe paciente é puérpera ou parturiente (mulher que pariu recentemente - até 45 dias do parto)\n1- sim; 2- não; 9- ignorado\n\n\nSG_UF\nSigla do estado de residência da gestante ou puérpera\nSigla padronizada pelo IBGE\n\n\nID_MN_RESI\nNome do município de residência da gestante ou puérpera\nNomes padronizados pelo IBGE\n\n\nCO_MUN_RES\nCódigo do município de residência da gestante ou puérpera\nCódigo definido pelo IBGE\n\n\nCS_ZONA\nTipo de zona de residência da gestante ou puérpera\n1- urbana; 2- rural; 3- periurbana; 9- ignorado\n\n\nFEBRE\nSe gestante ou puérpera manifestou sintoma de febre\n1- sim; 2- não; 9- ignorado\n\n\nTOSSE\nSe gestante ou puérpera manifestou sintoma de tosse\n1- sim; 2- não; 9- ignorado\n\n\nGARGANTA\nSe gestante ou puérpera manifestou sintoma de dor de garganta\n1- sim; 2- não; 9- ignorado\n\n\nDISPNEIA\nSe gestante ou puérpera manifestou sintoma de dispneia\n1- sim; 2- não; 9- ignorado\n\n\nDESC_RESP\nSe gestante ou puérpera manifestou sintoma de desconforto respiratório\n1- sim; 2- não; 9- ignorado\n\n\nSATURACAO\nSe gestante ou puérpera manifestou sintoma de saturação\n1- sim; 2- não; 9- ignorado\n\n\nDIARREIA\nSe gestante ou puérpera manifestou sintoma de diarreia\n1- sim; 2- não; 9- ignorado\n\n\nVOMITO\nSe gestante ou puérpera manifestou sintoma de vômito\n1- sim; 2- não; 9- ignorado\n\n\nDOR_ABD\nSe gestante ou puérpera manifestou sintoma de dor abdominal\n1- sim; 2- não; 9- ignorado\n\n\nFADIGA\nSe gestante ou puérpera manifestou sintoma de fadiga\n1- sim; 2- não; 9- ignorado\n\n\nPERD_OLFT\nSe gestante ou puérpera manifestou sintoma de perda de olfato\n1- sim; 2- não; 9- ignorado\n\n\nPERD_PALA\nSe gestante ou puérpera manifestou sintoma de perda de paladar\n1- sim; 2- não; 9- ignorado\n\n\nASMA\nSe gestante ou puérpera tem asma\n1- sim; 2- não; 9- ignorado\n\n\nDIABETES\nSe gestante ou puérpera tem diabetes mellitus\n1- sim; 2- não; 9- ignorado\n\n\nNEUROLOGIC\nSe gestante ou puérpera tem doença neurológica\n1- sim; 2- não; 9- ignorado\n\n\nPNEUMOPATI\nSe gestante ou puérpera tem outra pneumopatia crônica\n1- sim; 2- não; 9- ignorado\n\n\nIMUNODEPRE\nSe gestante ou puérpera tem imunodeficiência ou imunodepressão (diminuição da função do sistema imunológico)\n1- sim; 2- não; 9- ignorado\n\n\nRENAL\nSe gestante ou puérpera tem doença renal crônica\n1- sim; 2- não; 9- ignorado\n\n\nOBESIDADE\nSe gestante ou puérpera tem obesidade\n1- sim; 2- não; 9- ignorado\n\n\nCARDIOPATI\nSe gestante ou puérpera tem doença cardiovascular crônica\n1- sim; 2- não; 9- ignorado\n\n\nHEMATOLOGI\nSe gestante ou puérpera tem doença hematológica crônica\n1- sim; 2- não; 9- ignorado\n\n\nHEPATICA\nSe gestante ou puérpera tem doença hepática crônica\n1- sim; 2- não; 9- ignorado\n\n\nVACINA_COV\nSe gestante ou puérpera recebeu vacina COVID-19\n1- sim; 2- não; 9- ignorado\n\n\nDOSE_1_COV\nData em que gestante ou puérpera recebeu a 1ª dose da vacina COVID-19\nDia/Mês/Ano\n\n\nDOSE_2_COV\nData em que gestante ou puérpera recebeu a 2ª dose da vacina COVID-19\nDia/Mês/Ano\n\n\nFAB_COV_1\nFabricante da vacina que a gestante ou puérpera recebeu na 1ª dose\n\n\n\nFAB_COV_2\nFabricante da vacina que a gestante ou puérpera recebeu na 2ª dose\n\n\n\nSUPORT_VEN\nSe gestante ou puérpera precisou de ventilação mecânica; se sim, se foi invasiva ou não\n1- sim, invasivo; 2- sim, não invasivo; 3- não; 9- ignorado\n\n\nUTI\nSe gestante ou puérpera foi internada na UTI\n1- sim; 2- não; 9- ignorado\n\n\nDT_ENTUTI\nData de entrada da gestante ou puérpera na UTI\nDia/Mês/Ano\n\n\nDT_SAIDUTI\nData de saída da gestante ou puérpera na UTI\nDia/Mês/Ano\n\n\nEVOLUCAO\nEvolução do caso da gestante ou puérpera\n1- cura; 2- óbito; 3- óbito por outras causas; 9- ignorado"
  },
  {
    "objectID": "tabulacao.html#variáveis",
    "href": "tabulacao.html#variáveis",
    "title": "3  Tabulação de dados",
    "section": "3.1 Variáveis",
    "text": "3.1 Variáveis\nOs objetos apresentados, ou variáveis, podem ser denotados como o armazenamento de informações sobre a característica de interesse a respeito de cada unidade amostral, variáveis socioeconômicas como raça, renda e escolaridade são um ótimo exemplo. As variáveis podem ser divididas em dois tipos:\n\nVariáveis Qualitativas: cujos valores podem ser separados por categorias não numéricas. Sendo chamadas de variáveis qualitativas ordinais quando há presença de uma ordenação entre as categorias (Ex.: Escolaridade), e variáveis qualitativas nominais caso contrário (Ex.: Raça, Sexo)\nVariáveis Quantitativas: onde os valores são expressos em números resultantes de uma contagem ou mensuração. Podendo ser quantitativas discretas, quando resultam de um conjunto finito ou enumerável de possíveis valores (Ex.: Número de vitórias ou de filhos), ou ainda variáveis quantitativas continuas quando assumem valores em uma escala continua (Ex.: Peso, Altura).\n\nObserve as 10 unidades amostrais para as variáveis da base de dados COVID-19 para melhor compreensão, onde a idade representa variável quantitativa discreta, a raça represeta qualitativa nominal e a escolaridade é relativa a qualitativa ordinal.\n\n\n\n\n\n\nidade_anos\nraca\nescol\n\n\n\n\n5\n39\nparda\nsuperior\n\n\n6\n34\nbranca\nsuperior\n\n\n8\n29\nbranca\nmedio\n\n\n11\n28\nbranca\nmedio\n\n\n13\n37\nparda\nfund2\n\n\n16\n27\nbranca\nmedio\n\n\n17\n44\nbranca\nmedio\n\n\n23\n31\nbranca\nmedio\n\n\n24\n33\namarela\nmedio\n\n\n25\n25\nparda\nmedio\n\n\n\n\n\nPodemos olhar uma variável por outra perspectiva, assumindo um outro tipo de classificação. Isso pode soar um pouco estranho a princípio, mas olher o exemplo a seguir para melhor compreensão, considere a variável idade, podemos transformar em faixas de idade para classificação em criança, jovem, adulto e idoso. Observe:\n\n#criacao da variavel classificacao\nclassificacao <- idade_anos |>\n  lapply(function(x) ifelse(x < 12, 'crianca',\n                            ifelse(x < 25, 'jovem',\n                                   ifelse( x < 60 ,'adulto','idoso'))))\n#tabela concatenando idade e classificacao\nclassificacao |> \n  unlist() |> \n  cbind(idade_anos) |> \n  head(10) |> knitr::kable()\n\n\n\n\n\nidade_anos\n\n\n\n\njovem\n24\n\n\nadulto\n31\n\n\nadulto\n27\n\n\njovem\n20\n\n\nadulto\n39\n\n\nadulto\n34\n\n\nadulto\n34\n\n\nadulto\n29\n\n\nadulto\n44\n\n\nadulto\n27\n\n\n\n\n\nAgora, temos uma variável categórica ordinal."
  },
  {
    "objectID": "tabulacao.html#como-tabular",
    "href": "tabulacao.html#como-tabular",
    "title": "3  Tabulação de dados",
    "section": "3.2 Como tabular",
    "text": "3.2 Como tabular\nÉ perceptível, até mesmo quando trabalhamos com DataFrames e matrizes, a forma proposta de visualização e armazenamento dessas variáveis. Por colunas onde cada coluna representa uma das características (no nosso exemplo, idade, raça e escolaridade).\nFazemos isso de forma a facilitar nossa análise, sendo cada linha um indíviduo e, cada uma das observações dentro dessa linha, suas características.\nAssim como discutido, podemos obter nossas bases de dados de diversas fontes, como planilhas excel, arquivos .csv, bases SQL, ou até mesmo criá-las no nosso próprio R script com a função data.frame() como já apresentado. Por ser mais intuitivo e mais utilizado no dia a dia, vamos tomar o excel para exemplificar todo o processo. Você irá notar que o processo é realizado de forma bem simples.\n\n\n\n\n\nTabulação das variáveis no excel\n\n\n\n\nCada uma das células receberá um valor x referente a alguma característica indicada pela coluna e um indivíduo representado pela linha, em nosso caso temos 3 características para cada uma das 4 observações."
  },
  {
    "objectID": "tabulacao.html#alguns-problemas-no-meio-do-caminho",
    "href": "tabulacao.html#alguns-problemas-no-meio-do-caminho",
    "title": "3  Tabulação de dados",
    "section": "3.3 Alguns problemas no meio do caminho",
    "text": "3.3 Alguns problemas no meio do caminho\nÉ valido ressaltar que é possível se deparar com alguns problemas que talvez possam vir a ser solucionados da maneira errada.\nA forma como tabulamos nossos dados pode vir a ser um facilitar ou empecilho em nossas análises, um belo exemplo é a forma citada anteriormente de classificação dos dados ou transformação para que sejam salvos em alguma outra categoria, como faixa etária ou idade.\nOutro problema é quando trabalhamos com dados que possas vir a ter mais de uma resposta. Por exemplo: Quais sintomas estava sentindo? O melhor a se fazer nesse caso é criar uma coluna para cada um dos possíveis sintomas.\n\n\n\n\n\nMais de uma opção de escolha na variável\n\n\n\n\nUma outra forma seria:\n\n\n\n\n\nMais de uma opção de escolha na variável, outra forma\n\n\n\n\nDevemos lembrar sempre de anexar um ID ou forma de identificação única para cada uma das observações. É possível criar uma ou trabalhar com alguma já existente, um exemplo de uma já existente é o próprio CPF ou RG quando trabalhamos com pessoas.\nVale ressaltar outras boas práticas ao realizar a tabulação:\n\nSe trabalhando com Excel ou Softwares parecidos, deixe a planilha apenas com a tabela de dados, evite armazenar na mesma planilha várias informações avulssas que não façam parte da sua tabela;\nNo R conseguimos especificar qual planilha de um arquivo .xlsx queremos transferir, porém pode vir a ser um pouco confuso as vezes, então é sugerido deixar todas as suas informações em uma única tabela em uma única planilha;\nPadronização é extremamente importante, salve todos os dados para cada coluna em apenas um determinado formato (Ex.: Coluna Idade - Integer, Coluna Raça - Character), lembrando sempre de manter um padrão de medida (cm, L), variáveis do tipo categórico tambem precisam de padronização (Evite coisas como: Não, nao, n, N, não);\nCuidado ao classificar dados faltantes, uma prática errada é preencher esses dados com 0, isso pode vir a atrapalhar toda sua análise\nFoi citado CPF como forma de identificação, mas pode haver casos em que teremos mais de uma linha contendo um mesmo indivíduo dependendo do nosso tipo de dados. Ou seja, esteja atento para que não haja duplicidade de variável identificadora ou ID."
  },
  {
    "objectID": "manipulacao_dados.html",
    "href": "manipulacao_dados.html",
    "title": "2  Manipulação de dados",
    "section": "",
    "text": "Neste capítulo falaremos alguns princípios básicos sobre manipulação de dados. Iremos trabalhar em um cenário mais próximo da realidade possível, ou seja, iremos trabalhar em cima de uma base de dados real. O objetivo é manipular a base e torná-la pronta para ser usada nos capítulos seguintes. Será mostrado desde como importar a base até como criar novas variáveis que poderão ser utilizadas em análises. Não será possível cobrir todo o ramo de manipulação em um só capítulo, mas iremos trabalhar com o máximo de ferramentas possíveis. Pacotes ou funções que não forem utilizadas aqui, mas que são interessantes serão mencionados ao longo do capítulo junto a links que contenham explicações de como utilizá-las. Vale ressaltar que estamos em um cenário mais básico e introdutório. Vamos começar.\n\n2.0.1 Importação de dados\nUm dos caminhos mais simples para importar dados no R é utilizando a função read.table(). Está função é simples pois ja vem instalada com o R, faz parte do pacote base utils, e importa arquivos nos formatos cvs e txt.\nA utilização do pacote é bem simples, não preciso carregá-lo na memória usando library().\n\ndados1 <- read.table(file = \"dados.csv\", sep = \";\")\ndados2 <- read.table(file = \"caminho-para-o-arquivo/dados.csv\", sep = \";\")\n\nObserve que na função temos os argumentos file e sep. O file indica o nome do arquivo que será importado e sep indica qual o símbolo separador de colunas, que neste caso é a virgula. Note também que usamos dois exemplos, o primeiro considera que o seu arquivo está no diretório de trabalho (quando criamos o projeto e colocamos os arquivos de dados na pasta criada pelo projeto), não sendo necessário especificar o caminho até do arquivo. O outro exemplo mostra como especificar o local do seu arquivo. A função possui mais argumentos que você pode explorar usando o help, mas no geral, esses dois são os mais utilizados.\n\n2.0.1.1 Extensão .txt ou .csv\nCaso esteja trabalhando com arquivos do tipo cvs ou txt o pacote readr irá servir muito bem. As funções deste pacote são bem rapidas e algumas delas são focadas em tranformar arquivos simples em data.frame. Aglumas funções do pacote são\n\nread_cvs(): para arquivos delimitados por vírgulas.\nread_cvs2(): para arquivos delimitados por ponto e vírgula.\nread_tsv(): para arquivos delimitados por tabulações.\nread_delim(): para aquivos com qualquer delimitador.\nread_fwf(): para arquivos compactos que devem ter a largura de cada coluna especificada.\nread_table(): para arquivos de texto tabulas com colunas separas por espaço.\n\nCaso esta seja a primeira vez que você ira utilizar este pacote, será necessário instalá-lo em seu computar. Você pode fazer isso utilizando a função install.packages(\"readr\") e é claro, antes de usar qualquer pacote que não faça parte do R base, você deve carregá-lo. Como exemplo, consideramos um arquivo chamado dados1 que queremos importar para o R.\n\nlibrary(readr)\ndados_csv <- read_csv(file = \"caminho-para-o-arquivo/dados1.csv\")\ndados_txt <- read_delim(file = \"caminho-para-o-arquivo/dados1.txt\", delim = \" \")\n\nApesar dos argumentos deste pacote serem semelhantes aos da função read.table(), devemos nos atentar a algumas diferenças. Aqui é o argumento delim que indica qual o separador das colunas no arquivo texto.\nVale ressaltar que para cada função read_, existe umas respectiva função write_ para exportar o arquivo no formato de interesse. Como exemplo, queremos salvar a base de dados mtcars na pasta do meu computador com o nome cars:\n\nwrite_csv(x = mtcars, path = \"cars.csv\")\nwrite_delim(x = mtcars, delim = \" \", path = \"cars.txt\")\n\n\n\n2.0.1.2 Arquivos em Excel\nArquivos em formato xlsx são muito utilizados, porém o R não possui uma função nativa para importar este tipo de arquivo. Existem diversos pacotes para importar dados neste e formato e os principais são redxl, xlsx, XLConnect e tydixl. Apesar destes pacotes terem objetivos semelhantes, cada um tem suas peculiaridades, então aconselhamos estudar cada um desses pacotes e assim decidir qual melhor atende às suas necessidades. Aqui vamos mostrar apenas o pacote readxl, pois é um dos mais facéis e diretos de se utilizar. Este pacote serve para importar e ler planilhas do Excel nos formatos xlsx ou xls. A seguir estão listadas algumas funções para importação e leitura de dados:\n\nread_excel(): esta função detecta automaticamente a extensão do arquivo, e importa arquivos do tipo xsl e xlsx.\nread_xsl(): importa arquivos no formato xsl.\nread_xlsx(): importa arquivos no formato xlsx.\n\nNovamente, é necessário à instalação e carregamento do pacote caso não o tenha em seu computador. Para exemplicar consideramos um arquivo chamado dados2 que queremos importar para o R.\n\nlibrary(readxl)\ndados_excel1 <- read_excel(path = \"dados2.xls\")\ndados_excelx1 <- read_excel(path = \"dados2.xlsx\")\n\nPor meio da função read_excel conseguimos importar tanto um arquivo no formato xls quanto no formato xlsx.\nPodemos também exportar um arquivo em excel (.xls e .xlsx) ao considerar a função write_xlsx do pacote writexl. Suponha que temos o interesse em salvar a base de dados dados em excel na pasta do computador (exportar) com o nome de dados_correto:\n\nlibrary(writexl)\nwrite_xlsx(dados, \"dados_correto.xlsx\")\n\n\n\n\n2.0.2 Análise de consistência e tratamento de dados\nO tratamento dos dados toma muitas vezes a maior parte do tempo de uma análise estatística.\nA análise de consistência consiste em realizar uma primeira análise dos dados com o intuito de encontrar inconsistências. São exemplos de inconsistências:\n\nboas práticas para nome das variáveis.\ncomo erros de digitação;\nindivíduos imputados mais de uma vez na planilha de dados de maneira errada;\nidentificar casos missings e avaliar se a observação está ausente de maneira correta ou não;\nidentificar as categorias de variáveis qualitativas.\n\nA partir daqui iremos trabalhar com a nossa base de dados de COVID-19 em gestantes e puérperas.\nImportando os dados\nComo já aprendemos a importar os dados, vamos direto ao ponto. Nos dados estão no forma rds que não foi mencionado anteriormente, mas o pacote readr tem uma função para importar este tipo de arquivo.\n\ndados <- readr::read_rds(\"dados/dados_covid[SUJO].rds\")\nknitr::kable(head(dados))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDT_NOTIFIC\nDT_SIN_PRI\nDT_NASC\nDT_INTERNA\nSEM_PRI\nSG_UF\nID_MN_RESI\nCO_MUN_RES\nCS_ZONA\nCS_RACA\nCS_ESCOL_N\nidade\nCS_GESTANT\nPUERPERA\nFEBRE\nTOSSE\nGARGANTA\nDISPNEIA\nDESC_RESP\nSATURACAO\nDIARREIA\nVOMITO\nFADIGA\nPERD_OLFT\nPERD_PALA\nDOR_ABD\nCARDIOPATI\nHEMATOLOGI\nHEPATICA\nASMA\nDIABETES\nNEUROLOGIC\nPNEUMOPATI\nIMUNODEPRE\nRENAL\nOBESIDADE\nVACINA_COV\nDOSE_1_COV\nDOSE_2_COV\nFAB_COV_1\nFAB_COV_2\nDT_ENTUTI\nDT_SAIDUTI\nUTI\nSUPORT_VEN\nEVOLUCAO\n\n\n\n\n15/05/2020\n06/05/2020\n03/06/2003\n15/05/2020\n19\nCE\nMORRINHOS\n230890\nNA\n4\nNA\n16\n2\nNA\n1\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n2\n2\n1\n\n\n18/05/2020\n10/05/2020\n07/07/1996\n15/05/2020\n20\nPR\nCURITIBA\n410690\n1\n1\n2\n23\n2\n2\n2\n2\n2\n1\n2\n2\n1\n2\nNA\nNA\nNA\nNA\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\nNA\nNA\nNA\nNA\nNA\n\n\n2\n3\n1\n\n\n30/04/2020\n20/04/2020\n26/03/1996\n24/04/2020\n17\nSP\nSAO CAETANO DO SUL\n354880\n1\n9\n9\n24\n9\n1\n1\n2\n2\n2\n2\n2\n2\n2\nNA\nNA\nNA\nNA\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\nNA\nNA\nNA\nNA\nNA\n\n\n2\n3\n1\n\n\n11/05/2020\n04/05/2020\n02/06/1986\n09/05/2020\n19\nPA\nMARABA\n150420\n1\n4\n4\n33\n5\n1\n1\n1\n2\n2\n1\n2\n2\n2\nNA\nNA\nNA\nNA\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\nNA\nNA\nNA\nNA\nNA\n\n\n2\n2\n1\n\n\n01/07/2020\n12/06/2020\n11/12/1996\n30/06/2020\n24\nDF\nSANTA MARIA\n530150\n1\n9\nNA\n23\n5\n1\n2\n2\n2\n2\n2\n2\n1\n2\nNA\n1\nNA\nNA\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\nNA\nNA\nNA\nNA\nNA\n\n\n2\n3\n1\n\n\n09/06/2020\n09/06/2020\n09/12/1984\n09/06/2020\n24\nRO\nPORTO VELHO\n110020\n1\n4\n2\n35\n3\n2\n1\n1\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\nNA\nNA\nNA\nNA\nNA\n\n\n2\n3\n1\n\n\n\n\n\n\n2.0.2.1 Tratamento da base de dados\nInicialmente, vamos verificar os nomes das variáveis na base de dados por meio da função names. Note que os nomes estão, de certa forma, padronizados. Todos maíusculos (com exceção de “idade”), separados por “_”. Este ainda não é o cenário ideal para trabalharmos, mas poderia ser pior, contendo maiúsculas, espaços e acentos. Utilizar os dados com essas características não impossibilita as futuras análises, mas pode atrapalhar quando precisamos selecionar algumas dessas variáveis.\n\nnames(dados)\n\n [1] \"DT_NOTIFIC\" \"DT_SIN_PRI\" \"DT_NASC\"    \"DT_INTERNA\" \"SEM_PRI\"   \n [6] \"SG_UF\"      \"ID_MN_RESI\" \"CO_MUN_RES\" \"CS_ZONA\"    \"CS_RACA\"   \n[11] \"CS_ESCOL_N\" \"idade\"      \"CS_GESTANT\" \"PUERPERA\"   \"FEBRE\"     \n[16] \"TOSSE\"      \"GARGANTA\"   \"DISPNEIA\"   \"DESC_RESP\"  \"SATURACAO\" \n[21] \"DIARREIA\"   \"VOMITO\"     \"FADIGA\"     \"PERD_OLFT\"  \"PERD_PALA\" \n[26] \"DOR_ABD\"    \"CARDIOPATI\" \"HEMATOLOGI\" \"HEPATICA\"   \"ASMA\"      \n[31] \"DIABETES\"   \"NEUROLOGIC\" \"PNEUMOPATI\" \"IMUNODEPRE\" \"RENAL\"     \n[36] \"OBESIDADE\"  \"VACINA_COV\" \"DOSE_1_COV\" \"DOSE_2_COV\" \"FAB_COV_1\" \n[41] \"FAB_COV_2\"  \"DT_ENTUTI\"  \"DT_SAIDUTI\" \"UTI\"        \"SUPORT_VEN\"\n[46] \"EVOLUCAO\"  \n\n\numa boa prática consiste em padronizar os nomes das variáveis, até para facilitar a lembrança deles. Para isso, utilizaremos o pacote janitor para a arrumação da base de dados. Usamos a função clean_names() para primeiro ajuste dos nomes das variáveis.\n\ndados <- janitor::clean_names(dados) \nnames(dados)\n\n [1] \"dt_notific\" \"dt_sin_pri\" \"dt_nasc\"    \"dt_interna\" \"sem_pri\"   \n [6] \"sg_uf\"      \"id_mn_resi\" \"co_mun_res\" \"cs_zona\"    \"cs_raca\"   \n[11] \"cs_escol_n\" \"idade\"      \"cs_gestant\" \"puerpera\"   \"febre\"     \n[16] \"tosse\"      \"garganta\"   \"dispneia\"   \"desc_resp\"  \"saturacao\" \n[21] \"diarreia\"   \"vomito\"     \"fadiga\"     \"perd_olft\"  \"perd_pala\" \n[26] \"dor_abd\"    \"cardiopati\" \"hematologi\" \"hepatica\"   \"asma\"      \n[31] \"diabetes\"   \"neurologic\" \"pneumopati\" \"imunodepre\" \"renal\"     \n[36] \"obesidade\"  \"vacina_cov\" \"dose_1_cov\" \"dose_2_cov\" \"fab_cov_1\" \n[41] \"fab_cov_2\"  \"dt_entuti\"  \"dt_saiduti\" \"uti\"        \"suport_ven\"\n[46] \"evolucao\"  \n\n\nVeja que ele deixou todos os nomes minúsculos. Neste caso não foi feito, mas a função substitui o espaço por “_” e tira acentos. Isso ajuda a evitar problemas futuros em algumas análises que não lidam muito bem com acentos e espaços nos nomes das variáveis.\nOutro problema comum é a presença de linhas e colunas vazias. Na base de dados em questão, não há linhas nem colunas em branco, como pode ser visto na saída abaixo.\n\njanitor::remove_empty(dados,\"rows\")\njanitor::remove_empty(dados,\"cols\")\n\n\n\n2.0.2.2 \nIdentificando casos duplicados\nOutra boa prática é identificar casos duplicados, isto é, identificar se há casos erroneamente repetidos. O ideal é utilizar variável chave do seu banco de dados, ou seja, aquela em que cada observação é única. Por exemplo, em uma base de dados de funcionários de uma empresa, uma variável chave poderia ser o CPF. Uma variável chave também pode ser a combinação de variáveis, gerando assim observações únicas. Para identificar casos duplicados, usamos a função get_dupes do pacote janitor. Em nosso banco de dados não tempos uma varíavel chave, então não vamos especificá-la na função, assim a função irá procurar observações repetidas considerando todas as variáveis, ou seja, linhas repetidas.\n\njanitor::get_dupes(dados)\n\nNo variable names specified - using all columns.\n\n\nNo duplicate combinations found of: dt_notific, dt_sin_pri, dt_nasc, dt_interna, sem_pri, sg_uf, id_mn_resi, co_mun_res, cs_zona, ... and 37 other variables\n\n\n [1] dt_notific dt_sin_pri dt_nasc    dt_interna sem_pri    sg_uf     \n [7] id_mn_resi co_mun_res cs_zona    cs_raca    cs_escol_n idade     \n[13] cs_gestant puerpera   febre      tosse      garganta   dispneia  \n[19] desc_resp  saturacao  diarreia   vomito     fadiga     perd_olft \n[25] perd_pala  dor_abd    cardiopati hematologi hepatica   asma      \n[31] diabetes   neurologic pneumopati imunodepre renal      obesidade \n[37] vacina_cov dose_1_cov dose_2_cov fab_cov_1  fab_cov_2  dt_entuti \n[43] dt_saiduti uti        suport_ven evolucao   dupe_count\n<0 rows> (or 0-length row.names)\n\n\nEm nosso caso, não temos casos duplicados. Caso tivesse, seria necessário remover as linhas duplicadas. Isto pode ser feito com o uso da função distinct do pacote dplyr.\n\n\n\n2.0.3 Identificar problemas nas variáveis da base de dados\nOutra etapa importante na análise de consistência é identificar o tipo de variável e ver se o R está interpretando corretamente o tipo de cada variável.\nTemos na nossa base de dados variáveis de data, além de variáveis qualitativas e quantitativas (veja o dicionário das variáveis na em: refenciar parte). Assim, precisamos entender se o R realmente entendeu todas as variáveis da maneira correta. Uma maneira de identificar isso e também de ver algumas descritivas das variáveis que nos auxiliam a ver possíveis inconsistências na base de dados é a a função glimpse do pacote dplyr. A função skim do pacote skimr também pode ajudar nisso.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nglimpse(dados)\n\nRows: 11,523\nColumns: 46\n$ dt_notific <chr> \"15/05/2020\", \"18/05/2020\", \"30/04/2020\", \"11/05/2020\", \"01…\n$ dt_sin_pri <chr> \"06/05/2020\", \"10/05/2020\", \"20/04/2020\", \"04/05/2020\", \"12…\n$ dt_nasc    <chr> \"03/06/2003\", \"07/07/1996\", \"26/03/1996\", \"02/06/1986\", \"11…\n$ dt_interna <chr> \"15/05/2020\", \"15/05/2020\", \"24/04/2020\", \"09/05/2020\", \"30…\n$ sem_pri    <int> 19, 20, 17, 19, 24, 24, 26, 27, 28, 24, 14, 29, 28, 10, 36,…\n$ sg_uf      <chr> \"CE\", \"PR\", \"SP\", \"PA\", \"DF\", \"RO\", \"PI\", \"RS\", \"PE\", \"MA\",…\n$ id_mn_resi <chr> \"MORRINHOS\", \"CURITIBA\", \"SAO CAETANO DO SUL\", \"MARABA\", \"S…\n$ co_mun_res <int> 230890, 410690, 354880, 150420, 530150, 110020, 221100, 431…\n$ cs_zona    <int> NA, 1, 1, 1, 1, 1, 1, 1, 1, 1, NA, 1, 1, 1, NA, 1, 1, NA, 2…\n$ cs_raca    <int> 4, 1, 9, 4, 9, 4, 9, 1, 4, 9, 4, 4, 4, 4, 4, 9, 4, 9, 4, 4,…\n$ cs_escol_n <int> NA, 2, 9, 4, NA, 2, 4, 2, NA, NA, NA, 9, 9, 3, 3, NA, 3, NA…\n$ idade      <dbl> 16, 23, 24, 33, 23, 35, 31, 17, 22, 29, 28, 22, 27, 25, 26,…\n$ cs_gestant <int> 2, 2, 9, 5, 5, 3, 1, 5, 3, 3, 4, 3, 5, 3, 3, 3, 3, 9, 3, 3,…\n$ puerpera   <int> NA, 2, 1, 1, 1, 2, NA, 1, NA, 1, NA, NA, 1, 2, 1, NA, NA, 1…\n$ febre      <int> 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, NA, 1, 1, 1, 1, 1, 1, 1, 1…\n$ tosse      <int> 1, 2, 2, 1, 2, 1, 1, 1, NA, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1…\n$ garganta   <int> NA, 2, 2, 2, 2, 2, 2, NA, 1, NA, 2, NA, 2, 1, 1, 2, 2, NA, …\n$ dispneia   <int> NA, 1, 2, 2, 2, 2, 2, 1, NA, NA, 1, NA, 2, 1, 2, 1, 1, NA, …\n$ desc_resp  <int> NA, 2, 2, 1, 2, 2, 1, 1, NA, 1, 1, NA, 2, 1, 2, 2, 1, NA, 1…\n$ saturacao  <int> NA, 2, 2, 2, 2, 2, 2, 1, NA, NA, 2, NA, 2, 2, 2, 1, 1, NA, …\n$ diarreia   <int> NA, 1, 2, 2, 1, 2, 2, 1, NA, NA, 2, NA, 2, 1, 2, 2, 2, NA, …\n$ vomito     <int> NA, 2, 2, 2, 2, 2, 2, 2, NA, NA, 2, NA, 2, 1, 2, 2, 2, NA, …\n$ fadiga     <int> NA, NA, NA, NA, NA, 2, NA, NA, NA, NA, 2, NA, NA, 2, 2, 2, …\n$ perd_olft  <int> NA, NA, NA, NA, 1, 2, NA, NA, NA, NA, 2, NA, NA, 1, 2, 1, 2…\n$ perd_pala  <int> NA, NA, NA, NA, NA, 2, NA, NA, NA, NA, 2, NA, NA, 1, 2, 2, …\n$ dor_abd    <int> NA, NA, NA, NA, NA, 2, NA, NA, NA, NA, 2, NA, NA, 2, 2, 2, …\n$ cardiopati <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 1, NA, NA, …\n$ hematologi <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ hepatica   <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ asma       <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ diabetes   <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ neurologic <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 1, NA, NA, …\n$ pneumopati <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ imunodepre <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ renal      <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ obesidade  <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ vacina_cov <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ dose_1_cov <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ dose_2_cov <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ fab_cov_1  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ fab_cov_2  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ dt_entuti  <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"30/06/2020\", \"\", \"12/07/2020\",…\n$ dt_saiduti <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"29/07/2020\", \"\", \"\", \"\", \"\", \"…\n$ uti        <int> 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, NA, 2…\n$ suport_ven <int> 2, 3, 3, 2, 3, 3, 9, 1, 3, 3, 3, 3, 3, 2, 3, 2, 1, 2, 3, 2,…\n$ evolucao   <int> 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, NA, 1, 1, 1, 1, 1, 1…\n\n\nNo R, as variáveis qualititativas são nomeadas “factor”, as variáveis quantitativas são nomeadas “numeric” e as variáveis de data são “date”. Note que na importação dos dados o R não entendeu corretamente os tipos de variáveis. Mas vamos corrigir isso no que segue.\nComeçando pela data, vamos rodar o seguinte código:\n\ndados$dt_notific  <- as.Date(dados$dt_notific, format = \"%d/%m/%Y\")\ndados$dt_sin_pri  <- as.Date(dados$dt_sin_pri, format = \"%d/%m/%Y\")\ndados$dt_nasc  <- as.Date(dados$dt_nasc, format = \"%d/%m/%Y\")\ndados$dt_interna  <- as.Date(dados$dt_interna, format = \"%d/%m/%Y\")\ndados$dt_entuti  <- as.Date(dados$dt_entuti, format = \"%d/%m/%Y\")\ndados$dt_saiduti  <- as.Date(dados$dt_saiduti, format = \"%d/%m/%Y\")\n\nA função as.Date informa para o R que a variável indicada é de data. O argumento format indica o formato que está a data, nesse caso, “dia/mês/ano”. Aqui é possível verificar todos os formatos de datas da função. Vamos ver como ficou:\n\nglimpse(dados)\n\nRows: 11,523\nColumns: 46\n$ dt_notific <date> 2020-05-15, 2020-05-18, 2020-04-30, 2020-05-11, 2020-07-01…\n$ dt_sin_pri <date> 2020-05-06, 2020-05-10, 2020-04-20, 2020-05-04, 2020-06-12…\n$ dt_nasc    <date> 2003-06-03, 1996-07-07, 1996-03-26, 1986-06-02, 1996-12-11…\n$ dt_interna <date> 2020-05-15, 2020-05-15, 2020-04-24, 2020-05-09, 2020-06-30…\n$ sem_pri    <int> 19, 20, 17, 19, 24, 24, 26, 27, 28, 24, 14, 29, 28, 10, 36,…\n$ sg_uf      <chr> \"CE\", \"PR\", \"SP\", \"PA\", \"DF\", \"RO\", \"PI\", \"RS\", \"PE\", \"MA\",…\n$ id_mn_resi <chr> \"MORRINHOS\", \"CURITIBA\", \"SAO CAETANO DO SUL\", \"MARABA\", \"S…\n$ co_mun_res <int> 230890, 410690, 354880, 150420, 530150, 110020, 221100, 431…\n$ cs_zona    <int> NA, 1, 1, 1, 1, 1, 1, 1, 1, 1, NA, 1, 1, 1, NA, 1, 1, NA, 2…\n$ cs_raca    <int> 4, 1, 9, 4, 9, 4, 9, 1, 4, 9, 4, 4, 4, 4, 4, 9, 4, 9, 4, 4,…\n$ cs_escol_n <int> NA, 2, 9, 4, NA, 2, 4, 2, NA, NA, NA, 9, 9, 3, 3, NA, 3, NA…\n$ idade      <dbl> 16, 23, 24, 33, 23, 35, 31, 17, 22, 29, 28, 22, 27, 25, 26,…\n$ cs_gestant <int> 2, 2, 9, 5, 5, 3, 1, 5, 3, 3, 4, 3, 5, 3, 3, 3, 3, 9, 3, 3,…\n$ puerpera   <int> NA, 2, 1, 1, 1, 2, NA, 1, NA, 1, NA, NA, 1, 2, 1, NA, NA, 1…\n$ febre      <int> 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, NA, 1, 1, 1, 1, 1, 1, 1, 1…\n$ tosse      <int> 1, 2, 2, 1, 2, 1, 1, 1, NA, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1…\n$ garganta   <int> NA, 2, 2, 2, 2, 2, 2, NA, 1, NA, 2, NA, 2, 1, 1, 2, 2, NA, …\n$ dispneia   <int> NA, 1, 2, 2, 2, 2, 2, 1, NA, NA, 1, NA, 2, 1, 2, 1, 1, NA, …\n$ desc_resp  <int> NA, 2, 2, 1, 2, 2, 1, 1, NA, 1, 1, NA, 2, 1, 2, 2, 1, NA, 1…\n$ saturacao  <int> NA, 2, 2, 2, 2, 2, 2, 1, NA, NA, 2, NA, 2, 2, 2, 1, 1, NA, …\n$ diarreia   <int> NA, 1, 2, 2, 1, 2, 2, 1, NA, NA, 2, NA, 2, 1, 2, 2, 2, NA, …\n$ vomito     <int> NA, 2, 2, 2, 2, 2, 2, 2, NA, NA, 2, NA, 2, 1, 2, 2, 2, NA, …\n$ fadiga     <int> NA, NA, NA, NA, NA, 2, NA, NA, NA, NA, 2, NA, NA, 2, 2, 2, …\n$ perd_olft  <int> NA, NA, NA, NA, 1, 2, NA, NA, NA, NA, 2, NA, NA, 1, 2, 1, 2…\n$ perd_pala  <int> NA, NA, NA, NA, NA, 2, NA, NA, NA, NA, 2, NA, NA, 1, 2, 2, …\n$ dor_abd    <int> NA, NA, NA, NA, NA, 2, NA, NA, NA, NA, 2, NA, NA, 2, 2, 2, …\n$ cardiopati <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 1, NA, NA, …\n$ hematologi <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ hepatica   <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ asma       <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ diabetes   <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ neurologic <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 1, NA, NA, …\n$ pneumopati <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ imunodepre <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ renal      <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ obesidade  <int> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ vacina_cov <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ dose_1_cov <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ dose_2_cov <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ fab_cov_1  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ fab_cov_2  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ dt_entuti  <date> NA, NA, NA, NA, NA, NA, NA, 2020-06-30, NA, 2020-07-12, NA…\n$ dt_saiduti <date> NA, NA, NA, NA, NA, NA, NA, 2020-07-29, NA, NA, NA, NA, NA…\n$ uti        <int> 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, NA, 2…\n$ suport_ven <int> 2, 3, 3, 2, 3, 3, 9, 1, 3, 3, 3, 3, 3, 2, 3, 2, 1, 2, 3, 2,…\n$ evolucao   <int> 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, NA, 1, 1, 1, 1, 1, 1…\n\n\nAgora vamos lidar com as variáveis qualitativas. Veja que “cs_zona” foi identificada como int. Isso acontece porque ela foi tabulada como número, como posteriormente variáveis deste tipo serão recodificadas de acordo com o dicionário, precisamos tratá-la como fator. Já as demais variáveis qualitativas estão identificadas como numeric, dbl ou chacacter pois na tabulação suas categorias estão codificadas com números ou textos. Para então dizer ao R o verdadeiro tipo dessas variáveis, vamos utilizar os seguintes comandos:\n\ndados$cs_raca <- as.factor(dados$cs_raca)\ndados$cs_escol_n <- as.factor(dados$cs_escol_n)\ndados$cs_gestant <- as.factor(dados$cs_gestant)\ndados$puerpera <- as.factor(dados$puerpera)\ndados$cs_zona <- as.factor(dados$cs_zona)\ndados$febre <- as.factor(dados$febre)\ndados$tosse <- as.factor(dados$tosse)\ndados$suport_ven <- as.factor(dados$suport_ven)\ndados$uti <- as.factor(dados$uti)\ndados$evolucao <- as.factor(dados$evolucao)\n\nUma forma um pouco mais eficiente de fazer isso é selecionar as variáveis por meio de um vetor, por exemplo, quero que as variáveis da coluna 10 até a coluna 20 sejam fatores. Podemos fazer isso com a ajuda a função lapply. Essa função, em resumo, nos possibilita aplicar uma função em uma lista de elementos e retorna uma lista de mesmo tamanho em que o resultado é a aplicação desta função a cada elemento da lista. Neste caso, aplicamos a função as.factor nas colunas selecionadas (lista de elementos). Veja como é feito.\n\n\ndados[,c(17:37)] <- lapply(dados[,c(17:37)], as.factor)\nglimpse(dados)\n\nRows: 11,523\nColumns: 46\n$ dt_notific <date> 2020-05-15, 2020-05-18, 2020-04-30, 2020-05-11, 2020-07-01…\n$ dt_sin_pri <date> 2020-05-06, 2020-05-10, 2020-04-20, 2020-05-04, 2020-06-12…\n$ dt_nasc    <date> 2003-06-03, 1996-07-07, 1996-03-26, 1986-06-02, 1996-12-11…\n$ dt_interna <date> 2020-05-15, 2020-05-15, 2020-04-24, 2020-05-09, 2020-06-30…\n$ sem_pri    <int> 19, 20, 17, 19, 24, 24, 26, 27, 28, 24, 14, 29, 28, 10, 36,…\n$ sg_uf      <chr> \"CE\", \"PR\", \"SP\", \"PA\", \"DF\", \"RO\", \"PI\", \"RS\", \"PE\", \"MA\",…\n$ id_mn_resi <chr> \"MORRINHOS\", \"CURITIBA\", \"SAO CAETANO DO SUL\", \"MARABA\", \"S…\n$ co_mun_res <int> 230890, 410690, 354880, 150420, 530150, 110020, 221100, 431…\n$ cs_zona    <fct> NA, 1, 1, 1, 1, 1, 1, 1, 1, 1, NA, 1, 1, 1, NA, 1, 1, NA, 2…\n$ cs_raca    <fct> 4, 1, 9, 4, 9, 4, 9, 1, 4, 9, 4, 4, 4, 4, 4, 9, 4, 9, 4, 4,…\n$ cs_escol_n <fct> NA, 2, 9, 4, NA, 2, 4, 2, NA, NA, NA, 9, 9, 3, 3, NA, 3, NA…\n$ idade      <dbl> 16, 23, 24, 33, 23, 35, 31, 17, 22, 29, 28, 22, 27, 25, 26,…\n$ cs_gestant <fct> 2, 2, 9, 5, 5, 3, 1, 5, 3, 3, 4, 3, 5, 3, 3, 3, 3, 9, 3, 3,…\n$ puerpera   <fct> NA, 2, 1, 1, 1, 2, NA, 1, NA, 1, NA, NA, 1, 2, 1, NA, NA, 1…\n$ febre      <fct> 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, NA, 1, 1, 1, 1, 1, 1, 1, 1…\n$ tosse      <fct> 1, 2, 2, 1, 2, 1, 1, 1, NA, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1…\n$ garganta   <fct> NA, 2, 2, 2, 2, 2, 2, NA, 1, NA, 2, NA, 2, 1, 1, 2, 2, NA, …\n$ dispneia   <fct> NA, 1, 2, 2, 2, 2, 2, 1, NA, NA, 1, NA, 2, 1, 2, 1, 1, NA, …\n$ desc_resp  <fct> NA, 2, 2, 1, 2, 2, 1, 1, NA, 1, 1, NA, 2, 1, 2, 2, 1, NA, 1…\n$ saturacao  <fct> NA, 2, 2, 2, 2, 2, 2, 1, NA, NA, 2, NA, 2, 2, 2, 1, 1, NA, …\n$ diarreia   <fct> NA, 1, 2, 2, 1, 2, 2, 1, NA, NA, 2, NA, 2, 1, 2, 2, 2, NA, …\n$ vomito     <fct> NA, 2, 2, 2, 2, 2, 2, 2, NA, NA, 2, NA, 2, 1, 2, 2, 2, NA, …\n$ fadiga     <fct> NA, NA, NA, NA, NA, 2, NA, NA, NA, NA, 2, NA, NA, 2, 2, 2, …\n$ perd_olft  <fct> NA, NA, NA, NA, 1, 2, NA, NA, NA, NA, 2, NA, NA, 1, 2, 1, 2…\n$ perd_pala  <fct> NA, NA, NA, NA, NA, 2, NA, NA, NA, NA, 2, NA, NA, 1, 2, 2, …\n$ dor_abd    <fct> NA, NA, NA, NA, NA, 2, NA, NA, NA, NA, 2, NA, NA, 2, 2, 2, …\n$ cardiopati <fct> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 1, NA, NA, …\n$ hematologi <fct> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ hepatica   <fct> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ asma       <fct> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ diabetes   <fct> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ neurologic <fct> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 1, NA, NA, …\n$ pneumopati <fct> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ imunodepre <fct> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ renal      <fct> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ obesidade  <fct> NA, 2, 2, 2, 2, 2, NA, 2, NA, NA, NA, NA, 2, 2, 2, NA, NA, …\n$ vacina_cov <fct> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ dose_1_cov <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ dose_2_cov <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ fab_cov_1  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ fab_cov_2  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ dt_entuti  <date> NA, NA, NA, NA, NA, NA, NA, 2020-06-30, NA, 2020-07-12, NA…\n$ dt_saiduti <date> NA, NA, NA, NA, NA, NA, NA, 2020-07-29, NA, NA, NA, NA, NA…\n$ uti        <fct> 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, NA, 2…\n$ suport_ven <fct> 2, 3, 3, 2, 3, 3, 9, 1, 3, 3, 3, 3, 3, 2, 3, 2, 1, 2, 3, 2,…\n$ evolucao   <fct> 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, NA, 1, 1, 1, 1, 1, 1…\n\n\nÓtimo! Corrigimos as inconsistências das variáveis qualitativas. Mas outra questão surge: como faço para usar um rótulo nos números codificados nas categorias das variáveis qualitativas? Para o grupo, por exemplo, ao invés de aparecer 1 quero que apareça “sim”. Para isso, vamos utilizar o pacote forcats que lida com variáveis qualitativas (categóricas). Para renomear as categorias das variáveis, vamos usar a função fct_recode desse pacote:\n\ndados$cs_raca <- forcats::fct_recode(dados$cs_raca,\n                                   branca = \"1\",\n                                   preta = \"2\",\n                                   amarela = \"3\",\n                                   parda = \"4\",\n                                   indigena = \"5\",\n                                   ignorado = \"9\")\n\ndados$cs_escol_n <- forcats::fct_recode(dados$cs_escol_n,\n                                     \"sem escola\"  = \"0\",\n                                     fund1 = \"1\",\n                                     fund2 = \"2\",\n                                     medio = \"3\",\n                                     superior = \"4\",\n                                     ignorado = \"9\")\n\ndados$cs_gestant <- forcats::fct_recode(dados$cs_gestant,\n                                     \"1tri\" = \"1\",\n                                     \"2tri\" = \"2\",\n                                     \"3tri\" = \"3\",\n                                     IG_ig = \"4\",\n                                     nao = \"5\",\n                                     ignorado = \"9\")\n\ndados$puerpera <- forcats::fct_recode(dados$puerpera,\n                                      sim = \"1\",\n                                      nao = \"2\",\n                                      ignorado = \"9\")\n\ndados$cs_zona <- forcats::fct_recode(dados$cs_zona,\n                                  urbana = \"1\",\n                                  rural = \"2\",\n                                  periurbana = \"3\",\n                                  ignorado = \"9\")\n\ndados$febre <- forcats::fct_recode(dados$febre,\n                                   sim = \"1\",\n                                   nao = \"2\",\n                                   ignorado = \"9\")\n\ndados$suport_ven <-forcats::fct_recode(dados$suport_ven,\n                                       \"sim, invasivo\" = \"1\",\n                                       \"sim, nao invasivo\" = \"2\",\n                                       nao = \"3\",\n                                       ignorado = \"9\")\n\ndados$uti <-forcats::fct_recode(dados$uti,\n                                       sim = \"1\",\n                                       nao = \"2\",\n                                       ignorado = \"9\")\n\ndados$evolucao <-forcats::fct_recode(dados$evolucao,\n                                       cura = \"1\",\n                                       obito = \"2\",\n                                       \"obito por outras causas\" = \"3\",\n                                       ignorado = \"9\")\n\nEste tramanto foi feito para todas as variáveis qualitativas da base, mas por conta do tamanho do código, omitimos algumas da saída.\nFinalmente chegamos nas variáveis quantitativas. Uma forma de identificar problemas em variáveis quantitativas é avaliar os valores mínimo e máximo de cada variável e ver se tem algum valor impossível para a mesma. Em nosso caso podemos verificar a variável idade. Seria meio estranho encontrar alguém com valores extremamente altos ou negativos, concorda?! A função summary pode ser uma opção boa aqui, ela nos formece algumas medidas descritivas como, media, mínimo, máximo, entre outros.\n\nsummary(dados$idade)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  10.00   25.00   30.00   30.25   35.00   55.00       9 \n\n\nAparentemente nossa variável esta dentro do esperado, sem valores inesperados.\n\n2.0.3.1 Transformação de dados\nÉ possível modificar ou criar novas variáveis na base de dados por meio da função mutate do pacote dplyr, você pode veificar melhor essa função clicando aqui. Também podemos criar categorias com base em alguma condição por meio da função case_when também do pacote dplyr, veja melhor aqui. Para ficar mais claro, vamos a um exemplo combinando as duas funções. Vamos criar a variável “faixa_et”, onde as observações serão as faixas etárias. São essas: “<20”, “20-34” e “>=”. Veja como faz:\n\ndados <- dados |> \n  mutate(faixa_et = case_when(\n    idade < 20 ~ \"<20\",\n    idade >= 20 & idade < 34 ~ \"20-34\",\n    idade >= 34 ~ \">=34\"\n  ))\n\ntable(dados$faixa_et)#table nos mostra as observações da quela variável e a sua frequência. \n\n\n  <20  >=34 20-34 \n  714  3862  6938 \n\n\nAqui fizemos a utilização da função “pipe” |> que agora está no pacote base do R, mas que antes era necessário carregá-la por meio de pacotes. Essa função é de extrema importância, facilita a programção no R de uma forma inimaginável. É válido dedicar um pouco de seu tempo para entender melhor essa função. Separamos alguns links que pode te ajudar a entender melhor e você pode acessá-los clickando aqui, aqui ou aqui. Como foi mencionado acima, a função foi adicionada ao R base há pouco tempo, então esses links se referem ao pipe “antigo”, mas fique tranquilo, a função é a mesma. Para resumir, o pipe pega a saída de uma função e a passa para outra função como um argumento. Isso nos permite vincular uma sequência de etapas de análise.\n\n\n2.0.3.2 Manipulação de datas\nAlgo interessante também é trabalhar com a varíavel de datas. Podemos calulcar a diferença entre duas datas no R de forma bem simples por meio da função difftime do pacote base do R. Para exemplificar vamos criar a variável “dias_uti” que vai ser ser quantos dias a pessoa ficou internada na uti. Vamos fazer isso calculando a diferença entre a data de saída e a data de entrada na uti e queremos o resultado em dias.\n\ndados$dias_uti <- difftime(dados$dt_saiduti, dados$dt_entuti, units = \"days\")\nglimpse(dados)\n\nRows: 11,523\nColumns: 48\n$ dt_notific <date> 2020-05-15, 2020-05-18, 2020-04-30, 2020-05-11, 2020-07-01…\n$ dt_sin_pri <date> 2020-05-06, 2020-05-10, 2020-04-20, 2020-05-04, 2020-06-12…\n$ dt_nasc    <date> 2003-06-03, 1996-07-07, 1996-03-26, 1986-06-02, 1996-12-11…\n$ dt_interna <date> 2020-05-15, 2020-05-15, 2020-04-24, 2020-05-09, 2020-06-30…\n$ sem_pri    <int> 19, 20, 17, 19, 24, 24, 26, 27, 28, 24, 14, 29, 28, 10, 36,…\n$ sg_uf      <chr> \"CE\", \"PR\", \"SP\", \"PA\", \"DF\", \"RO\", \"PI\", \"RS\", \"PE\", \"MA\",…\n$ id_mn_resi <chr> \"MORRINHOS\", \"CURITIBA\", \"SAO CAETANO DO SUL\", \"MARABA\", \"S…\n$ co_mun_res <int> 230890, 410690, 354880, 150420, 530150, 110020, 221100, 431…\n$ cs_zona    <fct> NA, urbana, urbana, urbana, urbana, urbana, urbana, urbana,…\n$ cs_raca    <fct> parda, branca, ignorado, parda, ignorado, parda, ignorado, …\n$ cs_escol_n <fct> NA, fund2, ignorado, superior, NA, fund2, superior, fund2, …\n$ idade      <dbl> 16, 23, 24, 33, 23, 35, 31, 17, 22, 29, 28, 22, 27, 25, 26,…\n$ cs_gestant <fct> 2tri, 2tri, ignorado, nao, nao, 3tri, 1tri, nao, 3tri, 3tri…\n$ puerpera   <fct> NA, nao, sim, sim, sim, nao, NA, sim, NA, sim, NA, NA, sim,…\n$ febre      <fct> sim, nao, sim, sim, nao, sim, sim, sim, sim, sim, sim, NA, …\n$ tosse      <fct> sim, nao, nao, sim, nao, sim, sim, sim, NA, sim, sim, sim, …\n$ garganta   <fct> NA, nao, nao, nao, nao, nao, nao, NA, sim, NA, nao, NA, nao…\n$ dispneia   <fct> NA, sim, nao, nao, nao, nao, nao, sim, NA, NA, sim, NA, nao…\n$ desc_resp  <fct> NA, nao, nao, sim, nao, nao, sim, sim, NA, sim, sim, NA, na…\n$ saturacao  <fct> NA, nao, nao, nao, nao, nao, nao, sim, NA, NA, nao, NA, nao…\n$ diarreia   <fct> NA, sim, nao, nao, sim, nao, nao, sim, NA, NA, nao, NA, nao…\n$ vomito     <fct> NA, nao, nao, nao, nao, nao, nao, nao, NA, NA, nao, NA, nao…\n$ fadiga     <fct> NA, NA, NA, NA, NA, nao, NA, NA, NA, NA, nao, NA, NA, nao, …\n$ perd_olft  <fct> NA, NA, NA, NA, sim, nao, NA, NA, NA, NA, nao, NA, NA, sim,…\n$ perd_pala  <fct> NA, NA, NA, NA, NA, nao, NA, NA, NA, NA, nao, NA, NA, sim, …\n$ dor_abd    <fct> NA, NA, NA, NA, NA, nao, NA, NA, NA, NA, nao, NA, NA, nao, …\n$ cardiopati <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ hematologi <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ hepatica   <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ asma       <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ diabetes   <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ neurologic <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ pneumopati <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ imunodepre <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ renal      <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ obesidade  <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ vacina_cov <fct> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ dose_1_cov <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ dose_2_cov <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ fab_cov_1  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ fab_cov_2  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ dt_entuti  <date> NA, NA, NA, NA, NA, NA, NA, 2020-06-30, NA, 2020-07-12, NA…\n$ dt_saiduti <date> NA, NA, NA, NA, NA, NA, NA, 2020-07-29, NA, NA, NA, NA, NA…\n$ uti        <fct> nao, nao, nao, nao, nao, nao, nao, sim, nao, sim, nao, nao,…\n$ suport_ven <fct> \"sim, nao invasivo\", \"nao\", \"nao\", \"sim, nao invasivo\", \"na…\n$ evolucao   <fct> cura, cura, cura, cura, cura, cura, cura, obito, cura, cura…\n$ faixa_et   <chr> \"<20\", \"20-34\", \"20-34\", \"20-34\", \"20-34\", \">=34\", \"20-34\",…\n$ dias_uti   <drtn> NA days, NA days, NA days, NA days, NA days, NA days, NA d…\n\n\nNote que não utilizamos a função mutate para criar está nova variável, utilizamos apenas o $ para representar a variável e atribuímos a função. Assim, o R já entende como uma variável.\n\n\n2.0.3.3 Manipulação de dados\nJá temos a nossa base de dados devidamente tratada para prosseguir com a análise descritiva, mas quando falamos de manipulação de dados, um leque de possibilidades aparece. Em diversos cenários precisamos filtrar observações, reordená-las, selecionar variáveis específicas, entre outras coisas. Não poderíamos deixar de mencionar o poderoso tidyverse. O tidyverse é um pacote que contém um coleção de outros pacotes que são utilizados para manipulação, exploração e visualização de dados e que compartilham uma filosofia de design bem parecida, por isso de forma combinada permitem que você consiga fazer inúmeros trabalhos. Os pacotes que fazem parte desse universo são: dplyr, tidyr, ggplot2, forcats, purrr, stringr, tibble e readr. Anteriormente já trabalhamos com alguns destes pacotes, mas agora é válido aprofundarmos um pouco mais em alguns deles. Aqui você irá acessar o site do tidyverse onde podera navegar por cada pacote e aprender mais sobre suas utilidades e aqui você irá acessar um post escrito pelo Laboratório de Data Scinence - UFES (daslab) que contem diversos exemplos práticos de uso de todos os pacotes do universo tidyverse. Neste capítulo iremos trabalhar com algumas funções específicas.\n\n2.0.3.3.1 Pacote dplyr\nO dplyr é extremamente útil e nos ajuda a resolver os desafios mais comuns de manipulação de dados.\nSuas principais funções são:\n\nfilter() - filtra linhas;\ngroup_by() - agrupa pela(s) variável(is) no argumento. Função muito útil quando usada a funçaõ summurise.\nsummarise() - reduz vários valores a um único resumo.\nselect() - seleciona colunas;\narrange() - ordena a base;\nmutate() - cria/modifica colunas.\n\nJá utilizamos algumas funções do pacote, vamos falar sobre outras. Como já avançamos um pouco sobre a utilização de funções, vamos combinar algumas funções, o que geralmente é feito no dia a dia.\n\n#criando um novo banco de dados selecionando 3 variáveis\ndados_tratamento <- dados |> \n  select(sg_uf, cs_zona, idade)\n\nglimpse(dados_tratamento)\n\nRows: 11,523\nColumns: 3\n$ sg_uf   <chr> \"CE\", \"PR\", \"SP\", \"PA\", \"DF\", \"RO\", \"PI\", \"RS\", \"PE\", \"MA\", \"M…\n$ cs_zona <fct> NA, urbana, urbana, urbana, urbana, urbana, urbana, urbana, ur…\n$ idade   <dbl> 16, 23, 24, 33, 23, 35, 31, 17, 22, 29, 28, 22, 27, 25, 26, 20…\n\n\nAqui criamos a base “dados_tratamento” onde apenas selecionamos algumas colunas da base de dados inicial com a função select.\n\ndados_tratamento2 <- dados_tratamento |> \n  filter(cs_zona == \"urbana\") |> \n  group_by(sg_uf) |> \n  summarise(media = mean(idade, na.rm = TRUE)) |> \n  arrange(desc(media))\n\nknitr::kable(head(dados_tratamento2))\n\n\n\n\nsg_uf\nmedia\n\n\n\n\nAP\n36.66667\n\n\nBA\n31.04152\n\n\nRR\n31.00000\n\n\nSP\n30.94237\n\n\nRJ\n30.93570\n\n\nMG\n30.93257\n\n\n\n\n\nVamos entender o código acima. Primeiro acessamos a base “dados_tratamento” e com função filter selecionamos apenas as observações “urbana”. Após isso utilizamos a função group_by para agrupar nossas observações pela variável “sg_uf” e por últimos, combinamos com a função summarise para criar a variável “media” que será a media da variável idade. Note que nesta função utilizamos o argumento na.rm - TRUE. Este argumento serve para indicar para a função se ela deve ou não remover valores NA's do cálculo, o default é FALSE. Como não é possível calcular a média de valores ausentes e temos variáveis ausentes, foi necessário utilizar este argumento. Caso contrário, Estados com valores faltantes ficariam com NA. Por último, utilizamos a função arrange para ordernar os dados em em ordem descrente pela variavel media. Uma dica para tentar entender melhor o funcionamento das funções é tentar refazer o código utilizando uma função de cada vez e ir vendo como fica. Então, em poucas linhas de códigos conseguimos criar uma base com a idade média dos Estados considerando apenas zonas urbanas, legal né?\n\n\n2.0.3.3.2 Pacote stringr\nUm desafio muito grande na manipulação de dados é extrair informações de caracteres. Em resumo caracteres são letras, símbolos, sinais, números que representem algo escrito, etc.. Essa sequência de caracteres formam o que chamamos de string. Diversas vezes encontramos variáveis com categorias não padronizadas, como, por exemplo, uma variável contendo “São Paulo”, “sao paulo” e “sp”. Apesar de representarem o mesmo estado, elas são diferentes. Nesse sentido, uma parte muito importante no tratamento de dados é “lapidar” esse conjunto de caracteres para que seja possível usá-los nas análises. Essa é a introdução do post do daslab onde é passado de uma maneira muito prática como trabalhar com strings utilizando o pacote stringr, la você vai aprender também sobre expressões regulares, que com certeza serão úteis em vários momentos da sua carreira. Link do post. Como as variáveis de texto do nosso banco de dados já estão bem padronizadas não será necessário realizar nenhum tratamento, mas por ser um pacote de extrema importância e que não havia sido mencionado ainda, deixamos ele aqui para que você possa se aprofundar mais. Como em nossa base dados as variáveis de texto estão padrozinados, não será necessário realizar nenhum tratamento.\n\n\n\n2.0.3.4 Manipulando o formato da base de dados\nEm certos casos é necessário mudar o formato das bases de dados, fazer com que colunas se tornem linhas vice-versa. Vamos utilizar a base “dados_tratamento”. Veja que ela está no formato long, em que as avaliações do mesmo indivíduo (variável de identificação de indivíduo é “registro”) estão nas linhas. Queremos que as zonas fiquem nas colunas, com as três colunas (vamos tirar valores ignorados): urbana, rural e periurbana, ou seja, queremos o formato wide. Um pacote do R que pode nos auxiliar a transformar formato long em wide e vice-versa é o tidyr. A função que usaremos é spread, como segue:\n\nlibrary(tidyr)\n\ndados_formato <- dados_tratamento |> \n  filter(!is.na(cs_zona) & cs_zona != \"ignorado\") |> \n  mutate(id = row_number())\n\nknitr::kable(head(dados_formato))\n\n\n\n\nsg_uf\ncs_zona\nidade\nid\n\n\n\n\nPR\nurbana\n23\n1\n\n\nSP\nurbana\n24\n2\n\n\nPA\nurbana\n33\n3\n\n\nDF\nurbana\n23\n4\n\n\nRO\nurbana\n35\n5\n\n\nPI\nurbana\n31\n6\n\n\n\n\n\nFizemos pequenas alterações na base de dados. Primeiro realizamos um filtro para retirarmos valores faltantes da variável “cs_zona”, pois essa passará a\n\ndados_formato2 <- dados_formato |> \n  pivot_wider(names_from = cs_zona, values_from = idade)  \n\nknitr::kable(head(dados_formato2))\n\n\n\n\nsg_uf\nid\nurbana\nrural\nperiurbana\n\n\n\n\nPR\n1\n23\nNA\nNA\n\n\nSP\n2\n24\nNA\nNA\n\n\nPA\n3\n33\nNA\nNA\n\n\nDF\n4\n23\nNA\nNA\n\n\nRO\n5\n35\nNA\nNA\n\n\nPI\n6\n31\nNA\nNA\n\n\n\n\n\n\ndados_formato3 <- dados_formato2 |> \n  pivot_longer(cols = c(\"urbana\",   \"rural\",    \"periurbana\"), names_to = \"cs_zona\", values_to = \"idade\")\n\nknitr::kable(head(dados_formato3))\n\n\n\n\nsg_uf\nid\ncs_zona\nidade\n\n\n\n\nPR\n1\nurbana\n23\n\n\nPR\n1\nrural\nNA\n\n\nPR\n1\nperiurbana\nNA\n\n\nSP\n2\nurbana\n24\n\n\nSP\n2\nrural\nNA\n\n\nSP\n2\nperiurbana\nNA\n\n\n\n\n\n\n\n2.0.3.5 Combinando bases de dados\nQuando estamos trabalhando com dados, nem sempre uma única base irá conter todas as informações que precisamos, na verdade, isso é mais comum do que se possa imaginar. Assim, saber juntar duas bases de dados é indispensável. Vamos começar então falando sobre chave primária. Em resumo, chave primária se refere a um ou mais campos, onde combinados (no caso de mais de uma chave primária), não se repete na mesma tabela. Em outras palavras, uma chave primária no meu banco dados seria uma variável onde as observações não se repetem ou a combinação de variáveis que tornam as observações únicas. Para exemplicar vamos pegar nossa base de dados e separar em duas, para que posteriormente possamos juntalas. Como em nossa base de dados não temos naturalmente nenhuma chave primária, vamos utilizar a função mutate(id = row_number()) para criarmos um identificar único para este exemplo. Após isso, vamos dividir a nossa base de dados em duas, mantendo em comum entre elas apenas a nossa chave primária, neste caso, a variável “id”\n\ndados <- dados |> \n  mutate(id = row_number()) |> \n  select(id, everything())#selecionar variavel id e todas as outras \n\ndados1 <- dados[, c(1:24)]\n\nglimpse(dados1)\n\nRows: 11,523\nColumns: 24\n$ id         <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ dt_notific <date> 2020-05-15, 2020-05-18, 2020-04-30, 2020-05-11, 2020-07-01…\n$ dt_sin_pri <date> 2020-05-06, 2020-05-10, 2020-04-20, 2020-05-04, 2020-06-12…\n$ dt_nasc    <date> 2003-06-03, 1996-07-07, 1996-03-26, 1986-06-02, 1996-12-11…\n$ dt_interna <date> 2020-05-15, 2020-05-15, 2020-04-24, 2020-05-09, 2020-06-30…\n$ sem_pri    <int> 19, 20, 17, 19, 24, 24, 26, 27, 28, 24, 14, 29, 28, 10, 36,…\n$ sg_uf      <chr> \"CE\", \"PR\", \"SP\", \"PA\", \"DF\", \"RO\", \"PI\", \"RS\", \"PE\", \"MA\",…\n$ id_mn_resi <chr> \"MORRINHOS\", \"CURITIBA\", \"SAO CAETANO DO SUL\", \"MARABA\", \"S…\n$ co_mun_res <int> 230890, 410690, 354880, 150420, 530150, 110020, 221100, 431…\n$ cs_zona    <fct> NA, urbana, urbana, urbana, urbana, urbana, urbana, urbana,…\n$ cs_raca    <fct> parda, branca, ignorado, parda, ignorado, parda, ignorado, …\n$ cs_escol_n <fct> NA, fund2, ignorado, superior, NA, fund2, superior, fund2, …\n$ idade      <dbl> 16, 23, 24, 33, 23, 35, 31, 17, 22, 29, 28, 22, 27, 25, 26,…\n$ cs_gestant <fct> 2tri, 2tri, ignorado, nao, nao, 3tri, 1tri, nao, 3tri, 3tri…\n$ puerpera   <fct> NA, nao, sim, sim, sim, nao, NA, sim, NA, sim, NA, NA, sim,…\n$ febre      <fct> sim, nao, sim, sim, nao, sim, sim, sim, sim, sim, sim, NA, …\n$ tosse      <fct> sim, nao, nao, sim, nao, sim, sim, sim, NA, sim, sim, sim, …\n$ garganta   <fct> NA, nao, nao, nao, nao, nao, nao, NA, sim, NA, nao, NA, nao…\n$ dispneia   <fct> NA, sim, nao, nao, nao, nao, nao, sim, NA, NA, sim, NA, nao…\n$ desc_resp  <fct> NA, nao, nao, sim, nao, nao, sim, sim, NA, sim, sim, NA, na…\n$ saturacao  <fct> NA, nao, nao, nao, nao, nao, nao, sim, NA, NA, nao, NA, nao…\n$ diarreia   <fct> NA, sim, nao, nao, sim, nao, nao, sim, NA, NA, nao, NA, nao…\n$ vomito     <fct> NA, nao, nao, nao, nao, nao, nao, nao, NA, NA, nao, NA, nao…\n$ fadiga     <fct> NA, NA, NA, NA, NA, nao, NA, NA, NA, NA, nao, NA, NA, nao, …\n\ndados2 <- dados[, c(1, 25:49)]\n\nglimpse(dados2)\n\nRows: 11,523\nColumns: 26\n$ id         <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ perd_olft  <fct> NA, NA, NA, NA, sim, nao, NA, NA, NA, NA, nao, NA, NA, sim,…\n$ perd_pala  <fct> NA, NA, NA, NA, NA, nao, NA, NA, NA, NA, nao, NA, NA, sim, …\n$ dor_abd    <fct> NA, NA, NA, NA, NA, nao, NA, NA, NA, NA, nao, NA, NA, nao, …\n$ cardiopati <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ hematologi <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ hepatica   <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ asma       <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ diabetes   <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ neurologic <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ pneumopati <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ imunodepre <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ renal      <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ obesidade  <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ vacina_cov <fct> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ dose_1_cov <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ dose_2_cov <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ fab_cov_1  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ fab_cov_2  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ dt_entuti  <date> NA, NA, NA, NA, NA, NA, NA, 2020-06-30, NA, 2020-07-12, NA…\n$ dt_saiduti <date> NA, NA, NA, NA, NA, NA, NA, 2020-07-29, NA, NA, NA, NA, NA…\n$ uti        <fct> nao, nao, nao, nao, nao, nao, nao, sim, nao, sim, nao, nao,…\n$ suport_ven <fct> \"sim, nao invasivo\", \"nao\", \"nao\", \"sim, nao invasivo\", \"na…\n$ evolucao   <fct> cura, cura, cura, cura, cura, cura, cura, obito, cura, cura…\n$ faixa_et   <chr> \"<20\", \"20-34\", \"20-34\", \"20-34\", \"20-34\", \">=34\", \"20-34\",…\n$ dias_uti   <drtn> NA days, NA days, NA days, NA days, NA days, NA days, NA d…\n\n\nEm “dados1” selecionamos as colunas de 1 até a 24, onde a coluna 1 é a variável “id”. Em dados 2 selecionamos a coluna depois e as colunas de 25 até a 49. Agora temos dois banco de dados e precisamos juntá-los.\nHá algumas funções de combinação de duas bases de dados no pacote dplyr. Elas recebem três argumentos: a primeira base a ser declarada (x=), a segunda base a ser declarada (y=) e a variável de identificação informada no argumento by=. Aqui estão as funções mais úteis:\n\nleft_join() - retorna todas as linhas da base de dados no argumento x e todas as colunas das duas bases de dados. Linhas da base de dados de x sem correspondentes em y receberão NA na base de dados combinada.\nright_join() - retorna todas as linhas da base de dados no argumento y e todas as colunas das duas bases de dados. Linhas da base de dados de y sem correspondentes em x receberão NA na base de dados combinada.\nfull_join() - retorna todas as linhas e todas as colunas de x e de y. As linhas sem correspondência entre as bases receberão NA na base de dados combinada.\ninner_join() - filtra a base de dados no argumento x apenas onde tem valores correspondentes na base de dados no argumento y e todas as colunas das duas bases de dados.\nsemi_join() - filtra a base de dados no argumento x apenas onde tem valores correspondentes na base de dados no argumento y, mantendo apenas as colunas da base de dados de x.\nanti_join() - filtra a base de dados no argumento x para incluir apenas valores que não possuem correspondências na base de dados no argumento y.\n\nAssim sendo, no nosso exemplo, tanto as funções left_join(), right_join(), full_join() e inner_join() retornarão a mesma combinação, pois “dados1” e “dados2” possuem exatamente os mesmos indivíduos, ou seja, não há nenhuma linha que esteja em uma das bases de dados e que não está na outra. Este cenário foi um pouco mais simples, mas pense que no dia a dia você irá encontrar bases onde você precisará encontrar chaves primarias entre elas. Além disso, varios problemas podem vir acompanhados, por exemplo, imagine que para juntar duas bases você utilizará uma chave formada pela combinação de duas variáveis: UF e Município. Em uma base a sua UF está no formato de sigla e na outra está sendo representada pelo código da UF atribuido pelo IBGE. Já na variável de Município, Em uma base os dados estão todos padronizados, maiúsculos e sem acentuação, já na outra base está no formato “padrão” com a primeira letra maiúscula e acentuação. Veja que será necessário um bom tratamento de dados para pode juntar essas bases. Voltando para o nosso exemplo, vamos a prática.\n\ndados_todos <- full_join(dados1, dados2, by=c(\"id\")) \n\nglimpse(dados_todos)\n\nRows: 11,523\nColumns: 49\n$ id         <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ dt_notific <date> 2020-05-15, 2020-05-18, 2020-04-30, 2020-05-11, 2020-07-01…\n$ dt_sin_pri <date> 2020-05-06, 2020-05-10, 2020-04-20, 2020-05-04, 2020-06-12…\n$ dt_nasc    <date> 2003-06-03, 1996-07-07, 1996-03-26, 1986-06-02, 1996-12-11…\n$ dt_interna <date> 2020-05-15, 2020-05-15, 2020-04-24, 2020-05-09, 2020-06-30…\n$ sem_pri    <int> 19, 20, 17, 19, 24, 24, 26, 27, 28, 24, 14, 29, 28, 10, 36,…\n$ sg_uf      <chr> \"CE\", \"PR\", \"SP\", \"PA\", \"DF\", \"RO\", \"PI\", \"RS\", \"PE\", \"MA\",…\n$ id_mn_resi <chr> \"MORRINHOS\", \"CURITIBA\", \"SAO CAETANO DO SUL\", \"MARABA\", \"S…\n$ co_mun_res <int> 230890, 410690, 354880, 150420, 530150, 110020, 221100, 431…\n$ cs_zona    <fct> NA, urbana, urbana, urbana, urbana, urbana, urbana, urbana,…\n$ cs_raca    <fct> parda, branca, ignorado, parda, ignorado, parda, ignorado, …\n$ cs_escol_n <fct> NA, fund2, ignorado, superior, NA, fund2, superior, fund2, …\n$ idade      <dbl> 16, 23, 24, 33, 23, 35, 31, 17, 22, 29, 28, 22, 27, 25, 26,…\n$ cs_gestant <fct> 2tri, 2tri, ignorado, nao, nao, 3tri, 1tri, nao, 3tri, 3tri…\n$ puerpera   <fct> NA, nao, sim, sim, sim, nao, NA, sim, NA, sim, NA, NA, sim,…\n$ febre      <fct> sim, nao, sim, sim, nao, sim, sim, sim, sim, sim, sim, NA, …\n$ tosse      <fct> sim, nao, nao, sim, nao, sim, sim, sim, NA, sim, sim, sim, …\n$ garganta   <fct> NA, nao, nao, nao, nao, nao, nao, NA, sim, NA, nao, NA, nao…\n$ dispneia   <fct> NA, sim, nao, nao, nao, nao, nao, sim, NA, NA, sim, NA, nao…\n$ desc_resp  <fct> NA, nao, nao, sim, nao, nao, sim, sim, NA, sim, sim, NA, na…\n$ saturacao  <fct> NA, nao, nao, nao, nao, nao, nao, sim, NA, NA, nao, NA, nao…\n$ diarreia   <fct> NA, sim, nao, nao, sim, nao, nao, sim, NA, NA, nao, NA, nao…\n$ vomito     <fct> NA, nao, nao, nao, nao, nao, nao, nao, NA, NA, nao, NA, nao…\n$ fadiga     <fct> NA, NA, NA, NA, NA, nao, NA, NA, NA, NA, nao, NA, NA, nao, …\n$ perd_olft  <fct> NA, NA, NA, NA, sim, nao, NA, NA, NA, NA, nao, NA, NA, sim,…\n$ perd_pala  <fct> NA, NA, NA, NA, NA, nao, NA, NA, NA, NA, nao, NA, NA, sim, …\n$ dor_abd    <fct> NA, NA, NA, NA, NA, nao, NA, NA, NA, NA, nao, NA, NA, nao, …\n$ cardiopati <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ hematologi <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ hepatica   <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ asma       <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ diabetes   <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ neurologic <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ pneumopati <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ imunodepre <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ renal      <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ obesidade  <fct> NA, nao, nao, nao, nao, nao, NA, nao, NA, NA, NA, NA, nao, …\n$ vacina_cov <fct> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ dose_1_cov <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ dose_2_cov <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ fab_cov_1  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ fab_cov_2  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ dt_entuti  <date> NA, NA, NA, NA, NA, NA, NA, 2020-06-30, NA, 2020-07-12, NA…\n$ dt_saiduti <date> NA, NA, NA, NA, NA, NA, NA, 2020-07-29, NA, NA, NA, NA, NA…\n$ uti        <fct> nao, nao, nao, nao, nao, nao, nao, sim, nao, sim, nao, nao,…\n$ suport_ven <fct> \"sim, nao invasivo\", \"nao\", \"nao\", \"sim, nao invasivo\", \"na…\n$ evolucao   <fct> cura, cura, cura, cura, cura, cura, cura, obito, cura, cura…\n$ faixa_et   <chr> \"<20\", \"20-34\", \"20-34\", \"20-34\", \"20-34\", \">=34\", \"20-34\",…\n$ dias_uti   <drtn> NA days, NA days, NA days, NA days, NA days, NA days, NA d…\n\n\nPronto, temos nossa base completa e aprendemos um pouco sobre manipular dados. O pacote tidyverse será um grande aliado seu no R de forma geral. Como mencionado anteriormente, não cobrimos tudo o que é necessário saber para trabalhar com manipulação de dados, é necessário entender a demanda e pesquisar soluções. Saber traduzir o seu problema para que consiga pesquisar com mais facilidade é uma habilidade muito importante. Recomendamos que treine, trabalhe com diferentes tipos de dados, pesquise pacotes, funções, etc. Com o tempo fará com tranquilidade coisas que hoje considera difícil. Lembre-se, a pratica leva a perfeição."
  },
  {
    "objectID": "supervisionada.html",
    "href": "supervisionada.html",
    "title": "4  Aprendizado supervisionado",
    "section": "",
    "text": "Tópicos:\n\nconceitos iniciais\nalgoritmos supervisionados\naplicações e interpretabilidade\n\n\n4.0.1 Machine learning\n\nfalar sobre ml\nmecionar um pouco sobre Aprendizado supervisionado VS não supervisionado\n“neste capítulo vamos falar sobre aprendizado supervisionado\n\n\n\n4.0.2 Aprendizado supervisionado (conceitos iniciais)\nAprendizado supervisionado pode ser definido como a tarefa de aprender uma função que mapeia uma entrada em uma saída e isso é feito com base em exemplos e treinos. Em outras palavras, uma máquina é treinada para encontrar soluções chamadas rótulos, onde esses rótulos identificam alguma característica. Apesar de também poder ser usada para regressão, o aprendizado supervisionado tem como tafera típica a classificação. Um exemplo bem simples de classificação é: suponha que eu queira classificar imagens de animais, nesse caso possuo um banco de dados com imagens de cachorros e gatos. Quero que meu algoritmo classifique as imagens identificando o tipo do animal na imagem. Para isso o algoritmo é treinado utilizando vários exemplos para que ele consiga classificar novas imagens posteriormente. Outra tafera é predizer um valor com base em características, por exemplo, prever o valor de um carro dado um conjunto de características (quilometragem, idade, marca, etc.) chamadas preditores. Este tipo de tarefa é chamada regressão. Para treinar o sistema é preciso incluir diversos exemplos, assim o banco de dado é separado em treino e teste, onde o é feito o treinamento na base treino para posteriormente serem feitos os testes de predição e avaliação da qualidade do ajuste na base teste.\n\n4.0.2.1 Dificuldades gerais do machine learnig\nComo dito ateriormente, a idéia geral do aprendizado de máquina é contruir um algorito para solucionar os meus problemas, onde esse algoritmo será treinado com dados. Mas, o que acontece se o meu algorito for ruim ou os dados serem ruins.\n\n4.0.2.1.1 Quantidade insuficiente de dados\nFalando sobre dados ruins, o primeiro problema é a quantidade de dados. Já parou pra pensar em quão difícil é treinar uma máquina? voltando no exemplo anterior, para você aprender a diferenciar um cachorro de um gato quando era criança, bastou alguém lhe apontar qual era qual algumas vezes e você se tornou capaz de diferenciar cães de gatos independente das caracteristicas. Uma máquina não consegue fazer isso fácilmente, é necessário uma quantidade grande de dados para a maioria dos algoritmos, até mesmo para problemas simples como o do exemplo citado e para problemas complexos, como reconhecimento de imagem ou fala você pode precisar de milhões de exemplos.\n\n\n4.0.2.1.2 Dados de treino não representativos\nComo mencionado anteriormente, o treinamento de um algoritmo é feito por meio de uma base de dados, onde está é separada em dados de treinamento e de teste, para que eu possa usá-lo e generalizá-lo em dados futuros. Dados de treinamento que não representem bem os dados que serão uzados no futuro podem um modelo que não funcionará bem. Utilizando o exemplo do algoritmo de regressão onde o objetivo era prever os valores dos carros com base em suas características. Digamos que meu algoritmo foi treinado com uma da base de dados de carros apenas do estado de São Paulo, mas meu algoritmo será utilizado para prever carros de todo o país, pode ser que não funcione tão bem. O estados podem alterar significamente os preços dos carros por meio de impostos por exemplo. É de extrema importância utilizar um conjunto de dados de treino que represente bem os dados que você deseja generalizar. Isso pode não ser uma tarefa fácil, pode encontrar problemas com amostras, principalmente se ela for muito pequena e até mesmo uma amostra grande pode não ser representativa.\n\n\n4.0.2.1.3 Qualidade dos dados\nComo pode ter imaginado, a qualidade dos dados também é de extrema importância. Dados com discrenpâncias, vários erros, e gerados a partir de medições de baixa qualidade fará com que fique mais difícil o seu algoritmo identificar padrões e tomar decisões. Se você convive com pessoas do ramo da ciência de dados em geral, é bem provável que ja tenha ouvido alguém dizer algo o tipo: “gastamos a maior parte do nosso tempo para limpar os dados”. Isso não é em vão. Na maioria dos casos, principalmente no ramo de aprendizagem de máquinas é gasto um enorme tempo para limpar os dados pois pode influênciar muito na qualidade do modelo. Por exemplo, se algumas informações forem muito discrepantes, é preciso decidir entre tentar corrigir ou excluí-las. Se uma variável tiver uma quantidade significativa de valores faltantes, deverá ser decidido se essas observações serão excluídas ou se será possível utilizar métodos de imputação de dados. Treinar mais de um modelo com diferentes decisões tomadas sobre os dados também pode ser efetivo.\n\n\n4.0.2.1.4 Sobreajustamento dos dados (Overfitting)\nO sobreajustamento é um conceito que ocorre quando nosso modelo (não só um modelo de aprendizado de máquinas), se ajusta exatamento aos nossos dados de treinamento. Ouvir isso uma primeira vez pode parecer excelente, ou até mesmo o cenário ideal, afinal, queremos que o nosso modelo se ajuste o máximo possível, certo? bom.. não exatamente. O que acontece neste caso, é que o modelo mostra-se adequado apenas para os dados de treino, como se o modelo tivesse apenas decorado os dados de treino e não fosse capaz de generalizar para outros dados nunca vistos antes. Assim, o desempenho do nosso modelo quando usado em novos dados cai drasticamente. Algumas razões que podem levar a um sobreajustamento: base de treino muito pequena, não contendo dados suficientes para representar bem todos valores de entrada possíveis; grande quantidade de informações irrelevantes (dados ruidosos); treinamento excessivo em um único conjunto de amostra; modelo muito complexo, fazendo com que ele aprenda os ruídos nos dados de treinamento. Agora que sabemos o problema que é um sobreajustamento e as razões que podem levar a isso, precisamos falar sobre como evitar que isso aconteça. Existem algumas tecnicas comumente utilizadas.\n\nRegularização: Foi dito anteriormente que uma razão para o sobreajustamento é a complexidade do modelo, então, faz sentido diminuírmos sua complexidade. Isso pode ser feito removendo ou dimuindo o número de parâmetros.\nParada antecipada: Quando um modelo está sendo treinado por radadas de repetição, é possível avaliar cara uma dessa repetição. Nomermalmente o desempenho de um modelo melhora a cada repetição, mas chega um momento em que começa a acontecer o sobreajustamento. A ideia da parada antecipada é pausar o treinamento anter que chegue a esse ponto.\nAumento de dados: Essa técnica consiste em aumentar ligeiramente os dados da amostra toda vez que o modelo os processa, ou seja, injevar dados limpos e relevantes nos dados de treino. Isso faz com que os conjuntos de treino pareçam “exclusivos” do modelo, impedindo que ele aprenda suas características. Mas isso deve ser feito com moderação, pode injetar dados que não estão limpos pode fazer mais mal do que bem. Além disso, não é um método garantido.\n\n\n\n4.0.2.1.5 Existem outras técnicas que podem ser utilizadas para evitar o sobreajustamento. Mas precisamos falar também sobre como detectá-los.\nUma forma não técnica e que não deve ser a sua única forma de tentar identificar o sobreajustamento é por meio da visualização gráfica. A visualização gráfica pode ser usada apenas para levantar hipotéses, nunca para tomar uma decisão final. Até mesmo porque nem sempre é possível verificar esse problema visualmente. Tavelz a técnica mais eficiente para isso é a Validação Cruzada k-fold (k-fold Cross Validation). Valos falar sobre posteriormente.\n\n\n4.0.2.1.6 Subajustamento dos dados (Underfitting)\nComo pode ter imaginado, subajustamento é o oposto do sobreajustamto. Ocorre quando seu modelo é muito simples para aprender a estrutura dos dados. O subjastumento leva à um erro elevado tanto nos dados detreino quanto nos dados de teste. Pode ocorrer quando o modelo não foi treinado por tempo suficiente ou as variáveis ​​de entrada não são significativas o suficiente para determinar uma relação significativa entre as variáveis ​​de entrada e saída. Aqui também estamos em um cenário a ser evitado e apesar de ser contrário ao sobreajustamento, as téncias tanto para identificar quanto para evitar o problema são semelhantes. Um adendo, geralmente, identificar um subajustamento é mais fácil que identificar um sobreajustamento.\n\n\n\n4.0.2.2 Modelo de Regressão Linear\nJá temos uma breve noção sobre o que é aprendizado supervisionado, agora vamos aprofundar um pouco dentro dos modelos. Como foi mencionado aprendizado supervisionado é usado principalmente para métodos de classificação e regressão. Modelo de regressão linear, como o próprio nome já diz, se enquadra nos métodos de regressão. A regressão consiste em modelar um valor de previsão com base em variáveis independentes. De forma mais geral, o modelo conquiste em fazer uma previsão “simples” calculando uma ponderação entre as somas dos recusrso de entrada e uma constante chamada intercepto. Assim, obtemos uma relação linear entre a variável de saída e as variáveis de entrada. A linha de regressão é a linha de melhor ajuste para o modelo\n\\[\n\\hat y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ...+ \\beta_nx_n\n\\]\nonde:\n\n\\(\\hat y\\) é o valor predito\n\\(n\\) o número de características\n\\(x_i\\) é a \\(i^{th}\\) característica\n\\(\\beta_j\\) é o \\(j^{th}\\) parâmetro do modelo\n\nCerto, temos uma definição matemática do nosso modelo, mas como posso treiná-lo? Treinar um modelo significa também definir os parâmetros para que o modelo se ajuste melhor aos meus dados. Em outras palavras, um modelo treinado irá se ajustar a melhor linha para prever o valor de \\(y\\) para um dado valor de \\(x\\). Assim, ao encontrar os melhores valores de \\(\\beta 's\\) obtemos a melhor linha de ajuste. Para isso, primeiro precisamos de uma medida de quão bem (ou mal) o modelo se ajusta aos meus dados. A medida mais comum usada em um modelo de regressão é a Raiz do Erro Quadrático Médio (REQM). Em resumo, o REQM é uma medida de quão espalhados estão esses resíduos. Ele avalia a diferença média quadrática entre os valores observados e previstos. Portanto, treinar um modelo consiste em encontrar os valores de \\(\\beta's\\) que irá minimizar o REQM.\n\\[\nREQM = \\sqrt{\\frac{1}{n}\\sum_{i = 1}^{n}  (\\hat y_i - y_i)^2}\n\\]\nExistem algumas suposições importantes quue devem ser feitas para utilizar um modelo de regressão linear. Estas são algumas verificações formais durante a construção de um modelo de regressão linear, o que garante a obtenção do melhor resultado possível do conjunto de dados fornecido.\n\nSuposição de linearidade: A regressão linear assume que a relação entre a entrada e saída é linear. Pode parecer um pouco óbvio, mas em alguns casos onde, em um primeiro olhar, faça sentido usar uma regressão linar, nossos dados não permitam isso. Pode ser necessário transformar os dados.\nHomocedasticidade: Homocedasticidade é uma situação em que o termo de erro é o mesmo para todos os valores de variáveis ​​independentes. Com homocedasticidade, não deve haver uma distribuição padrão clara de dados no gráfico de dispersão.\nErros normalmente distribuídos: A regressão linear assume que o termo de erro deve seguir o padrão de distribuição normal. Se os termos de erro não forem normalmente distribuídos, os intervalos de confiança se tornarão muito amplos ou muito estreitos, o que pode causar dificuldades em encontrar coeficientes. Você pode obter algum benefício usando transformações (por exemplo, log ou BoxCox) em suas variáveis ​​para tornar sua distribuição mais gaussiana.\nMulticolinearidade: O modelo de regressão linear não assume nenhuma autocorrelação em termos de erro. Se houver alguma correlação no termo de erro, isso reduzirá drasticamente a precisão do modelo. A autocorrelação geralmente ocorre se houver uma dependência entre os erros residuais. Considere calcular correlações pareadas para seus dados de entrada e remover os mais correlacionados.\n\n\n\n4.0.2.3 Modelo de Regressão logística\nAlguns algoritmos de regressão podem ser usados para classificação (o contrário também é valido). A regressão logística é um dos algoritmos mais populares do machine leranrning e geralmente é usada para estimar a probabilidade de que uma instância pertença a uma classe. Por exemplo, qual a probalidade de que o objeto de uma imgagem seja um cachorro? ou um gato? neste caso, se a probabilidade estimada for maior que 50%, então o modelo pode prever que naquela imagem tem um cachorro (classe rotulada como “1”), se for menor, prevê que é um gato (classe rotulada como “0”). Este tipo de regressão pode retornar valores categóricos ou discretos, como: Sim ou Não, 0 ou 1, verdadeiro ou falso, entre outros. Mas aqui, ela fornece os valores probabilísticos que estão entre 0 e 1. Apresar de ser semelhante a regressão linear, aqui não ajustamos uma linha de regressão, mas sim uma função logistica em forma de “S” que prevê os dois valores máximos (0 ou 1).\n\ninserir imagem\n\nA equação de regressão Logística pode ser obtida a partir da equação de Regressão Linear.\n\\[\n\\hat y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ...+ \\beta_nx_n\n\\]\nO problema de usar essa abordagem é que podemos prever probalidades negativas em alguns casos e valores maiores que 1 em outros. Essas previsões não são sensatas, pois sabemos que a verdadeira probabilidade deve ser um número entre 0 e 1. Para resolver esse problema, devemos modelar \\(\\hat y\\) usando uma função que fornceça saídas entre 0 e 1 para todos os valores de \\(\\hat y\\). Na regressão logística usamos a função logística como sendo:\n\\[\n\\hat y = \\frac{e^{\\beta_0+\\beta_1X}}{1 + e^{\\beta_0+\\beta_1X}}\n\\]\nDepois de algumas manipulações, chegamos que\n\\[\n\\frac{\\hat y}{1- \\hat y} = e^{\\beta_0+\\beta_1X}\n\\]\nMas precisamos variar de \\(-\\infty\\) até \\(\\infty\\), então pegue o logaritmo da equação e temos:\n\\[\n\\log\\bigg[\\frac{\\hat y}{1- \\hat y} \\bigg ] = {\\beta_0+\\beta_1X}\n\\]\nExistem alguns tipos de regressão logística:\n\nBinomial: Aqui deve haver apenas dois tipos de possível variáveis, como 0 ou 1, Falso ou Verdadeiro, etc.\nMultinomial: Pode também haver 3 ou mais tipos não ordenados possíveis da variável dependende, como, cachorro, gato ou tigre.\nOrdinal: Na regressão logística ordinal, pode haver 3 ou mais tipos ordenados possíveis de variáveis ​​dependentes, como “baixo”, “médio” ou “alto”.\n\n\n\n4.0.2.4 Validação Cruzada (Cross-Validation)\nAté aqui falamos um pouco sobre alguns problemas que podem ser encontrados no aprendizado de máquinas e superficialmente sobre dois modelos de regressão. Vamos falar agora sobre um método que é bem utilizado para validar a estabilidade do seu modelo. Como mencionamos anteriormente, não podemos simplismente ajustar um modelo aos meus dados de treino e esperar que ele funcione perfeitamente, ou até mesmo esperar que aquele seja o melhor modelo possível ser fazer nenhuma validação. Falamos um pouco sobre isso quando discutimos sobre sobreajustamento e subajustamento. Então, vamos nos aprofundar sobre um método que nos garanta que o nosso modelo obteve a maioria dos padrões dos dados corretos sem captar muitos ruídos.\n\n4.0.2.4.1 O que é validação cruzada?\nValidação cruzada é uma técnica para avaliar um modelo de aprendizado de máquina e tester o seu desempenho. Pode ajudar a comparar e selecionar um modelo mais apropriado para o nosso problema. É bem fácil de entender, de implementar e tende a ter um viés menor do que outros métodos usados para o mesmo objetivo. Por isso é uma ferramenta tão utilizada. Tanto a vaildação cruzada quanto outros algoritmos funcionam de maneira semelhantes, consistem em: divider o conjunto de dados em treino e teste; treinar o modelo no conjunto treino; validar o modelo no conjunto teste e repetir as etapas anteriores algumas vezes. Dentro da validação cruzada existem diversas técnicas onde umas são mais utilizadas. Já mencionamos anteriormente o método k-fold, mas exite também os métodos, hold-out, leave-p-out, k-fold stratified, entre outros. Vamos falar sobre alguns deles.\n\nHold-Out Cross Validation: Está é a tecnica mais simples e comum. Ele consiste em remover uma parte dos dados de treinamento e usá-la para obter previsões do modelo treinado no restante dos dados. A estimativa de erro informa como nosso modelo está se saindo em dados não vistos ou no conjunto de vailidação. A implementação é extremamente fácil e existem pacotes que podem ajudar nisso. Mas apesar disto, esse método tem um grande desvantagem. Se estivermos trabalhando com um conjunto de dados que não é completamente uniforme, podemos acabar em uma situação difícil após a separação. O conjunto de treino pode não representar muito bem o conjunto de teste, ou seja, os conjuntos podem ser bem diferentes, onde um é mais fácil do que o outro.\nK-Fold Cross Validation: O K-Fold pode se apresentar como um técnica que minimiza a desvantagens do método Hold-Out apresentando uma nova maneira de difidir o banco de dados. Neste método os dados são divididos em k subconjuntos (daí o nome). O método de validação é repetido k vezes, onde, a cade vez, um dos k subconjuntos é usado como conjunto de teste e os outros k-1 conjuntos são unidos para formar o conjunto de treinamento. A estimativa de erro é a média de todas as k tentativas. Como cada ponto de dados chega a um conjunto de validação exatamente uma vez e a um conjunto de treinamento k-1 vezes, isso reduz significativamente o viés. Como “regra geral”, k=5 ou k=10 é escolhido, mas não existe nada fixo. Comparando diretamente ao método Hold-Out, o método K-Fold tende a ser melhor, mas também possui uma desvantagem. Aumentar o k resulta no treinamento de mais modelos e o processo de treinamento pode ser custoso e demorado.\nLeave-P-Out Cross Validation: Este método consiste em criar todos os conjuntos de treinamento e testes possíveis usando p amostras como conjunto de teste. Em outras palavras, deixa p pontos de dados fora dos dados de treino, ou seja, se houver n pontos de dados na amostra original, np amostras são usadas para treinar o modelo p pontos são usadas como conjunto teste. Como pode imaginar, este método e extremamente exaustivo, tento em vista que é preciso validar o modelo para todas as comibanções possíveis e para um p demasiadamente grande, pode ser computacionalmente inviável.\n\nO método de validação cruzada também pode nos ajudar a ajustar hiperparâmetros, falaremos sobre isso posteriormente.\n\n\n\n4.0.2.5 Precisão vs intrerpretabilidade\nAté aqui, discutimos muito sobre métodos para obter modelos precisos, com desempenhos ótimos. Obter um modelo que irá prever com excelência um evento em dados não é visto como um modelo valioso, mas, onde entra a interpretabilidade?\na interpretabilidade fornece informações sobre o relacionamento entre as entradas e a saída de um modelo. Um modelo que pode ser interpretado permite responder perguntas sobre por que os recursos independentes predizer aquele atributo dependente. Por exemplo: Um modelo extremamente preciso preciso pode permitir que eu saiba quais os meus clientes “podem” receber créditos ou não, mas se ele não for interpretável, eu nunca saberei o porque. Pense no cenário da saúde, onde eu tenho diversas informações sobre paciêntes e meu modelo pode predizer precisamente quais tem mais probalidade de ser diagnosticado com um doença. Mas já pensou em qual importante é saber quais fatores influênciam isso? porque aquele paciente é mais provável de ser diagnostico com tal doença em relação a outro. Em diversos cenários a interpretabilidade torna-se indispensável dentro dos modelos. A depender do cenário, a interpretabilidade é mais importante que a precisão e vice-versa.\nSaber qual priorizar vai depender muito do cenário em que se encontra. Normalmente a escolha de um determinado algoritmo em detrimento de outro e como a seleção do algoritmo está relacionada ao caso de uso que estamos tentando resolver e ao objetivo de negócios que queremos alcançar. Um modelo com menos parâmetros é mais fácil de interpretar. Isso é intuitivo. Um modelo de regressão linear tem um coeficiente por recurso de entrada e um termo de interceptação. Por exemplo, você pode examinar cada termo e entender como eles contribuem para a saída. Uma árvore de decisões (falaremos mais sobre elas) também costuma ser de fácil interpretação, mas mesmo modelos considerados “interpretáveis” podem se tornar rapidamente não interpretáveis."
  },
  {
    "objectID": "naosupervisionado.html#alguns-conceitos-básicos-de-algebra",
    "href": "naosupervisionado.html#alguns-conceitos-básicos-de-algebra",
    "title": "6  Aprendizado não supervisionado",
    "section": "6.1 Alguns conceitos básicos de algebra",
    "text": "6.1 Alguns conceitos básicos de algebra\nPara melhor introduzir o campo do aprendizado não supervisionado, alguns conceitos de álgebra são necessários para compreender o que se passa por trás de cada algoritmo da análise de dados multivariada. Vamos introduzir com vetores e matriz, seguindo com decomposição espectral para então darmos inicio a área da estatística multivariada ou aprendizado não supervisionado. Não é objetivo desse livro demonstrar conceitos algébricos e nem se aprofundar demais no assunto Johnson, Wichern, et al. (2002).\n\n6.1.1 Definições importantes\nVetor Aleatório : Seja X um vetor contendo p componentes, onde cada componente é uma variável aleatória, isto é, \\(X_i\\) é uma variável aleatória, \\(\\forall\\quad i =1,2,...,p\\). Então X é chamado de vetor aleatório e é denotado por:\n\\[\n\\begin{align}\n  X &= \\begin{bmatrix}\n           X_{1} \\\\\n           X_{2} \\\\\n           \\vdots \\\\\n           X_{p}\n         \\end{bmatrix}\n  \\end{align}\n\\]\nO vetor transposto do vetor aleatório X é denotadopor \\(X' = [X_1 X_2 X_3 ...X_p]\\)\nVetor de Médias : O vetor \\(\\mu\\) é chamado vetor de médias quando \\(E(X) = \\mu\\) onde X é um vetor aleatório. Dessa forma\n\\[\n\\begin{align}\n  E(X) &= \\begin{bmatrix}\n           E(X_{1}) \\\\\n           E(X_{2}) \\\\\n           \\vdots \\\\\n           E(X_{p})\n         \\end{bmatrix}\n  \\end{align} = \\mu = \\begin{bmatrix}\n           \\mu_1 \\\\\n           \\mu_2 \\\\\n           \\vdots \\\\\n           \\mu_p\n         \\end{bmatrix}\n\\]\nMatriz de covariâncias : A matriz de variâncias e covariâncias do vetor X é denotada por,\n\\[\nCov(X) = V(X) = Var(X) = \\Sigma_{p\\times p} = \\begin{bmatrix}\n           \\sigma_{11} & \\sigma_{12} & ... & \\sigma_{1p}  \\\\\n          \\sigma_{21} & \\sigma_{22} & ... & \\sigma_{2p}  \\\\\n            \\vdots &\\vdots & \\ddots &\\vdots \\\\\n           \\sigma_{p1} & \\sigma_{p2} & ... & \\sigma_{pp}\n         \\end{bmatrix}\n\\]\nOnde \\(\\sigma_{ii}\\) representa a variância do elemento \\(X_i\\) do vetor aleatório e \\(\\sigma_{ij} = E[(X_i- \\mu_i)(X_j - \\mu_j)]\\) \\(\\forall\\quad i,j = 1,\\dots,p\\). A matriz de covariância é uma matriz simétrica, sua transposta é igual a ela mesma, ou seja \\(\\Sigma = '\\Sigma\\). Sendo tambem não negativa definida, \\(a'\\Sigma a \\geq 0\\) para todo vetor de constantes pertencentes aos reais.\nMatriz de correlação : A matriz de correlação do vetor X é denotada por,\n\\[\nP_{p\\times p} = \\begin{bmatrix}\n           1 & \\rho_{12} & \\rho_{13}& ... & \\rho_{1p}  \\\\\n          \\rho_{21} & 1 & \\rho_{23}&... & \\rho_{2p}  \\\\\n          \\rho_{31} & \\rho_{32} & 1 &... & \\rho_{3p}  \\\\\n            \\vdots &\\vdots & \\ddots &\\vdots \\\\\n           \\rho_{p1} & \\rho_{p2} &\\rho_{p3}& ... & 1\n         \\end{bmatrix}\n\\]\nEm que\n\\[\n\\rho_{ij} = \\frac{\\sigma_{ij}}{\\sqrt{\\sigma_{ii}\\sigma_{jj}}} = \\frac{\\sigma_{ij}}{\\sigma_i\\sigma_j}\n\\]\nAuto Valores e Auto Vetores : Se \\(\\Sigma\\) for uma matriz quadrada, ou seja \\(\\Sigma_{p\\times p}\\), então um vetore não nulo \\(e\\) em \\(R^n\\) é denominado autovetor de \\(\\Sigma\\) se \\(\\Sigma e\\) for um múltiplo escalar de \\(e\\), isto é,\n\\[\n\\Sigma e = \\lambda e\n\\]\ncom algum escalar \\(\\lambda\\). O escalar \\(\\lambda\\) é denominado de autovalor de \\(\\Sigma\\), e dizemos que \\(e\\) é um autovetor associado a \\(\\lambda\\). Por \\(\\Sigma\\) ser uma matriz não negativa definida seus autovalores \\(\\lambda_i\\) associados tambem serão não negativos. Os autovetores e autovalores serão necessários para a análise de componentes principais mais a frente abordada.\n\n6.1.1.1 Equação característica\nAinda é necessário uma forma de encontrar os autovetores e autovalores associados a uma matriz \\(\\Sigma\\). Se \\(\\Sigma\\) for uma matriz quadrada, então \\(\\lambda\\) se, e somente se, \\(\\lambda\\) satisfaz a equação\n\\[\ndet(\\lambda I - \\Sigma) = 0\n\\]\nOnde det é o determinante e \\(I\\) a matriz identidade. Para esclarecimento, suponha como exemplo que,\n\\[\n\\Sigma = \\begin{bmatrix}\n8 & -2 \\\\\n-2 & 5\n\\end{bmatrix}\n\\]\nEntão,\n\\[\n\\begin{split}\ndet\\left(\\begin{bmatrix}\n\\lambda& 0\\\\\n0 & \\lambda\n\\end{bmatrix}\n-  \n\\begin{bmatrix}\n8 & -2 \\\\\n-2 & 5\n\\end{bmatrix}\n\\right) = 0\\\\\ndet\\left(\\begin{bmatrix}\n\\lambda - 8 & 2 \\\\\n2 & \\lambda-5\n\\end{bmatrix}\n\\right) = 0 \\\\\n(\\lambda - 8)\\times(\\lambda-5) - (2)\\times(2) = 0\n\\end{split}\n\\]\nResolvendo a equação obtemos os valores de \\(\\lambda_1 = 9\\) e \\(lambda_2 = 4\\), podemos encontrar os autovetores \\(v\\) associados seguindo a definição:\n\\[\n\\begin{bmatrix}\n8&-2\\\\\n-2 & 5\n\\end{bmatrix}\n\\begin{bmatrix}\nv_{11}\\\\\nv_{12}\n\\end{bmatrix} =\n9\\begin{bmatrix}\nv_{11}\\\\\nv_{12}\n\\end{bmatrix} \\rightarrow v_{11} =- 2v_{12}\n\\]\nNote que para cada autovalor temos infinitos possíveis autovetores dentro dos reais. Nos restringiremos aos autovetores normalizados.Dizemos que um vetor \\(e_i\\) é normalizado quando:\n\\[\ne_i = \\begin{bmatrix}\ne_{i1}\\\\\ne_{i2}\\\\\n\\vdots\\\\\ne_{ip}\n\\end{bmatrix}\n\\]\nEm que\n\\[\n||e_i|| = \\sqrt{e^2_{i1} + e^2_{i2} + \\dots + e^2_{ip}} = 1\n\\]\n\n\n\n6.1.2 Decomposição Espectral de Matrizes de correlação e Covariância em seus Autovetores e Autovalores normalizados.\nO teorema da decomposição espectral é de extrema importância em álgebra matricial e estatística multivariada, ele relaciona a matriz com seus autovalores e autovetores normalizados.\nSuponha \\(\\Sigma\\) a matriz de covariâncias. Então existe uma matriz ortogonal \\(O\\)(matriz no qual sua transposta é igual a sua inversa) tal que,\n\\[\nO'\\Sigma O = \\begin{bmatrix}\n\\lambda_1 & 0 & 0 &\\dots & 0\\\\\n0&\\lambda_2& 0 & \\dots & 0 \\\\\n0 & 0 &\\lambda_3 &\\dots & 0\\\\\n\\vdots& \\vdots & \\vdots & \\ddots & \\vdots\\\\\n0 & 0 & 0 & \\dots& \\lambda_p\n\\end{bmatrix} = \\Lambda\n\\]\nOnde \\(\\lambda\\_1 \\geq \\lambda\\_2 \\geq \\dots \\lambda\\_p\\geq0\\) são os autovalores ordenados em ordem decrescente da matriz \\(\\Sigma\\). Nesse caso, dizemos que a matriz \\(\\Sigma\\) é similar à matriz \\(\\Lambda\\), que implica em:\n\n\\(det(\\Sigma) = det(\\Lambda) = \\prod^p_{i=1} \\lambda_i\\)\ntraço\\((\\Sigma) =\\) traço\\((\\Lambda) = \\lambda_1 +\\dots+\\lambda_p\\)\n\nTem-se que a i-ésima coluna da matriz \\(O\\) é o autovetor normalizado \\(e_i\\) relacionado ao autovalor \\(\\lambda_i\\). Então a matriz \\(O\\) é dada por \\(O = [e_1,e_2,\\dots,e_p]\\) e pelo teorema da decomposição espectral, podemos ver que:\n\\[\n\\Sigma = O \\Lambda O' = \\sum_{i=1}^p \\lambda_i e_i e_i'\n\\]\nDentro do R é possível realizar a decomposição espectral usando a função eigen(),\n\nsigma <- matrix(c(8,-2,-2,5),nrow = 2)\nsigma\n\n     [,1] [,2]\n[1,]    8   -2\n[2,]   -2    5\n\neigen(sigma)\n\neigen() decomposition\n$values\n[1] 9 4\n\n$vectors\n           [,1]       [,2]\n[1,] -0.8944272 -0.4472136\n[2,]  0.4472136 -0.8944272"
  },
  {
    "objectID": "naosupervisionado.html#análise-de-componentes-principais-pca",
    "href": "naosupervisionado.html#análise-de-componentes-principais-pca",
    "title": "6  Aprendizado não supervisionado",
    "section": "6.2 Análise de Componentes Principais (PCA)",
    "text": "6.2 Análise de Componentes Principais (PCA)\nA análise de componentes principais se preocupa em conseguir explicar a variância e covariância de uma estrutura de variáveis através de algumas poucas combinações lineares. Tendo como principal objetivo dessa análise a redução de dimensionalidade e interpretação das relações. Essas combinações lineares são os componentes principais e são não correlacionadas entre sí. Quando assumimos que as variáveis originiais possuem distribuição normal, as componentes, além de não correlacionadas são normalmente distribuidas e idependentes. Os componentes principais são extraidos através da decomposição da matriz de covariância do vetor aleatório. Caso alguma trasnformação seja realizada nesse vetor, a decomposição será realizada na matriz de covariância do vetor transformado. Um caso muito utilizado, suponha que nossas variáveis estão em escalas muito diferentes, o PCA pode acabar por dar mais variabilidade a essa variável com escala superior, para isso então padronizamos o vetor. Utilizar a matriz de covariância do vetor transformado e a matriz de correlação do vetor originais são ações equivalentes nessa situação.\nDefinição: Seja X um vetor aleatório com \\(\\mu = E(X)\\) e \\(\\Sigma = Var(X)\\) e \\((\\lambda_i,e_i), i = 1,\\dots,p\\) os pares de autovalores e autovetores normalizados associados de \\(\\Sigma\\). Então,\n\\[\n\\begin{split}\nY = O'X,\\quad \\textrm{com}\\quad O = [e_1,e_2,\\dots,e_p],\\textrm{ os componentes principais de X}\\\\\n\\textrm{ou seja}\\\\\nY =\n\\begin{bmatrix}\nY_1\\\\\n\\vdots\\\\\nY_d\n\\end{bmatrix} \\textrm{ com  } \\quad Y_1 = e_1'X = e_{11}X_1 + e_{12}X_2 +  \\dots + e_{1p}X_p\n\\end{split}\n\\]\nO primeiro componente principal. Os componentes principais de X, Y, são tais que,\n\\[\n\\begin{split}\n\\mu_y = E(Y) = E(O'X) = O'E(X) = O'\\mu_x\\\\\n\\Sigma_y = Var(Y) = Var(O'X) = O'Var(X)O = O'\\Sigma_xO = \\Lambda\n\\end{split}\n\\]\nou seja\n\\[\ncov(Y_i,Y_j) = 0, \\forall i \\neq j \\textrm{ e } Var(Y_i) = \\lambda_i\n\\]\nA prova desse resultado pode ser vista em (Johnson, Wichern, et al. 2002, 5:432).\nDescrevemos a variância total da população como sendo o somatório de todos os autovalores \\(\\lambda\\). A partir disso, podemos descrever a proporção da variância total explicada pela j-ésima componente como sendo:\n\\[\n\\frac{\\lambda_j}{\\sum_{i=1}^p \\lambda_i} \\qquad \\forall j =1,\\dots,p\n\\]\nPara algum \\(p\\) significativamente grande, podemos utilizar \\(d<p\\) componentes ao invés das \\(p\\) variáveis originais, considerando que, podemos descrever uma proporção relativamente alta da variância com essas \\(d\\) componentes.\nSe \\(Y_i = e'_iX, i =1\\dots,p\\) são as componentes principais obtidas da matriz de covariância, então\n\\[\n\\rho_{Y_i,X_j} = \\frac{e_{ij}\\sqrt{\\lambda_i}}{\\sigma_{jj}}, \\quad \\forall i,j=1,\\dots p\n\\]\nSão os coeficientes de correlação entre a componente \\(Y_i\\) e a variável \\(X_j\\)\n\n6.2.1 Exemplo.\nPara realmente entender a aplicabilidade da análise de componentes, vamos pegar um subconjunto do banco de dados mtcars, conjunto de dados no R base, consiste nas características de modelos de carros. Selecionaremos um subconjunto de colunas numéricas para conseguirmos trabalhar, considerando que PCA funciona melhor com variáveis numéricas. Há possibilidade de transformação de variáveis categoricas em variáveis dummy, porem o algoritmo não será tão preciso, também não sendo possível trabalhar com variáveis categóricas ordinais nesse caso.\n(deixei um exemplo com mtcars pois o banco de dados trabalhado no livro tem poucas variaveis numericas)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n3\n1\n\n\n\n\n\nPodemos obter de forma simples no R as componentes, bem como a proporção da variância explicada, com a função prcomp(). Bem como citado tambem é comum padronização das variáveis devido a escala de cada característica, para isso basta informar o parâmetro scale. como TRUE dentro da função.\n\ndados.pca <- dados |> \n  prcomp()\npaste('dados não padronizados: ',sep = \"\\n\")\n\n[1] \"dados não padronizados: \"\n\ndados.pca |> summary()\n\nImportance of components:\n                           PC1      PC2     PC3     PC4     PC5     PC6    PC7\nStandard deviation     136.532 38.14735 3.06642 1.27492 0.90474 0.64734 0.3054\nProportion of Variance   0.927  0.07237 0.00047 0.00008 0.00004 0.00002 0.0000\nCumulative Proportion    0.927  0.99938 0.99985 0.99993 0.99997 0.99999 1.0000\n                          PC8    PC9\nStandard deviation     0.2859 0.2159\nProportion of Variance 0.0000 0.0000\nCumulative Proportion  1.0000 1.0000\n\n#padronizando as variaveis devido a diferenca de escalas\n\ndados.pca.padr <- dados |>\n  prcomp(scale. = T)\npaste('dados padronizados:',sep = \"\\n\")\n\n[1] \"dados padronizados:\"\n\ndados.pca.padr |> summary()\n\nImportance of components:\n                          PC1    PC2     PC3     PC4     PC5     PC6     PC7\nStandard deviation     2.3782 1.4429 0.71008 0.51481 0.42797 0.35184 0.32413\nProportion of Variance 0.6284 0.2313 0.05602 0.02945 0.02035 0.01375 0.01167\nCumulative Proportion  0.6284 0.8598 0.91581 0.94525 0.96560 0.97936 0.99103\n                          PC8     PC9\nStandard deviation     0.2419 0.14896\nProportion of Variance 0.0065 0.00247\nCumulative Proportion  0.9975 1.00000\n\n#outras informacoes\n\ndados.pca.padr |> print()\n\nStandard deviations (1, .., p=9):\n[1] 2.3782219 1.4429485 0.7100809 0.5148082 0.4279704 0.3518426 0.3241326\n[8] 0.2418962 0.1489644\n\nRotation (n x k) = (9 x 9):\n            PC1         PC2         PC3          PC4        PC5         PC6\nmpg  -0.3931477  0.02753861 -0.22119309 -0.006126378 -0.3207620  0.72015586\ncyl   0.4025537  0.01570975 -0.25231615  0.040700251  0.1171397  0.22432550\ndisp  0.3973528 -0.08888469 -0.07825139  0.339493732 -0.4867849 -0.01967516\nhp    0.3670814  0.26941371 -0.01721159  0.068300993 -0.2947317  0.35394225\ndrat -0.3118165  0.34165268  0.14995507  0.845658485  0.1619259 -0.01536794\nwt    0.3734771 -0.17194306  0.45373418  0.191260029 -0.1874822 -0.08377237\nqsec -0.2243508 -0.48404435  0.62812782 -0.030329127 -0.1482495  0.25752940\ngear -0.2094749  0.55078264  0.20658376 -0.282381831 -0.5624860 -0.32298239\ncarb  0.2445807  0.48431310  0.46412069 -0.214492216  0.3997820  0.35706914\n             PC7         PC8         PC9\nmpg  -0.38138068 -0.12465987  0.11492862\ncyl  -0.15893251  0.81032177  0.16266295\ndisp -0.18233095 -0.06416707 -0.66190812\nhp    0.69620751 -0.16573993  0.25177306\ndrat  0.04767957  0.13505066  0.03809096\nwt   -0.42777608 -0.19839375  0.56918844\nqsec  0.27622581  0.35613350 -0.16873731\ngear -0.08555707  0.31636479  0.04719694\ncarb -0.20604210 -0.10832772 -0.32045892\n\n\nDa informação obtida por print(dados.pca.padr), podemos identificar os loadings da análise. Os loadings podem ser definidos como os coeficientes da combinação linear das variáveis originais de onde as componentes principais são construidas. De um ponto de vista matemático os loadings são iguais às coordenadas das variáveis divididas pela raiz quadrada do autovalor associado ao componente. são úteis quando você deseja entender os resultados. Lembre-se de que cada nova variável Y é uma combinação linear de todas as variáveis. A matriz de loadings representa verticalmente quanto da variância de cada componente é explicada por cada variável original. Vemos por exemplo que, conforme mpg aumenta, a PC1 tem um descrécimo. Os loadings são muito úteis na hora de nomear nossas componentes por essa relação que faz com cada uma das variáveis.\n\n\n6.2.2 Número de Componentes Principais\nAté agora foi descrito que podemos utilizar um número \\(d < p\\) de componentes principais que contenha uma explicabilidade aproximada dos dados originais, mas qual seria esse valor \\(d\\)? Há um conjunto de técnicas para essa tomada de decisão, sendo uma delas por exemplo a proporção de variância acumulada total explicada pelas componentes \\(Y_1,\\dots,Y_p\\):\n\\[\n\\frac{\\sum^d_{j=1}\\lambda_j}{\\sum_{i=1}^p \\lambda_i}\n\\]\nEsse valor é observado na função prcomp() já citada, como cumulative Proportion no resultado do summary() da função.\nPodemos utilizar como apoio gráfico e auxílio na tomada de decisão para o número de componentes é o scree plot, conhecido também como gráfico do cotovelo. Consiste na ordenação dos autovalores do maior para o menor, procurando por uma espécie de cotovelo dentro do gráfico. Selecionamos o número $i $ de componentes em que há um grande valor para observação \\(\\lambda_{i-1}\\) em comparação a observação \\(\\lambda_i\\) e uma pequena alteração da observação \\(\\lambda_i\\) para a observação \\(\\lambda_{i+1}\\). Observe a seguir\n\n#variancia explicada por cada componente\nvar_explicada = dados.pca.padr$sdev^2 / sum(dados.pca.padr$sdev^2)\nlibrary(ggplot2)\n\n\nqplot(c(1:9), var_explicada) + \n  geom_line() + \n  xlab(\"Principal Componente\") + \n  ylab(\"variancia explicada\") +\n  ggtitle(\"Scree Plot\") +\n  ylim(0, 1) + \n  scale_x_discrete(limits=c(1:9))\n\n\nPodemos por meio, tanto do scree plot, quanto pelo valor da variância explicada acumulada, selecionar \\(d= 3\\) componentes para reter, pela queda de 2 para 3 ser significante, enquanto a de 3 para 4 nem tanto. Reduzindo número de variáveis a 3.\n##Métodos de Agrupamentos\nA análise de agrupamentos ou clusterização, tem como objetivo, agrupar indivíduos da população usando como base medidas de similaridade entre eles, formando grupos heterogêneos entre sí com homogenuidade entre indivíduos de mesmo cluster. Muito utilizado na classificação de tipos de clientes de mercado, usuários de aplicativos, ou até mesmo em áres como psicologia, para agrupamentos de perfis de personalidade. Outro exemplo pode ser visto no trabalho (colocar link mariana).\n\n\n6.2.3 Medidas de dissimilaridade\nDe forma mais intutitiva, essas medidas de dissimilaridade seriam formas de numerar o quão próximo ou distânte a característica de um indivíduo (Idade por exemplo), se aproxima da mesma característica de outro indivíduo da mesma população. Não possuimos uma única forma de medida. Aqui apresentaremos as mais conhecidas e mais trabalhadas. Não existe uma métrica melhor, a eficácia de uma medida dependerá do caso em que a mesma será aplicada. Suponha que para cada elemento amostral será obtido o vetor \\(X = [X_{1},X_{2},\\dots,X_{p}]'\\) de medidas, onde \\(X_{i}\\) representa a medida da i-ésima característica para a unidade amostral.\nDistância Euclidiana: Essa é provavelmente a mais conhecida e usada medida de distância. Ela simplesmente é a distância geométrica no espaço multidimensional. Considere o i-ésimo e o j-ésimo indivíduo:\n\\[\nd(X,Y) = \\sqrt{\\sum^p_{i=1}(X_i - Y_i)^2}\n\\]\nDistância de Canberra: A distância de Camberra examina a soma das séries de diferenças fracionárias entre as coordenadas do par de observações.\n\\[\nd(X,Y) = \\sum^p_{i=1}\\frac{|X_i - Y_i|}{|X_i| + |Y_i|}\n\\]\nDistância de Manhattan: A distância de Manhattan (“City Block” ou “Geometria do Táxi”) é uma forma de geometria em que a distância entre dois pontos é a soma das diferenças absolutas de suas coordenadas.\n\\[\nd(X,Y) = \\sum^p_{i=1}|X_i- Y_i|\n\\]\nDistância de Chebyshev: Em matemática, distância de Chebyshev (ou distância de Tchebychev), métrica máxima ou \\(L_{\\infty}\\) métrica, é uma métrica definida em um espaço vetorial onde a distância entre dois vetores é a maior de suas diferenças ao longo de qualquer característica.\n\\[\nd(X,Y) = \\max_i(|X_i - Y_i|)\n\\]\nDistância de Minkowski: A distância de Minkowski de ordem \\(k\\), sendo \\(k\\) inteiro, pode ser considerada uma generalização tanto da distância euclidiana quanto da distância de manhattan.\n\\[\nd(X,Y) = \\left(\\sum^p_{i=1}|X_i - Y_i|^k\\right)^\\frac{1}{k}\n\\]\nTodas essas distâncias aqui citadas podem ser acessadas pela função dist() do R, alterando o parãmetro method para a distância desejada, da seguinte forma :\n\ndb<- dados[1:10,c('sem_pri','idade_anos','dt_evoluca_2','ano','dt_sint')]\ndb$ano <- db\ndb.dist <- db |> na.omit() |> dist(method = 'euclidean')\ndb.dist\n\n           1         2         3         4         5         6         7\n2  21.633308                                                            \n3  21.633308  8.485281                                                  \n4  31.292172 24.738634 16.321765                                        \n5  50.521283 28.962044 30.886890 37.804762                              \n6  67.242843 47.774470 45.615787 43.266615 24.665766                    \n7  20.435264 11.063453 18.782971 34.985711 35.445733 56.920998          \n8  31.805660 13.813037 10.217632 17.076299 22.126907 35.445733 24.665766\n9  37.994736 28.962044 37.421919 53.699162 40.958516 65.424766 19.809089\n10 44.009090 27.626075 22.768399 18.782971 22.847319 24.738634 38.418745\n           8         9\n2                     \n3                     \n4                     \n5                     \n6                     \n7                     \n8                     \n9  40.249224          \n10 13.813037 52.752251\n\n\nConsguindo a distância euclidiana entre cada uma das 10 primeiras observações para as características selecionadas.\n\n\n6.2.4 Técnicas Hierárquicas\nDentro da estatística multivariada dividimos frequêntemente as técnicas aglomerativas em dois tipos: hierárquicos e não hierárquicos, sendo as hierárquicas classificadas em aglomerativa e divisivas. Métodos hierárquicos são geralmente utilizados na análise exploratória afim de encontrar um número ótimo de clusters para o conjunto de variáveis, para as técnicas não hierárquicas é necessário um valor prévio de grupos.\n\n6.2.4.1 Técnicas Hierárquicas Aglomerativas\nConsidere cada observação como um grupo único, nos métodos aglomerativos vamos anexando cada grupo um ao outro em cada passo, usando suas medidas de similaridade para esse agrupamentos. Em cada instância do processo o par de grupos com a menor medida de dissimilaridade. Suponha a distância euclidiana por exemplo, em cada passo, verificaremos os \\(p\\) grupos e anexamos o par com a menor distância euclidiana, seguindo para o próximo passo realizamos o mesmo com os \\(p-1\\) grupos, até q sobre apenas 1 grupo com todas as observações. Seguindo o processo por \\(p-1\\) passos.\nLigamento Simples: Assumindo que cada observação é um cluster incialmente, suponha as observações X e Y sendo as com menor distância, ou os vizinhos mais próximos, formando o novo cluster {XY}. A distância entre o grupo {XY} e os demais grupos, suponha W, é definida como:\n\\[\nd(\\{XY\\},W) = \\min\\{d_{XW},d_{YW}\\}\n\\]\nConsidere a matriz de distâncias do exemplo anterior das 5 primeiras observações:\n\\[\n\\begin{bmatrix}\nd_{1,2}=21.63 &  & & \\\\\nd_{1,3}= 21.63 & d_{2,3}=8.48 & & \\\\\nd_{1,4}=31.29 & d_{2,4}=24.73 & d_{3,4}=16.32 \\\\\nd_{1,5}=50.52 & d_{2,5}=28.96 & d_{3,5}=30.88 & d_{4,5}=37.80\n\\end{bmatrix}\n\\]\nSendo a distância entre a observação 3 e 2 a menor distância dentre todas as observações. Anexaremos as duas observações em um único grupo, assumindo a nova distância desse grupo com as demais observações como sendo o minimo da distância das variaveis do grupo os demais grupos:\n\\[\n\\begin{bmatrix}\nd_{23,1}=21.63 &  & & \\\\\nd_{23,4}= 16.32 & d_{1,4}=31.29 & & \\\\\nd_{23,5}=28.96 & d_{1,5}=50.52 & d_{4,5}=37.80\n\\end{bmatrix}\n\\]\nDando prosseguimento com o processo, note que agora a menor distância se da entre os grupos {23} e o grupo {4}, logo os dois serão reagrupados em um único cluster, seguindo com esse mesmo processo até que reste apenas um grupo.\n\\[\n\\begin{bmatrix}\nd_{234,1}=21.63 \\\\\nd_{234,5}= 28.96 & d_{4,5} = 37.80\n\\end{bmatrix} \\rightarrow\n\\begin{bmatrix}\nd_{1234,5}=28.96\n\\end{bmatrix}\n\\]\nOs resultados do agrupamento de ligação simples podem ser exibidos graficamente na forma de um dendrograma, ou diagrama de árvore. Os ramos na árvore representam clusters. As ramificações se unem em nós cujas posições ao longo de uma distância (ou similaridade) indicam o nível em que as junções ocorrem. Veja para o exemplo acima considerando agora as 10 observações, passando na função hclust() para ligação dos grupos, o parâmetro method para tipo de ligação, no caso atual method = \"single\".\n\nhc <-  db.dist |> \n  hclust( method = \"single\") \nlibrary(factoextra)\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\n\n\nfviz_dend(hc, cex = 0.5,\n          main = \"Dendrogram - Simples\",\n          xlab = \"observacoes\", ylab = \"distancia\", sub = \"\")\n\n\nLigação Completa : Funciona de maneira parecida com a ligação simples, uniremos os grupos com menor distância entre sí até que reste apenas um único grupo. Porém, as distâncias entre as variáveis unidas, digamos X e Y, das demais variáveis W será definida como:\n\\[\nd(\\{XY\\},W) = \\max\\{d_{XW},d_{YW}\\}\n\\]\nMas o procedimento das demais iterações será da mesma forma, fazendo o link entre os grupos de menor distância. Suponha o exemplo anterior:\n\\[\n\\begin{bmatrix}\nd_{1,2}=21.63 &  & & \\\\\nd_{1,3}= 21.63 & d_{2,3}=8.48 & & \\\\\nd_{1,4}=31.29 & d_{2,4}=24.73 & d_{3,4}=16.32 \\\\\nd_{1,5}=50.52 & d_{2,5}=28.96 & d_{3,5}=30.88 & d_{4,5}=37.80\n\\end{bmatrix}\n\\]\nUniremos as observações 2 e 3 assim como anteriormente, e a cada passo, a nova distância será a distância máxima entre as variáveis do grupo e os demais grupos:\n\\[\n\\begin{split}\n\\begin{bmatrix}\nd_{23,1}=21.63 &  & & \\\\\nd_{23,4}= 24.73 & d_{1,4}=31.29 & & \\\\\nd_{23,5}=30.88 & d_{1,5}=50.52 & d_{4,5}=37.80\n\\end{bmatrix}\\\\\n\\\\\n\\rightarrow\n\\begin{bmatrix}\nd_{123,4}=31.29 \\\\\nd_{123,5}= 50.52 & d_{4,5} = 37.80\n\\end{bmatrix} \\rightarrow\n\\begin{bmatrix}\nd_{1234,5}=50.52\n\\end{bmatrix}\n\\end{split}\n\\]\nObserve agora o dendrograma para ligação completa com 10 observações.\n\nhc <-  db.dist |> \n  hclust( method = \"complete\") \nlibrary(factoextra)\n\n\nfviz_dend(hc, cex = 0.5,\n          main = \"Dendrogram - Completa\",\n          xlab = \"observacoes\", ylab = \"distancia\", sub = \"\")\n\n\nLigação Média: A ligação média trata a distância entre dois clusters como a distância média entre todos os pares de itens onde um membro de um par pertence a cada cluster. Considere o grupo {XY} e o grupo {W}, e \\(N_w\\) como sendo número de elementos em {W}, e \\(N_{XY}\\) número de elementos em {XY}, então:\n\\[\nd(\\{XY\\},W) = \\frac{\\sum^{N_{xy}}_{i=1}\\sum_{j=1}^{N_w}d_{ij}}{N_{xy}N_w}\n\\]\nOnde \\(d_{ij}\\) representa a distância entre a i-ésima observação do grupo {XY} e j-ésima observação do grupo {w}. Seguindo com o exemplo anterior e seu dendrograma obtemos:\n\\[\n\\begin{split}\n\\begin{bmatrix}\nd_{1,2}=21.63 &  & & \\\\\nd_{1,3}= 21.63 & d_{2,3}=8.48 & & \\\\\nd_{1,4}=31.29 & d_{2,4}=24.73 & d_{3,4}=16.32 \\\\\nd_{1,5}=50.52 & d_{2,5}=28.96 & d_{3,5}=30.88 & d_{4,5}=37.80\n\\end{bmatrix}\\\\\n\\\\\\rightarrow\n\\begin{bmatrix}\nd_{23,1}=21.63 &  & & \\\\\nd_{23,4}= 20.525 & d_{1,4}=31.29 & & \\\\\nd_{23,5}=29.92 & d_{1,5}=50.52 & d_{4,5}=37.80\n\\end{bmatrix}\n\\\\\n\\\\ \\rightarrow\n\\begin{bmatrix}\nd_{234,1}=24.85 \\\\\nd_{234,5}= 32.54 & d_{1,5} = 50.52\n\\end{bmatrix} \\rightarrow\n\\begin{bmatrix}\nd_{1234,5}=37.04\n\\end{bmatrix}\n\\end{split}\n\\]\n\nhc <-  db.dist |> \n  hclust( method = \"average\") \nlibrary(factoextra)\n\n\nfviz_dend(hc, cex = 0.5,\n          main = \"Dendrogram - Média\",\n          xlab = \"observacoes\", ylab = \"distancia\", sub = \"\")\n\n\nMétodo Ward de clusterização : O método de ward se baseia na minimização da “perda de informação” ao juntar dois grupos. É tido como perda de informação o crescimento da soma dos quadrados dos erros, \\(SQE\\). Suponha o grupo {W}, a \\(SQE_W\\) pode ser descrita como a soma dos quadrados das distâncias de cada item do grupo para a média do grupo. Definindo \\(SQE\\) como a soma dos \\(SQE_i\\), onde \\(i\\) representa cada um dos \\(N\\) grupos. Em cada instância do processo é realizado a junção de todos os possiveis pares de grupos, optamos pela união que obtiver o menor incremento da \\(SQE\\). Note que no passo 0 essa soma é equivalente a 0, considerando que para cada \\(SQE_i\\), com apenas uma observação por cluster, a média será a própria observação. Enquanto que ao considerar o grupo final com todas as observações é possível obter a \\(SQE\\) por:\n\\[\nSQE = \\sum^N_{j=1}(X_j - \\bar{X})'(X_j - \\bar{X})\n\\]\nOnde \\(X_j\\) representa a j-ésima observação do grupo.\n\nhc <-  db.dist |> \n  hclust( method = \"ward.D2\") \nlibrary(factoextra)\n\n\nfviz_dend(hc, cex = 0.5,\n          main = \"Dendrogram - Ward\",\n          xlab = \"observacoes\", ylab = \"distancia\", sub = \"\")\n\n\n\n\n6.2.4.2 Algumas conclusões\nOs métodos hierárquicos são muito utilizados na exploração dos dados, bem como para pré definição do número de clusters, pois como veremos a seguir nos métodos não hierarquicos temos a necessidade de informar um número prévio de grupos. O dendograma é tido como principal forma de definição desses \\(k\\) grupos. Para definir o número ideal de clusters vamos utilizar o exemplo do método Ward. Observe que a distância para união do grupo {5,6} e {2,3,4,8,10} é relativamente grande se comparada as outras junções, uma forma de definir então seria \\(k = 3\\) grupos onde os grupos seriam, {1,7,9},{5,6} e {2,3,4,8,10} olhando o nível de fusão (distância) em que cada grupo precisou para se unir. Podemos então já utilizar \\(k\\) aproximado de 3 para iniciarmos nossos métodos não hieráquicos como veremos a seguir.\n\n\n\n6.2.5 Métodos de Agrupamentos Não Hierárquicos\nDentro desse conjunto de métodos iremos trabalhar com o mais usual e conhecido, k-médias. Bem como dito, os métodos não hierárquicos precisam de um número pré definido de grupos \\(k\\), anexando cada observação a um grupo com base em \\(k\\) centróides que serão definidos pelo algoritmo.\n\n6.2.5.1 K-Médias.\nK-médias é um método simples de particionamento, onde é necessário estabelecer um número \\(k\\) de grupos previamente a separação das variáveis. Definindo um número inicial de centróides, podendo esses ser observações do próprio conjunto de dados ou coordenadas aleatórias, é realizada a divisão do conjunto de dados, sendo cada observação anexada ao centro de menor distância, ou mais próximo. Com base nesse novo grupo criado, é determinado o nomo ponto central, que passa a ser a média do grupo. Baseado nesses novos pontos realizamos os passos anteriores por um número \\(N\\) de vezes até que não se tenha mais alteração na posição dos centróides. O resultado do processo são grupos heterogêneos entre sí com variáveis homogêneas entre sí, tendo a menor variância interna possível e a maior variação externa possível. O núemero de iterações do processo pode também ser pré estabelecido, considerando o custo computacional para bancos de dados grandes, é inviável a realização do processo até a falta de alteração dos clusters.\nExemplo:\nSuponha os seguintes dados para 20 variáveis, e suponha que vamos fazer inicialmente para \\(k=3\\) grupos.\n\n\n\n\n\n\nidade_anos\nsem_pri\n\n\n\n\n1\n24\n17\n\n\n2\n31\n26\n\n\n3\n27\n28\n\n\n4\n20\n33\n\n\n5\n39\n39\n\n\n6\n34\n51\n\n\n7\n34\n21\n\n\n8\n29\n33\n\n\n9\n44\n18\n\n\n10\n27\n40\n\n\n11\n28\n47\n\n\n12\n35\n50\n\n\n13\n37\n29\n\n\n14\n30\n29\n\n\n15\n32\n45\n\n\n16\n27\n32\n\n\n17\n44\n32\n\n\n18\n30\n42\n\n\n19\n16\n21\n\n\n20\n24\n21\n\n\n21\n31\n32\n\n\n22\n24\n36\n\n\n23\n31\n34\n\n\n24\n33\n47\n\n\n25\n25\n50\n\n\n26\n31\n21\n\n\n27\n26\n21\n\n\n28\n49\n19\n\n\n29\n25\n25\n\n\n30\n16\n31\n\n\n31\n20\n32\n\n\n32\n34\n42\n\n\n33\n28\n38\n\n\n34\n33\n16\n\n\n35\n34\n21\n\n\n36\n32\n20\n\n\n37\n38\n32\n\n\n38\n31\n40\n\n\n39\n38\n24\n\n\n40\n41\n27\n\n\n\n\n\nSuponha que os clusters são tidos inicialmente nas cordenadas:\n\n\n\n\n\n\nidade_anos\nsem_pri\n\n\n\n\n1\n36\n24\n\n\n2\n31\n44\n\n\n3\n24\n28\n\n\n\n\n\nAgregando cada variável a um cluster obtemos então.\n\n\n\n\n\n\nidade_anos\nsem_pri\nCentróide\n\n\n\n\n1\n24\n17\n3\n\n\n2\n31\n26\n1\n\n\n3\n27\n28\n3\n\n\n4\n20\n33\n3\n\n\n5\n39\n39\n2\n\n\n6\n34\n51\n2\n\n\n7\n34\n21\n1\n\n\n8\n29\n33\n3\n\n\n9\n44\n18\n1\n\n\n10\n27\n40\n2\n\n\n11\n28\n47\n2\n\n\n12\n35\n50\n2\n\n\n13\n37\n29\n1\n\n\n14\n30\n29\n1\n\n\n15\n32\n45\n2\n\n\n16\n27\n32\n3\n\n\n17\n44\n32\n1\n\n\n18\n30\n42\n2\n\n\n19\n16\n21\n3\n\n\n20\n24\n21\n3\n\n\n21\n31\n32\n1\n\n\n22\n24\n36\n3\n\n\n23\n31\n34\n3\n\n\n24\n33\n47\n2\n\n\n25\n25\n50\n2\n\n\n26\n31\n21\n1\n\n\n27\n26\n21\n3\n\n\n28\n49\n19\n1\n\n\n29\n25\n25\n3\n\n\n30\n16\n31\n3\n\n\n31\n20\n32\n3\n\n\n32\n34\n42\n2\n\n\n33\n28\n38\n2\n\n\n34\n33\n16\n1\n\n\n35\n34\n21\n1\n\n\n36\n32\n20\n1\n\n\n37\n38\n32\n1\n\n\n38\n31\n40\n2\n\n\n39\n38\n24\n1\n\n\n40\n41\n27\n1\n\n\n\n\n\nCom base nesses novos grupos definimos então o novo centróide como sendo a média das variáveis de cada grupo, ou seja:\n\n\n\n\n\ncentroide\nidade_anos\nsem_pri\n\n\n\n\n1\n36.46667\n24.46667\n\n\n2\n31.33333\n44.25000\n\n\n3\n23.76923\n28.00000\n\n\n\n\n\nAgregando cada variável a seu novo grupo e seguindo o processo até o número de iterações pré definidas ou até que não tenha mais alterações nas coordenadas dos centros de cada cluster.\nNo R base já está incluso uma função para o método k-médias, kmeans(), que pode ser implementado de maneira simples. considere o banco já discutido\n\nkmeans.df <- df |>\n  kmeans(centers = 3, iter.max = 300)\nkmeans.df\n\nK-means clustering with 3 clusters of sizes 12, 16, 12\n\nCluster means:\n  idade_anos  sem_pri\n1   31.33333 44.25000\n2   25.06250 28.18750\n3   37.91667 23.33333\n\nClustering vector:\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \n 2  2  2  2  1  1  3  2  3  1  1  1  3  2  1  2  3  1  2  2  2  2  2  1  1  3 \n27 28 29 30 31 32 33 34 35 36 37 38 39 40 \n 2  3  2  2  2  1  1  3  3  3  3  1  3  3 \n\nWithin cluster sum of squares by cluster:\n[1] 412.9167 861.3750 669.5833\n (between_SS / total_SS =  67.6 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\nDe forma simples podemos identificar os centros e em qual cada uma das variáveis foi atribuida após as \\(N\\) iterações. Identificamos também a variância entre clusters, bem como a variância total e entre as variáveis de cada grupo. Essa variância se torna importânte na identificação do valor \\(k\\) estabelecido.\n\ndados_grupos <- kmeans.df |> broom::augment(df)\ncent <- kmeans.df$centers\n\n\ndados_grupos |> \n  ggplot(aes(x = idade_anos, y = sem_pri,col = .cluster)) +\n  geom_point() +\n  geom_point(aes(x = cent[1,1], y = cent[1,2]), color = \"black\", size = 3)+\n  geom_point(aes(x = cent[2,1], y = cent[2,2]), color = \"black\", size = 3)+\n  geom_point(aes(x = cent[3,1], y = cent[3,2]), color = \"black\", size = 3)\n\n\n\nkmeans.df\n\nK-means clustering with 3 clusters of sizes 12, 16, 12\n\nCluster means:\n  idade_anos  sem_pri\n1   31.33333 44.25000\n2   25.06250 28.18750\n3   37.91667 23.33333\n\nClustering vector:\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \n 2  2  2  2  1  1  3  2  3  1  1  1  3  2  1  2  3  1  2  2  2  2  2  1  1  3 \n27 28 29 30 31 32 33 34 35 36 37 38 39 40 \n 2  3  2  2  2  1  1  3  3  3  3  1  3  3 \n\nWithin cluster sum of squares by cluster:\n[1] 412.9167 861.3750 669.5833\n (between_SS / total_SS =  67.6 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\n\n\n6.2.5.2 Número Ideal de Grupos\nUma das formas já discutidas aqui sobre seleção do número ideal de \\(k\\) grupos é a pré utilização de um método hierárquico e análise de seu dendrograma. Porém, retomando os assuntos apresentados quando foi discutido PCA, podemos utilizar o scree plot da variação total como metodologia de definição do número ideal de clusters para o algorítmo. A utilização é realizada da mesma maneira, é feita a identificação do número \\(k\\) que sofra grande decréscimo da soma da variação dentro dos clusters para um número \\(k-1\\) e um pequeno em comparação com \\(k+1\\). A variação total é dada como:\n\\[\n\\sum^k_{i=1}\\sum_{j\\in C_i}d^2(x_j,c_i)\n\\] Sendo \\(C_i\\) centro do i-ésimo grupo e \\(x_j\\) a j-ésima variável do i-ésimo grupo. A função de distância mais usual é a euclidiana discutida anteriormente.\n\nvar_totais <- vector()\nfor(i in 1:10){\n  var_totais[i] <- (df |> kmeans(centers = i, iter.max = 400))$tot.withinss\n}\n\n\nqplot(1:10, var_totais, geom = \"line\")\nqplot(c(1:10), var_totais) + \n  geom_line() + \n  xlab(\"Número de clusters\") + \n  ylab(\"Soma das variâncias dentro dos grupos\") +\n  ggtitle(\"Scree Plot\") +\n  scale_x_discrete(limits=c(1:10))\n\n\n\nPodemos definir a partir disso possíveis números ideais como 3, 4 ou até mesmo 6.\n\n\n6.2.5.3 Algumas conclusões\nPara definirmos um modelo como sendo ótimo para aplicação, é necessário defir alguns parâmetros para determinar a qualidade de um modelo ou método. O k-médias por exemplo é um algoritmo muito sucetível a outliers, dados fora do padrão encontrado no banco de dados, que podem acabar por deixar de agrupar uma determinada variável ou simplesmente formar um grupo amais, sem que haja necessidade. Outro fator que é necessário manter a atenção é a determinação do formato do cluster. Muitos dos algoritmos consideram um formato esférico ou circular para as variáveis, veja o exemplo:\n\ndados_circulo <- data.frame(\n X = runif(5000, -1, 1),\n  Y = runif(5000, -1, 1)\n) |>\n  dplyr::filter(X^2 + Y^2 <= 0.2 | (X^2 + Y^2 <= 0.8 & X^2 + Y^2 >= 0.6))\n\n\nqplot(dados_circulo$X, dados_circulo$Y)\n\n\nÉ notável como o agrupamento deve ser realizando simplesmente olhando para o gráfico proposto, porém, algoritmos como k-médias não pensam da mesma forma,\n\ndados_circulo.km <- dados_circulo |> kmeans(centers = 2)\ndados_circulo <- dados_circulo.km |> broom::augment(dados_circulo)\ncent <- dados_circulo.km$centers\n\n\ndados_circulo |> \n  ggplot(aes(x = X, y = Y,col = .cluster)) +\n  geom_point() +\n  geom_point(aes(x = cent[1,1], y = cent[1,2]), color = \"black\", size = 3)+\n  geom_point(aes(x = cent[2,1], y = cent[2,2]), color = \"black\", size = 3)\n\n\n\nkmeans.df\n\nK-means clustering with 3 clusters of sizes 12, 16, 12\n\nCluster means:\n  idade_anos  sem_pri\n1   31.33333 44.25000\n2   25.06250 28.18750\n3   37.91667 23.33333\n\nClustering vector:\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \n 2  2  2  2  1  1  3  2  3  1  1  1  3  2  1  2  3  1  2  2  2  2  2  1  1  3 \n27 28 29 30 31 32 33 34 35 36 37 38 39 40 \n 2  3  2  2  2  1  1  3  3  3  3  1  3  3 \n\nWithin cluster sum of squares by cluster:\n[1] 412.9167 861.3750 669.5833\n (between_SS / total_SS =  67.6 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\nÉ perceptível que o método por particionamento em médias não foi eficaz para o banco de dados em questão. Ao utilizar a função hcut() para particionamento utilizando um método hierárquico obtemos uma melhor resposta para o agrupamento das variáveis\n\ndados_circulo.h <- hcut(dados_circulo[,1:2], k = 2, hc_method = \"single\")\nd_circulo.h <- cbind(dados_circulo[,1:2],cluster=dados_circulo.h$cluster)\n\n\nd_circulo.h |> \n  ggplot(aes(x = X, y = Y,col = cluster)) +\n  geom_point()\n\n\nOs métodos hierárquicos apresentados no entanto, por utilizarem da distância de uma variável a outra são limitados a utilização de banco de dados numéricos, o que nem sempre é o encontrado nos problemas reais, é necessário optar nesse caso por métodos e algoritmos que consigam fazer a distinção mesmo na presença de variáveis categóricas. Fator relevante para a escolha do melhor algoritmo é a capacidade de lidar com um grande volume de dados. No k-médias temos a opção por exemplo de pré definirmos o número de iterações. Considere um grupo com milhões de variáveis, ao utilizar um método de ligação simples hierárquico faremos aproximadamente um milhão de ligações para depois identificar o número ideal de grupos, caso esse não seja conhecido (Caso mais comum). O ideal então é a análise exploratória de seus dados para com base nos conhecimentos sobre os diferentes tipos de métodos, saber qual será o de melhor aplicação para o determinado problema. Nada o impede de aplicar mais de um método e após sua aplicação identificar qual foi o modelo ótimo para o problema.\n\n\n\n\nAnton, Howard, e Chris Rorres. 2001. Álgebra linear com aplicações. Vol. 8. Bookman Porto Alegre.\n\n\nJohnson, Richard Arnold, Dean W Wichern, et al. 2002. Applied multivariate statistical analysis. Vol. 5. 8. Prentice hall Upper Saddle River, NJ."
  },
  {
    "objectID": "tutorialr.html#instalação-do-r",
    "href": "tutorialr.html#instalação-do-r",
    "title": "Appendix A — Tutorial de R",
    "section": "A.2 Instalação do R",
    "text": "A.2 Instalação do R\nA seguir, será apresentado o passo a passo de como instalar o R e o RStudio para os três sistemas operacionais: Windows, MAC e Linux, respectivamente.\n\nA.2.1 R no Windows\nA forma mais simples de instalar o R consiste em primeiramente acessar a página do software pelo endereço https://cloud.r-project.org/. Ao acessar a página haverão três opções para download, sendo cada uma referente a um sistema operacional em específico. Assim, para conseguir instalar o software em um sistema operacional Windows basta primeiramente clicar no link Download R for Windows.\n\n\n\n\n\nPasso 1\n\n\n\n\nQuatro subdiretórios irão surgir, dentre eles é necessário clicar na base, pois este contém a distribuição base do R para instalação.\n\n\n\n\n\nPasso 2\n\n\n\n\nO subdiretório base irá redirecionar para uma página que contém o link de download do arquivo de instalação do software. Este por sua vez, pode ser identificado como Download + versão atual do R + for Windows.\n\n\n\n\n\nPasso 3\n\n\n\n\nFeito isso, um arquivo executável será baixado no computador, o qual, ao abri-lo, deverá escolher o idioma (português brasileiro) e simplesmente clicar em Avançar toda vez que o cliente de instalação requerer.\n\n\n\n\n\nPasso 4\n\n\n\n\n\n\n\n\n\nPasso 5\n\n\n\n\nAssim, uma instalação padrão do software será instalada no computador.\n\n\nA.2.2 R no MAC\nDa mesma forma a qual iniciamos a instalação do R no Windows também iniciaremos no MAC, onde é necessário acessar o endereço https://cloud.r-project.org/ e clicar no link Download R for macOS.\n\n\n\n\n\nPasso 1\n\n\n\n\nO link irá redirecionar para uma página com arquivos de extensão .pkg típicos de macOS. É importante verificar qual versão disponível é a ideal para seu sistema. A versão do tipo arm64.pkg é referente a versão mais recente do macOS na data deste material.\n\n\n\n\n\nPasso 2\n\n\n\n\nTendo feito o download do arquivo, basta abri-lo para um cliente de instalação ficar disponível, e então, para efetuar uma instalação padrão deve-se seguir as instruções do cliente sem customizações aditivas assim como foi feito para o Windows.\n\n\nA.2.3 R no Linux\nA instalação do R no Linux depende da distribuição sendo utilizada. Basta acessar o mesmo endereço https://cloud.r-project.org/ utilizado na instalação dos outros sistemas, e clicar no link Download R for Linux.\n\n\n\n\n\nPasso 1\n\n\n\n\nFeito isso irá aparecer as opções de distribuições para Linux em que o software está disponível para download, basta selecionar a distribuição compatível. Caso sua distribuição for Ubuntu por exemplo, clicamos nela no respectivo link.\n\n\n\n\n\nPasso 2\n\n\n\n\nAssim, irá ser redirecionado para uma página com as devidas instruções de instalação do R para a distribuição escolhida. Basta seguir as instruções para efetuar uma instalação padrão do software."
  },
  {
    "objectID": "tutorialr.html#instalação-do-rstudio",
    "href": "tutorialr.html#instalação-do-rstudio",
    "title": "Appendix A — Tutorial de R",
    "section": "A.3 Instalação do RStudio",
    "text": "A.3 Instalação do RStudio\nO RStudio é um conjunto de ferramentas integradas projetadas (IDE - Integrated Development Environment) da linguagem R para auxiliar na produtividade ao utilizar o R. Embora não seja obrigatório o seu uso, é um consenso na comunidade de que o uso do RStudio facilita o aprendizado enquanto acelera a produtividade do usuário, tornando-o indispensável principalmente para iniciantes.\nNo ano de 2022, RStudio iniciou um processo de transição de nome onde passou a se chamar Posit. O objetivo por de trás desse processo se dá na inclusão da comunidade de Python ao R, dado o crescimento notório do Python na área de análise de dados nos últimos anos e que ambas as linguagens se complementam.\nO primeiro passo para instalar o RStudio é acessar o site da Posit e ir até a página de download que pode ser acessada pelo endereço https://posit.co/download/rstudio-desktop/. Feito isso, a página irá apresentar algumas opções, dentre elas uma breve tabela com arquivos executáveis mais recentes disponíveis de instalação do RStudio.\n\n\n\n\n\nArquivos executáveis de instalação\n\n\n\n\nDentre os arquivos executáveis está a versão mais recente para Windows (retângulo vermelho), macOS (retângulo azul) e para diferentes distribuições do Linux (retângulo verde). É preciso fazer o download conforme o seu sistema operacional.\nApós o download basta abrir o arquivo executável baixado e seguir as instruções do cliente para que a instalação seja feita.\n\n\n\n\n\nRStudio aberto pela primeira vez"
  },
  {
    "objectID": "tutorialr.html#primeiros-passos-no-rstudio",
    "href": "tutorialr.html#primeiros-passos-no-rstudio",
    "title": "Appendix A — Tutorial de R",
    "section": "A.4 Primeiros passos no RStudio",
    "text": "A.4 Primeiros passos no RStudio\nO RStudio é uma ferramenta que por padrão é dividida em quatro painéis, sendo que cada um deles contêm abas com diferentes utilidades.\n\n\n\n\n\nPainéis do RStudio\n\n\n\n\nA seguir descrevemos melhor os painéis e algumas abas comumente utilizadas do RStudio:\n Editor/Scripts: local para escrever códigos (principalmente arquivos em formato .R).\n Console: onde se executa os códigos e visualiza resultados.\n Aqui, é possível acessar todos os objetos criados em Environment e o histórico de códigos executados em History e conectar fonte de dados em Connections.\n Nessa área, temos diversas utilidades frequentemente utilizadas:\n\npodemos acessar arquivos e pastas do computador pela aba Files;\nna aba Plots, visualizamos resultados em que são gerados figuras (como gráficos e tabelas), caso um comando desse tipo tenha sido executado;\nem Packages, podemos manusear pacotes (instalar, atualizar ou deletar);\nna aba Help temos acesso à documentação de uma determinada função quando utilizado o comando help() ou ?. Uma função nada mais é do que uma estrutura de código pronta com a forma de acesso nome(argumento) que recebe argumentos de entrada e retorna uma resposta. O próprio comando help() é uma função.\n\nO usuário pode alterar as configurações padrões do RStudio ao acessar as opções globais.\n\n\n\n\n\nOpções globais\n\n\n\n\nPara usuários iniciantes, é recomendável configurar a aparência e estrutura (layout) dos painéis conforme a própria preferência para tornar a experiência de uso mais confortável.\n\n\n\n\n\nMenu de aparência\n\n\n\n\nPodemos alterar o layout pelo menu Panel Layout. Usualmente, os painéis são estruturados de forma que o painel Console fique ao lado do painel de Script (Source/Editor), facilitando a visualização dos comandos rodados.\n\n\n\n\n\nMenu de estruturação dos painéis\n\n\n\n\n\nA.4.1 Projetos\nUma funcionalidade importante é a criação de projetos, permitindo dividir o trabalho em múltiplos ambientes, cada um com o seu diretório, documentos e workspace.\nPara criar um projeto, os seguintes passos podem ser seguidos:\n\nClique na opção File do menu, e então em New Project.\nClique em New Directory.\nClique em New Project.\nEscreva o nome do diretório (pasta) onde deseja manter seu projeto, exemplo: “my_project”.\nClique no botão Create Project.\n\nPara criar um novo script para escrever os códigos, vá em File -> New File -> R Script.\n\n\nA.4.2 Boas práticas\nComente bem o seu código: é possível fazer comentários usando o símbolo #. É sempre bom explicar o que uma variável armazena, o que uma função faz, por que alguns parâmetros são passados para uma determinada função, qual é o objetivo de um trecho de código, etc.\nEvite linhas de código muito longas: usar linhas de código mais curtas ajuda na leitura do código.\nEscreva um código organizado. Por exemplo, adote um padrão no uso de minúsculas e maiúsculas, uma lógica única na organização de pastas e arquivos, pode ser adotada uma breve descrição (como comentário) indicando o que um determinado script faz.\nCarregue todos os pacotes que irá usar sempre no início do arquivo: quando alguém abrir o seu código será fácil identificar quais são os pacotes que devem ser instalados e quais dependências podem existir."
  },
  {
    "objectID": "tutorialr.html#primeiros-passos-no-r",
    "href": "tutorialr.html#primeiros-passos-no-r",
    "title": "Appendix A — Tutorial de R",
    "section": "A.5 Primeiros passos no R",
    "text": "A.5 Primeiros passos no R\nO código pode ser escrito no Script e então ser executado ao apertar o botão Run (localizado no painel de Script) ou com o atalho no teclado Ctrl + Enter. É importante salientar que, apenas a linha em que o símbolo de inserção de código (barra vertical do cursor) estiver é que será executada. Para executar múltiplas linhas simultaneamente, é necessário selecionar as linhas desejadas e então utilizar o comando de execução mencionado.\nOutra forma de escrever e executar códigos é através do painel Console. Normalmente, o Console é utilizado para executar códigos sem muitas linhas de estruturação ou para fazer testes rápidos (ex: uso do R como calculadora). Para rodar o código diretamente pelo painel Console, basta escrevê-lo na linha em que contém o símbolo >, o qual indica que o R está pronto para receber comandos, e então pressionar a tecla Enter.\n\nA.5.1 R como calculadora\nUma das utilidades do R é utilizá-lo como uma calculadora, onde podemos realizar contas matemáticas simples até as mais complexas.\nPor padrão, o R entende as linhas de códigos da esquerda para a direita e de cima para baixo. No entanto, ao se deparar com operações matemáticas, ele respeita algumas prioridades. A operação com maior para a menor prioridade é: potenciação > multiplicação ou divisão > adição ou subtração. Caso haja a necessidade de alterar essa ordem, isso pode ser feito utilizando parênteses.\n\n# Adição.\n10 + 15\n\n[1] 25\n\n# Subtração.\n10 - 2\n\n[1] 8\n\n# Multiplicação.\n2 * 10\n\n[1] 20\n\n# Divisão.\n30/2\n\n[1] 15\n\n# Raiz quadrada.\nsqrt(4)\n\n[1] 2\n\n# Potência.\n2^2\n\n[1] 4\n\n# Potência > Multiplicação > Soma.\n2^2 + 5 * 2\n\n[1] 14\n\n# Multiplicação > Potência > Soma.\n2^2 + (5 * 2)\n\n[1] 14\n\n# Potência > Soma > Multiplicação.\n2 * (2^2 + 5) \n\n[1] 18\n\n\nCaso um comando incompleto seja dado, como 10 ^, o R mostrará um +. Isso não tem a ver com a soma e apenas que o R está esperando que o comando que estava sendo escrito seja finalizado. Para recomeçar, basta terminar a escrita do comando ou apenas pressionar Esc.\nVale também ressaltar que se um comando que o R não reconhece for dado, ele retornará uma mensagem de erro.\n\n\nA.5.2 Atribuição\nOs objetos (também chamados de variáveis) são “locais” onde são guardadas informações (números, textos etc). O ato de “guardar” informações dentro de objetos é chamado de atribuição, e pode ser feito com <- ou =. Embora ambas as formas funcionem, na prática, o sinal <- é usualmente utilizado para atribuições enquanto que o sinal = é utilizado para configurar argumentos de funções.\n\n# Variável x recebe o número 5 de diferentes formas.\nx <- 5 \n\nx = 5\n\ny = (2^2 + 6) - 4\nx <- y - 1\n\nUm ponto importante a se atentar é que o R é case sensitive, isto é, faz a diferenciação entre as letras minúsculas e maiúsculas. Portanto, x é diferente de X.\n\n# Dica: Podemos obter o output do comando ao colocá-lo em volta de ().\n(x <- 10/2)\n\n[1] 5\n\n# Ao chamar X obteremos um erro, pois a variável criada era minúscula.\nX\n\nError in eval(expr, envir, enclos): object 'X' not found\n\n\n\n\nA.5.3 Objetos em R\nExistem cinco classes básicas de objetos no R:\n\nCharacter: “UAH!”\nNumeric: 0.95 (números reais)\nInteger: 100515 (inteiros)\nComplex: 2 + 5i (números complexos, a + bi)\nLogical: TRUE (booleanos, TRUE/FALSE)\n\nApós realizar a atribuição, podemos verificar a classe do objeto com a função class().\n\n# Character/texto, deve estar entre aspas \"\".\nx <- \"gestante\"; \nclass(x) \n\n[1] \"character\"\n\n# Numeric/números reais.\nx <- 0.9 \nclass(x) \n\n[1] \"numeric\"\n\n# Integer/números inteiros, tem que ser atribuído com o valor acompanhado de um ‘L’.\nx <- 5L\nclass(x)\n\n[1] \"integer\"\n\n# Complex/números complexos.\nx <- 2 + 5i\nclass(x)\n\n[1] \"complex\"\n\n# logical/valores lógicos.\nx <- TRUE\nclass(x)\n\n[1] \"logical\"\n\n\nOs valores lógicos são apresentados em letra maiúscula. Isso é muito importante, pois o R diferencia letras maiúsculas de minúsculas. Então, valores lógicos só são reconhecidos se escritos como TRUE ou FALSE. Além disso, cada valor lógico assume um valor numérico, sendo TRUE referente ao valor 1 e FALSE referente ao valor 0.\n\n# Operações matemáticas com valores lógicos.\n(TRUE*2)^2 + TRUE + FALSE + 2*TRUE\n\n[1] 7\n\n\nMuitas vezes é do interesse do usuário apagar objetos que foram criados, principalmente se for rodar códigos prontos em um ambiente que outra pessoa estava trabalhando, pois pode haver objetos já criados com os mesmos nomes dos que se encontram no código/script de interesse, o que poderá levar a erros e dificuldades de execução. A remoção de objetos pode ser feito com a função rm() ou remove().\n\n# Criando o objeto x.\nx <- 20\nx\n\n[1] 20\n\n# Removendo o objeto x.\nrm(x)\nx\n\nError in eval(expr, envir, enclos): object 'x' not found\n\n# Removendo todos os objetos criados.\n(x <- 1)\n\n[1] 1\n\n(y <- 2)\n\n[1] 2\n\nrm(list=ls())\n\nx\n\nError in eval(expr, envir, enclos): object 'x' not found\n\ny\n\nError in eval(expr, envir, enclos): object 'y' not found\n\n\nVale notar que ao utilizar a função rm() ou a função remove() para remover todos os objetos criados, é necessário incluir um argumento chamado list onde utilizamos o sinal de = para especificar os objetos a serem deletados. A função ls() lista todos os objetos criados até o momento.\n\n\nA.5.4 Vetores\nNo R a estrutura mais básica de dados é chamada de Vector (vetor), podendo aparecer no formado Atomic (atômico) ou no formado de list (lista). Dentre os vetores atômicos existem quatro tipos, sendo eles: Character, Integer, Double e Logical.\n\nCom vetores podemos atribuir vários valores a um mesmo objeto. Para entrar com vários números (ou nomes, ou qualquer outro grupo de coisas), precisamos usar uma função para dizer ao programa que os valores serão combinados em um único vetor. Para criar vetores atômicos a função c() é a mais usual por podermos criar vetores atômicos de todos os tipos diretamente. Também podemos utilizar a função seq() e o símbolo : para criar vetores do tipo Integer, e a função rep() que é capaz de criar vetores Double, por exemplo. Além disso, podemos verificar o tipo do vetor com a função typeof().\n\n# Vetor Double com a função c().\n(vetor1 <- c(2.5, 3, 4/5))\n\n[1] 2.5 3.0 0.8\n\ntypeof(vetor1)\n\n[1] \"double\"\n\n# Vetor Integer com a função c().\n(vetor2 <- c(5L, 7L, 9L))\n\n[1] 5 7 9\n\ntypeof(vetor2)\n\n[1] \"integer\"\n\n# Vetor Character com a função c().\n(vetor3 <- c(\"hospital1\", \"hospital2\"))\n\n[1] \"hospital1\" \"hospital2\"\n\ntypeof(vetor3)\n\n[1] \"character\"\n\n# Vetor Logical com a função c().\n(vetor4 <- c(TRUE, FALSE, FALSE, TRUE))\n\n[1]  TRUE FALSE FALSE  TRUE\n\ntypeof(vetor4)\n\n[1] \"logical\"\n\n# Vetor Integer com a função seq().\n(vetor5 <- seq(1, 5))\n\n[1] 1 2 3 4 5\n\ntypeof(vetor5)\n\n[1] \"integer\"\n\n# Vetor Integer com o símbolo :.\n(vetor6 <- 1:10)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\ntypeof(vetor6)\n\n[1] \"integer\"\n\n# Vetor Double com a função rep(). \n(vetor7 <- rep(1,10))\n\n [1] 1 1 1 1 1 1 1 1 1 1\n\ntypeof(vetor7)\n\n[1] \"double\"\n\n\nÉ comum o usuário querer saber o tamanho do vetor que ele está trabalhando, isso pode ser feito com a função length(). Além disso, é importante ter certeza de que estamos trabalhando com um vetor atômico, o que pode ser verificado com a função is.vector().\n\n# Podemos construir um vetor com vetores dentro da função c().\n(vetor <- c(c(1, 2), rep(1, 2), seq(1, 2), 1:2))\n\n[1] 1 2 1 1 1 2 1 2\n\nis.vector(vetor)\n\n[1] TRUE\n\ntypeof(vetor)\n\n[1] \"double\"\n\nlength(vetor)\n\n[1] 8\n\n\nObserve que é possível criar um vetor com elementos de diferentes tipos. Sabemos que a função rep() gera um vetor de tipo Double e a seq() gera um vetor de tipo Integer, e ao criar um vetor utilizando a função c() em conjunto com estas obtemos um vetor de tipo Double, de forma que o R priorizou este tipo ao invés do Integer. No R isso é chamado de coerção, onde o vetor sendo criado irá manter o tipo de maior prioridade dentre os seus elementos, e os elementos de tipos com menor prioridade serão convertidos para o tipo prioritário. Isso ocorre, pois todos os elementos de um vetor atômico devem ter o mesmo tipo. Para os tipos apresentados temos como o de menor prioridade para o maior: Logical < Integer < Double < Character. Além disso, se considerarmos Complex e List, teremos List com maior prioridade seguido de Character e Complex.\nPode ser do interesse do usuário visualizar elementos específicos que existem dentro de um vetor, isso pode ser feito ao especificar a posição do elemento dentro do vetor entre os símbolos [].\n\n# vetor com varios elementos.\nvet <- c(TRUE, 5, 7L, \"hospital\")\ntypeof(vet)\n\n[1] \"character\"\n\n# elemento de posição 3.\nvet[3]\n\n[1] \"7\"\n\n# elementos das posições 2, 3 e 4.\nvet[2:4]\n\n[1] \"5\"        \"7\"        \"hospital\"\n\n\nAs operações vetoriais podem ser realizadas de maneira bastante intuitiva, pois em vetores atômicos as operações são realizadas elemento a elemento.\n\n# Operações com vetores.\nvetor1 <- c(4, 9, 16)\n(vetor1_menos1 <- vetor1 - 1)\n\n[1]  3  8 15\n\n(vetor1_vezes2 <- vetor1 * 2)\n\n[1]  8 18 32\n\n(vetor1_dividido2 <- vetor1/2)\n\n[1] 2.0 4.5 8.0\n\n(vetor1_raiz <- sqrt(vetor1))\n\n[1] 2 3 4\n\nvetor2 <- c(1, 2, 3)\n(vetor1_mais_vetor2 <- vetor1 + vetor2)\n\n[1]  5 11 19\n\n\nVamos agora considerar vetores de pesos (quilos) e alturas (metros) de 6 pessoas.\n\n# Vetores de peso e de quilo.\n(peso <- c(62, 70, 52, 98, 90, 70))\n\n[1] 62 70 52 98 90 70\n\n(altura <- c(1.70, 1.82, 1.75, 1.94, 1.84, 1.61))\n\n[1] 1.70 1.82 1.75 1.94 1.84 1.61\n\n# Obs: note que o separador decimal do R é um . (ponto).\n\nPodemos a partir dessas informações calcular o IMC. Vale lembrar que o IMC é dado pelo peso (em kg) dividido pela altura (em metros) ao quadrado.\n\n(imc <- peso/(altura^2))\n\n[1] 21.45329 21.13271 16.97959 26.03890 26.58318 27.00513\n\n\nÉ importante saber que, no R, vetores são a base dos demais objetos. Objetos com apenas um elemento, por exemplo, não são considerados escalares, mas vetores de tamanho um. Em outras palavras, os próprios elementos de um vetor são também vetores.\n\nelemento1 <- \"\"\nis.vector(elemento1)\n\n[1] TRUE\n\nlength(elemento1)\n\n[1] 1\n\nelemento2 <- 5\nis.vector(elemento2)\n\n[1] TRUE\n\nlength(elemento2)\n\n[1] 1\n\nelemento3 <- TRUE\nis.vector(elemento3)\n\n[1] TRUE\n\nlength(elemento3)\n\n[1] 1\n\n\nAlém dos vetores de formato atômico também existem os de formado lista, que diferente dos atômicos, as listas podem ter elementos de tipos diferentes de forma que não há necessidade do R efetuar coerções. Para criar listas no R podemos utilizar a função list().\n\n# Lista com vários tipos de elementos (inclusive listas).\n(lista <- list(5, \"hospital\", list(1:5), c(rep(1, 2)), seq(1, 2)))\n\n[[1]]\n[1] 5\n\n[[2]]\n[1] \"hospital\"\n\n[[3]]\n[[3]][[1]]\n[1] 1 2 3 4 5\n\n\n[[4]]\n[1] 1 1\n\n[[5]]\n[1] 1 2\n\nis.vector(lista)\n\n[1] TRUE\n\ntypeof(lista)\n\n[1] \"list\"\n\nlength(lista)\n\n[1] 5\n\n# Dica: podemos verificar a estrutura de qualquer objeto com a função str().\nstr(lista)\n\nList of 5\n $ : num 5\n $ : chr \"hospital\"\n $ :List of 1\n  ..$ : int [1:5] 1 2 3 4 5\n $ : num [1:2] 1 1\n $ : int [1:2] 1 2\n\n# Dica: podemos retornar uma lista para vetor atômico com a função unlist().\nunlist(lista)\n\n [1] \"5\"        \"hospital\" \"1\"        \"2\"        \"3\"        \"4\"       \n [7] \"5\"        \"1\"        \"1\"        \"1\"        \"2\"       \n\n\n\n\nA.5.5 Matrizes\nMatrizes são vetores numéricos com duas dimensões, sendo estas a linha e a coluna às quais o elemento pertence. No R podemos criar matrizes com a função matrix().\n\n# Criando uma matriz de 16 elementos com 4 linhas e 4 colunas.\n(matri <- matrix(seq(1,16), nrow = 4, ncol = 4))\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\nstr(matri)\n\n int [1:4, 1:4] 1 2 3 4 5 6 7 8 9 10 ...\n\n# Podemos verificar se é uma matriz com a função is.matrix().\nis.matrix(matri)\n\n[1] TRUE\n\n\nNote que os números de 1 a 16 foram dispostos na matriz coluna por coluna, ou seja, preenchendo de cima para baixo e depois da esquerda para a direita. Isso ocorre por padrão, pois a função matrix() possui um argumento chamado byrow = FALSE em que, para criar uma matriz em que é preenchida de elementos por linha, basta alterar o argumento para byrow = TRUE. Além disso, a função seq() está gerando os elementos da matriz enquanto o argumento nrow indica o número de linhas e ncol o número de colunas.\nPara visualizar um elemento específico de uma matriz podemos utilizar o mesmo método que usamos com vetores. Lembrando que matrizes ainda são vetores, porém, com uma dimensão a mais. Então, para visualizar um elemento específico devemos indicar a posição do elemento para todas as dimensões existentes, no caso das matrizes, para linha e coluna.\n\n# Obtendo linhas, colunas e elementos específicos.\nmatri[3,  ]   # seleciona a 3ª linha.\n\n[1]  3  7 11 15\n\nmatri[ , 2]   # seleciona a 2ª coluna.\n\n[1] 5 6 7 8\n\nmatri[1, 2]   # seleciona o elemento da primeira linha e segunda coluna.\n\n[1] 5\n\n\nPerceba que cada linha e cada coluna de uma matriz é um vetor (uma dimensão). Assim, podemos alterar uma linha ou uma coluna atribuindo um vetor de interesse, por exemplo.\n\n# substituindo a primeira linha e quarta coluna da matriz.\nmatri[1, ] <- c(9, 9, 9, 9)\nmatri\n\n     [,1] [,2] [,3] [,4]\n[1,]    9    9    9    9\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\nmatri[, 4] <- rep(1, 4)\nmatri\n\n     [,1] [,2] [,3] [,4]\n[1,]    9    9    9    1\n[2,]    2    6   10    1\n[3,]    3    7   11    1\n[4,]    4    8   12    1\n\n\nÉ de importância para o usuário verificar o tamanho (número de elementos) quando se trata de vetores. Porém, quando se trata de matrizes, é importante conhecer as dimensões além do número de elementos. Para verificar as dimensões de uma matriz podemos utilizar a função dim(), enquanto para o tamanho (número de elementos) ainda podemos utilizar a função length().\n\n# Verificando o tamanho e dimensões da matriz.\nlength(matri)\n\n[1] 16\n\ndim(matri)\n\n[1] 4 4\n\n\nComo sabemos que as linhas e colunas de uma matriz são vetores, podemos adicionar mais linhas e colunas a ela com os elementos que queremos. Para concatenar linhas e colunas em uma matriz podemos utilizar as funções rbind() e cbind() respectivamente.\n\nvet1 <- c(99, 98, 97, 95)\nvet2 <- c(0, 5, 7, 9, 99) \n(matri <- rbind(matri, vet1))\n\n     [,1] [,2] [,3] [,4]\n        9    9    9    1\n        2    6   10    1\n        3    7   11    1\n        4    8   12    1\nvet1   99   98   97   95\n\n(matri <- cbind(matri, vet2))\n\n                 vet2\n      9  9  9  1    0\n      2  6 10  1    5\n      3  7 11  1    7\n      4  8 12  1    9\nvet1 99 98 97 95   99\n\n\nOperações matemáticas entre matrizes e elementos são realizadas elemento a elemento assim como vetores. Porém, quando se trata de matrizes, é de interesse efetuar a multiplicação matricial clássica, o que pode ser feito com a operação %*% respeitando a equidade do número de colunas da matriz que pré-multiplica e o número de linhas da matriz que pós-multiplica.\n\n# Criando duas matrizes 2x2 (duas linhas e duas colunas).\n(matriz1 <- matrix(c(rep(1, 2), rep(2, 2)), nrow = 2))\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    1    2\n\n(matriz2 <- matrix(c(rep(2, 2), rep(2, 2)), nrow = 2))\n\n     [,1] [,2]\n[1,]    2    2\n[2,]    2    2\n\n# Soma duas matrizes (elemento a elemento).\nmatriz1 + matriz2\n\n     [,1] [,2]\n[1,]    3    4\n[2,]    3    4\n\n# Subtrai duas matrizes (elemento a elemento).\nmatriz1 - matriz2\n\n     [,1] [,2]\n[1,]   -1    0\n[2,]   -1    0\n\n# Divide duas matrizes (elemento a elemento).\nmatriz1/matriz2\n\n     [,1] [,2]\n[1,]  0.5    1\n[2,]  0.5    1\n\n# Multiplica duas matrizes (elemento a elemento).\nmatriz1 * matriz2\n\n     [,1] [,2]\n[1,]    2    4\n[2,]    2    4\n\n# Multiplicação matricial clássica.\nmatriz1 %*% matriz2\n\n     [,1] [,2]\n[1,]    6    6\n[2,]    6    6\n\n# Potência de uma matriz (elemento a elemento).\n(matriz3 <- matriz2^2)\n\n     [,1] [,2]\n[1,]    4    4\n[2,]    4    4\n\n# Raiz quadrada de uma matriz (elemento a elemento).\nsqrt(matriz3)\n\n     [,1] [,2]\n[1,]    2    2\n[2,]    2    2\n\n\n\n\nA.5.6 Fatores\nÉ muito comum termos que lidar com variáveis categóricas, ou seja, variáveis que possuem categorias intrínsecas em sua natureza. No R, existe uma classe de objetos chamada Fatores especificamente para representar esse tipo de variável (nominal e ordinal). Os fatores podem ser vistos como vetores de elementos numéricos inteiros (pois são assim internamente representados no R) e possuem rótulos (labels). Consequentemente, são vetores do tipo Double.\n\n# Criando um vetor/variável com a informação do sexo de 7 pessoas. \n(sexo1 <- c(\"Mulher\", \"Homem\", \"Homem\", \"Mulher\", \"Mulher\", \"Mulher\", \"Homem\"))\n\n[1] \"Mulher\" \"Homem\"  \"Homem\"  \"Mulher\" \"Mulher\" \"Mulher\" \"Homem\" \n\n# Verificando a classe da variável sexo1.\nclass(sexo1)\n\n[1] \"character\"\n\n# Transformando em fator.\n(sexo2 <- as.factor(sexo1))\n\n[1] Mulher Homem  Homem  Mulher Mulher Mulher Homem \nLevels: Homem Mulher\n\nclass(sexo2)\n\n[1] \"factor\"\n\n# Verificando os levels da variável de classe factor (sexo2).\nlevels(sexo2)\n\n[1] \"Homem\"  \"Mulher\"\n\n\nPodemos verificar que a variável é representada internamente por elementos numéricos inteiros ao tentar transformá-la em um vetor numérico com a função as.numeric().\n\n# Ao transformar sexo1 obteremos um vetor de dados faltantes (NA) por coerção.\nas.numeric(sexo1)\n\nWarning: NAs introduced by coercion\n\n\n[1] NA NA NA NA NA NA NA\n\n# Ao transformar sexo2 obteremos um vetor double com valores inteiros.\n(sexo2_num <- as.numeric(sexo2))\n\n[1] 2 1 1 2 2 2 1\n\ntypeof(sexo2_num)\n\n[1] \"double\"\n\n\nFatores possuem levels em ordem alfabética, e isso pode influenciar diretamente na hora de construir gráficos e realizar aplicações de modelos.\n\n\nA.5.7 Data Frame\nTrata-se de uma “tabela de dados” onde as colunas são as variáveis e as linhas são os registros, e as colunas podem ser de classes diferentes. Logo, a principal diferença entre data frame e matriz é que matrizes só podem conter elementos da mesma classe.\nPara criar data frame no R é utilizado a função data.frame().\n\n# Colunas/variáveis para o data frame.\nID <- seq(1,6)\npes <- c(62, 70, 52, 98, 90, 70)\nalt <- c(1.70, 1.82, 1.75, 1.94, 1.84, 1.61)\nimc <- pes/(alt^2)\n\n# Criando o data frame.\n(dados <- data.frame(ID = ID, peso = pes, altura = alt, imc = imc))\n\n  ID peso altura      imc\n1  1   62   1.70 21.45329\n2  2   70   1.82 21.13271\n3  3   52   1.75 16.97959\n4  4   98   1.94 26.03890\n5  5   90   1.84 26.58318\n6  6   70   1.61 27.00513\n\n\nPodemos pensar na estrutura de um data frame da mesma forma que de uma matriz. Se por acaso for do interesse olhar os dados de altura, por exemplo, basta acessar a coluna três do data frame.\n\n# Selecionando a variável \"altura\".\ndados[, 3]\n\n[1] 1.70 1.82 1.75 1.94 1.84 1.61\n\n\nEmbora possamos usar os mesmos métodos discutidos na seção de matrizes, quando se trata de data frames, usualmente selecionamos as variáveis de interesse sem ter que saber em qual coluna ela está. Isso pode ser feito ao utilizar o símbolo $, dessa forma a coluna será selecionada em forma de vetor.\n\n# Selecionando a variável \"altura\".\ndados$altura\n\n[1] 1.70 1.82 1.75 1.94 1.84 1.61\n\n# Dica: também é possível fazer a seleção de colunas da seguinte forma:\ndados[, c(\"altura\", \"peso\")]\n\n  altura peso\n1   1.70   62\n2   1.82   70\n3   1.75   52\n4   1.94   98\n5   1.84   90\n6   1.61   70\n\n\nUtilizando o mesmo símbolo podemos adicionar ou deletar colunas.\n\n# Adicionando a variável \"grupo\".\ngr <- c(rep(1,3),rep(2,3))\ndados$grupo <- gr\ndados\n\n  ID peso altura      imc grupo\n1  1   62   1.70 21.45329     1\n2  2   70   1.82 21.13271     1\n3  3   52   1.75 16.97959     1\n4  4   98   1.94 26.03890     2\n5  5   90   1.84 26.58318     2\n6  6   70   1.61 27.00513     2\n\n# Deletando a variável \"grupo\".\ndados$grupo <- NULL\ndados\n\n  ID peso altura      imc\n1  1   62   1.70 21.45329\n2  2   70   1.82 21.13271\n3  3   52   1.75 16.97959\n4  4   98   1.94 26.03890\n5  5   90   1.84 26.58318\n6  6   70   1.61 27.00513\n\n\nNote que ao adicionar variáveis a um data frame essa variável tem que ter o mesmo número de elementos que as demais variáveis, caso isso não seja respeitado o R ira retornar um erro.\nA estrutura de data frame é provavelmente a mais utilizada no dia a dia de quem analisa dados. Sabendo disso, existem algumas funções que são importantes de um usuário de R ter em mente.\n\nhead() - Mostra as primeiras 6 linhas.\ntail() - Mostra as últimas 6 linhas.\ndim() - Número de linhas e de colunas.\nnames() - Os nomes das colunas (variáveis).\nstr() - Estrutura do data frame. Mostra, entre outras coisas, a classe de cada coluna.\n\nAlgumas dessas funções já foram abordadas ao longo do texto. As funções de visualização head() e tail() possuem um argumento chamado n o qual podemos customizar o número de linhas que queremos visualizar.\n\nhead(dados, n = 4)\n\n  ID peso altura      imc\n1  1   62   1.70 21.45329\n2  2   70   1.82 21.13271\n3  3   52   1.75 16.97959\n4  4   98   1.94 26.03890\n\ntail(dados, n = 4)\n\n  ID peso altura      imc\n3  3   52   1.75 16.97959\n4  4   98   1.94 26.03890\n5  5   90   1.84 26.58318\n6  6   70   1.61 27.00513\n\ndim(dados)\n\n[1] 6 4\n\nnames(dados)\n\n[1] \"ID\"     \"peso\"   \"altura\" \"imc\"   \n\nstr(dados)\n\n'data.frame':   6 obs. of  4 variables:\n $ ID    : int  1 2 3 4 5 6\n $ peso  : num  62 70 52 98 90 70\n $ altura: num  1.7 1.82 1.75 1.94 1.84 1.61\n $ imc   : num  21.5 21.1 17 26 26.6 ...\n\n\nCada coluna do data frame pode ser interpretada como um vetor. Dessa forma, as operações de vetores discutidas anteriormente são válidas.\n\n# Cria uma coluna do produto de peso por altura.\ndados$pesovezesaltura <- dados$peso * dados$altura\ndados\n\n  ID peso altura      imc pesovezesaltura\n1  1   62   1.70 21.45329          105.40\n2  2   70   1.82 21.13271          127.40\n3  3   52   1.75 16.97959           91.00\n4  4   98   1.94 26.03890          190.12\n5  5   90   1.84 26.58318          165.60\n6  6   70   1.61 27.00513          112.70\n\n# Cria uma coluna de peso + cinco.\ndados$peso5 <- dados$peso + 5\ndados\n\n  ID peso altura      imc pesovezesaltura peso5\n1  1   62   1.70 21.45329          105.40    67\n2  2   70   1.82 21.13271          127.40    75\n3  3   52   1.75 16.97959           91.00    57\n4  4   98   1.94 26.03890          190.12   103\n5  5   90   1.84 26.58318          165.60    95\n6  6   70   1.61 27.00513          112.70    75\n\n# Cria uma coluna da metade do peso original.\ndados$pesometade <-  dados$peso/2\ndados\n\n  ID peso altura      imc pesovezesaltura peso5 pesometade\n1  1   62   1.70 21.45329          105.40    67         31\n2  2   70   1.82 21.13271          127.40    75         35\n3  3   52   1.75 16.97959           91.00    57         26\n4  4   98   1.94 26.03890          190.12   103         49\n5  5   90   1.84 26.58318          165.60    95         45\n6  6   70   1.61 27.00513          112.70    75         35\n\n\n\n\nA.5.8 Operadores lógicos\nSabemos que TRUE e FALSE são objetos que pertencem à classe logical, além de terem representação numérica de 1 e 0 respectivamente.\nA operação lógica nada mais é do que um teste que retorna verdadeiro (TRUE) ou falso (FALSE). Assim, podemos realizar comparações entre valores utilizando alguns operadores específicos.\n\n# Verifica se 9 é igual a 12.\n9 == 12\n\n[1] FALSE\n\n# Verifica se 12 é igual a 12.\n12 == 12\n\n[1] TRUE\n\n# Verifica se 9 é diferente de 12.\n9 != 12\n\n[1] TRUE\n\n# Verifica se 9 é maior que 5.\n9 > 5\n\n[1] TRUE\n\n# Verifica se 9 é maior ou igual a 9.\n9 >= 9\n\n[1] TRUE\n\n# Verifica se 4 é menor que 4.\n4 < 4\n\n[1] FALSE\n\n# Verifica se 4 é menor ou igual que 4.\n4 <= 4\n\n[1] TRUE\n\n\nPodemos notar que estes operadores funcionam bem com números, mas isso não é verdade quando se trata de objetos do tipo character (texto). Dentre esses, o operador == apenas funciona com números e o != funciona normalmente tanto com números quanto para textos. Os operadores >, >=, < e <= funcionam com textos pensando na ordem alfabética destes.\nPodemos utilizar operadores de comparação múltipla mais usuais em conjunto com estes discutidos para tornar as comparações ainda mais dinâmicas.\n\nE: & - será verdadeiro se todas operações forem TRUE.\n\n\nx <- 17\n\n# Verifica se x > 9 é verdadeiro E x < 50 é verdadeiro.\n(x > 9) & (x < 50)\n\n[1] TRUE\n\n# Verifica se x < 9 é verdadeiro E x < 50 é verdadeiro E x > 17 é verdadeiro.\n(x > 9) & (x < 50) & (x > 17)\n\n[1] FALSE\n\n\n\nOU: | - será verdadeiro se pelomenos uma operação for TRUE.\n\n\nx <- 17\n\n# Verifica se x < 9 é verdadeiro OU x < 50 é verdadeiro.\n(x < 9) | (x < 50)\n\n[1] TRUE\n\n# Verifica se x < 9 é verdadeiro OU x > 50 é verdadeiro OU x <= 17 é verdadeiro.\n(x < 9) | (x > 50) | (x <= 17)\n\n[1] TRUE\n\n\n\nNegação: ! - nega a resposta lógica da comparação.\n\n\nx <- 17\n\n# Retorna TRUE se x < 50 for FALSE, e FALSE caso contrário. \n!(x < 50)\n\n[1] FALSE\n\n\nPodemos verificar se um valor (ou conjunto de valores) está contido em um vetor utilizando o operador %in%.\n\nex <- 1:15\n\n# Verifica se os valores 3 e 5 fazem parte dos elementos do vetor ex.\nc(3, 5) %in% ex\n\n[1] TRUE TRUE\n\n# Dica: o operador %in% também funciona com character:\ntexto <- c(\"hospital1\", \"hospital2\", \"hospital3\", \"hospital4\", \"hospital5\")\nc(\"hospital5\", \"UTI\") %in% texto\n\n[1]  TRUE FALSE\n\n\nTodos esses operadores podem ser utilizados ao manipular data frames. Iremos aproveitar o data frame criado anteriormente e adicionar mais duas colunas de textos para realizar alguns testes.\n\n# Visualizando o data frame criado anteriormente\ndados\n\n  ID peso altura      imc pesovezesaltura peso5 pesometade\n1  1   62   1.70 21.45329          105.40    67         31\n2  2   70   1.82 21.13271          127.40    75         35\n3  3   52   1.75 16.97959           91.00    57         26\n4  4   98   1.94 26.03890          190.12   103         49\n5  5   90   1.84 26.58318          165.60    95         45\n6  6   70   1.61 27.00513          112.70    75         35\n\n# Adicionando a coluna sexo.\ndados$sexo <- c(\"M\", \"F\", \"M\", \"F\", \"F\", \"M\")\n\n# Adicionando a coluna olhos (preenchimento impreciso = F).\ndados$olhos <- c(\"preto\", \"castanho\", \"F\", \"preto\", \"azul\", \"F\")\ndados\n\n  ID peso altura      imc pesovezesaltura peso5 pesometade sexo    olhos\n1  1   62   1.70 21.45329          105.40    67         31    M    preto\n2  2   70   1.82 21.13271          127.40    75         35    F castanho\n3  3   52   1.75 16.97959           91.00    57         26    M        F\n4  4   98   1.94 26.03890          190.12   103         49    F    preto\n5  5   90   1.84 26.58318          165.60    95         45    F     azul\n6  6   70   1.61 27.00513          112.70    75         35    M        F\n\n# Utilizando o operador %in% para obter as linhas com a cor dos olhos imprecisa.\ndados[dados$olhos %in% dados$sexo, ]\n\n  ID peso altura      imc pesovezesaltura peso5 pesometade sexo olhos\n3  3   52   1.75 16.97959            91.0    57         26    M     F\n6  6   70   1.61 27.00513           112.7    75         35    M     F\n\n# %in% com ! para obter as linhas com a cor dos olhos correta.\ndados[!(dados$olhos %in% dados$sexo), ]\n\n  ID peso altura      imc pesovezesaltura peso5 pesometade sexo    olhos\n1  1   62   1.70 21.45329          105.40    67         31    M    preto\n2  2   70   1.82 21.13271          127.40    75         35    F castanho\n4  4   98   1.94 26.03890          190.12   103         49    F    preto\n5  5   90   1.84 26.58318          165.60    95         45    F     azul\n\n# Linhas onde o peso é menor que o imc + 40. Retorna apenas colunas peso e imc.\ndados[(dados$peso < (dados$imc + 40)), c(\"peso\", \"imc\")]\n\n  peso      imc\n3   52 16.97959\n\n\n\n\nA.5.9 Dados faltantes, infinitos e indefinições matemáticas\nDados faltantes é uma das coisas mais comuns em bases de dados, podendo surgir por diferentes fatores. No R, dados faltantes são representados por NA e é um símbolo que todo usuário deve conhecer e saber lidar. Além do NA, símbolos como NaN e Inf também são muito comuns no dia a dia.\n\nNA (Not Available): dado faltante/indisponível.\nNaN (Not a Number): indefinições matemáticas. Como 0/0 e log(-1).\nInf (Infinito): número muito grande ou o limite matemático. Aceita sinal negativo (-Inf).\n\n\nx <- c(1, 6, 9)\n\n# Retorna NA\nx[4]\n\n[1] NA\n\n# Retorna NaN\nlog(-10)\n\nWarning in log(-10): NaNs produced\n\n\n[1] NaN\n\n# Retorna Inf\n10^14321\n\n[1] Inf\n\n\nAo lidar com bases de dados é necessário saber verificar se ela apresenta dados faltantes.\n\n# Base de dados que estamos usando.\ndados\n\n  ID peso altura      imc pesovezesaltura peso5 pesometade sexo    olhos\n1  1   62   1.70 21.45329          105.40    67         31    M    preto\n2  2   70   1.82 21.13271          127.40    75         35    F castanho\n3  3   52   1.75 16.97959           91.00    57         26    M        F\n4  4   98   1.94 26.03890          190.12   103         49    F    preto\n5  5   90   1.84 26.58318          165.60    95         45    F     azul\n6  6   70   1.61 27.00513          112.70    75         35    M        F\n\n# Adiciona linhas com dados faltantes.\ndados <- rbind(dados, c(6, NA, 1.75, NA, 125, 99, 50, \"M\", \"castanho\"))\ndados <- rbind(dados, c(9, 50, NA, 50, 127, 97, 55, \"F\", \"azul\"))\n\n# Deleta colunas que não iremos mais usar.\ndados[, c(\"pesovezesaltura\", \"peso5\", \"pesometade\")] <- NULL\ndados\n\n  ID peso altura              imc sexo    olhos\n1  1   62    1.7 21.4532871972318    M    preto\n2  2   70   1.82 21.1327134404057    F castanho\n3  3   52   1.75 16.9795918367347    M        F\n4  4   98   1.94 26.0388989265597    F    preto\n5  5   90   1.84 26.5831758034026    F     azul\n6  6   70   1.61 27.0051309748852    M        F\n7  6 <NA>   1.75             <NA>    M castanho\n8  9   50   <NA>               50    F     azul\n\n# Ao incluir NA a variável imc passou a apresentar mais casas decimais.\n# Dica: podemos arredondar os valores do vetor alterados com a função round().\ndados[1:6, \"imc\"] <- round(as.numeric(dados[1:6, \"imc\"]), digits = 2) \ndados\n\n  ID peso altura   imc sexo    olhos\n1  1   62    1.7 21.45    M    preto\n2  2   70   1.82 21.13    F castanho\n3  3   52   1.75 16.98    M        F\n4  4   98   1.94 26.04    F    preto\n5  5   90   1.84 26.58    F     azul\n6  6   70   1.61 27.01    M        F\n7  6 <NA>   1.75  <NA>    M castanho\n8  9   50   <NA>    50    F     azul\n\n# Avalia se os elementos da coluna peso são NA ou não.\nis.na(dados$peso)\n\n[1] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE\n\n# Verifica se existe pelomenos 1 dado faltante no data frame.\nany(is.na(dados))\n\n[1] TRUE\n\n# Filtra apenas as linhas com NA na variável peso.\ndados[is.na(dados$peso),]\n\n  ID peso altura  imc sexo    olhos\n7  6 <NA>   1.75 <NA>    M castanho\n\n# Dica: as funções na.omit() e complete.cases() podem remover linhas com NA.\nna.omit(dados)\n\n  ID peso altura   imc sexo    olhos\n1  1   62    1.7 21.45    M    preto\n2  2   70   1.82 21.13    F castanho\n3  3   52   1.75 16.98    M        F\n4  4   98   1.94 26.04    F    preto\n5  5   90   1.84 26.58    F     azul\n6  6   70   1.61 27.01    M        F\n\ndados[complete.cases(dados), ]\n\n  ID peso altura   imc sexo    olhos\n1  1   62    1.7 21.45    M    preto\n2  2   70   1.82 21.13    F castanho\n3  3   52   1.75 16.98    M        F\n4  4   98   1.94 26.04    F    preto\n5  5   90   1.84 26.58    F     azul\n6  6   70   1.61 27.01    M        F\n\n\nPara lidar com dados faltantes é importante ter pelo menos uma ideia do motivo para eles existirem na base de dados sendo analisada. Muitas vezes não temos ideia desse motivo, e a melhor estratégia acaba sendo analisar os dados, incluindo e reportando com transparência os dados faltantes. Ao analisar dados sem excluir os casos faltantes, muitas vezes nos deparamos com erros inesperados que ocorrem por tentarmos usar funções que não estão considerando esses casos. Situações como essas exigem uma atenção a mais do usuário, tendo que pesquisar e ler documentações de funções para ter certeza do que a função sendo usada está fazendo.\n\n# Criando um vetor com dados faltante.\nvetor1 <- c(NA, 1, 1, 1, 5)\n\n# mean() calcula a média do vetor.\nmean(vetor1)\n\n[1] NA\n\n# Inclui argumento que desconsidera dado faltante caso existir.\nmean(vetor1, na.rm = TRUE)\n\n[1] 2\n\n# sum() calcula a soma dos elementos do vetor.\nsum(vetor1)\n\n[1] NA\n\n# Inclui argumento que desconsidera dado faltante caso existir.\nsum(vetor1, na.rm = TRUE)\n\n[1] 8\n\n\n\n\nA.5.10 Condicionamento: If e else\nAs estruturas if e else, também chamadas de condicionais, servem para executar códigos apenas se uma condição (teste lógico) for satisfeita.\n\nvalor1 <- 224\nvalor2 <- 225\n\n# Cria objeto \"resposta\" de acordo com uma condição.\nif (valor1 == valor2) { # se valor1 for igual ao valor2.\n  resposta <- 10 # resposta é 10.\n} else { # caso contrário.\n  resposta <- 15 # respota é 15.\n  }\nresposta\n\n[1] 15\n\n\nVeja que o R só executa o conteúdo das chaves {} se a expressão dentro dos parênteses () retornar TRUE. Além disso, note que a condição de igualdade é representada por dois iguais (==). Como dito anteriormente, apenas um igual (=) é símbolo de atribuição (preferível <-), em argumentos de estruturas condicionais queremos realizar comparações.\nPara utilizar mais condições podemos utilizar o else if ().\n\nvalor1 <- 224\nvalor2 <- 225\n\n# Cria objeto \"resposta\" de acordo com uma condição.\nif (valor1 == valor2) { # se valor1 for igual ao valor2.\n  resposta <- 10 # resposta é 10.\n} else if (valor1 > valor2) { # Se não, então valor1 é maior que valor2 ?\n  resposta <- 15 # então a resposta é 15.\n  } else { # caso contrário.\n    resposta <- 25 # respota é 25.\n    }\nresposta\n\n[1] 25\n\n\n\n\nA.5.11 Iterador for\nO for serve para repetir uma mesma tarefa para um conjunto de valores diferentes (realiza um loop). Cada repetição é chamada de iteração.\nComo exemplo, considere o vetor atribuído ao objeto vetor1 como segue:\n\nvetor1 <- c(1,20,50,60,100)\n\nPodemos criar um novo vetor que seja formado por cada elemento do vetor1 dividido por sua posição.\n\nvetor2 <- NULL\nfor (i in 1: length(vetor1)){\n  vetor2[i] <- vetor1[i]/i\n}\nvetor2\n\n[1]  1.00000 10.00000 16.66667 15.00000 20.00000\n\n\nNote que primeiro definimos o objeto vetor2, recebendo NULL. O NULL representa a ausência de um objeto e serve para já declarar algum objeto que receberá valor na sequência. Ao rodar o for, o vetor2 passa a ser um vetor de tamanho 5 (tamanho do vetor1).\nNo exemplo, temos 5 iterações e para cada valor de i, correndo de 1 até 5 (tamanho do vetor1), pegamos o valor do vetor1 na posição i e dividimos por i. Assim, formamos o vetor2.\n\n\nA.5.12 Funções\nFunções no R são nomes que guardam um código de R. A ideia é que sempre que rodar a função com os seus argumentos, o código que ela guarda será executado e o resultado será retornado.\nJá usamos anteriormente algumas funções que estão na base do R. Por exemplo, quando usamos class() para entender a classe do objeto que o R está entendendo. Colocamos um argumento dentro do parêntese e o R retornou qual a classe do objeto em questão.\nImportantes:\n\nSe a função tiver mais de um argumento, eles são sempre separados por vírgulas;\nCada função tem os seus próprios argumentos. Para saber quais são e como usar os argumentos de uma função, basta acessar a sua documentação. Uma forma de fazer isso é pela função help(), cujo argumento é o nome da função em questão.\n\n\nhelp(mean)\n\nVeja que abrirá a documentação sobre a função mean no menu “Help” do RStudio. Assim, é possível ver os argumentos e exemplos de uso da função.\nAinda sobre funções já presentes no R, vamos considerar agora a função sample. Veja a documentação dessa função para ver o que ela faz.\n\nhelp(sample)\n\nA função sample retorna uma amostra de um vetor com tamanho especificado em um de seus argumentos com ou sem reposição. Ela apresenta quatro argumentos na forma sample(x, size, replace = FALSE, prob = NULL), em que: x é o vetor do qual será amostrado o número de elementos especificado no argumento size, replace indica se é com ou sem reposição e prob é para especificar probabilidades de seleção.\nPodemos usar essa função para amostrar de um objeto dois elementos (size = 2) em uma seleção com reposição (replace = TRUE) e que a probabilidade de seleção seja a mesma para todos os elementos do vetor. No caso da probabilidade, como podemos ver na documentação da função sample, o default (padrão se o usuário não mudar o argumento) é ser a mesma probabilidade de seleção para todos os elementos. Assim, se o usuário nada especificar para esse argumento, o R entenderá o seu default. O mesmo vale para o argumento replace: caso fosse o interesse fazer a seleção sem reposição, não precisaríamos colocar esse argumento por seu default ser FALSE.\n\n\n[1] 2 2\n\n\nTambém poderíamos usar a mesma função sem colocar o nome dos argumentos, desde que o usuário entenda o que ela está fazendo.\n\nsample(vetor_am, 2 , TRUE) \n\n[1] 10  2\n\n\nNesse caso, é importante que se respeite a ordem dos argumentos: o vetor tem que ser o primeiro, o segundo argumento é size e assim por diante.\nVale ressaltar que as duas últimas saídas não necessariamente serão as mesmas, porque é feito um sorteio aleatório de dois elementos de vetor_am em cada uma delas.\nAlém de usar funções já prontas, podemos criar novas funções. Suponha que queremos criar uma função de dois argumentos que retorna o primeiro mais três vezes o segundo argumento.\n\nf_conta <- function(x, y) {\n  out <- x + 3 * y\n  return(out)\n}\n\nA função acima possui:\n\nnome: f_conta.\nargumentos: x e y.\no corpo out: <- x + 3 * y.\no que retorna: return(out).\n\nPara chamar a função e utilizá-la basta chamar pelo nome com os devidos argumentos, assim como temos feito até então.\n\nf_conta(x = 10, y = 20)\n\n[1] 70\n\n\nVeja que o cálculo acima retorna exatamente o mesmo que o seguinte:\n\nf_conta(y = 20, x = 10)\n\n[1] 70\n\n\nIsso acontece porque a ordem dos argumentos foi alterada, porém, mantendo seus devidos nomes. Se não quiser colocar os nomes dos argumentos, precisa tomar cuidado para não errar a ordem deles. Isso porque:\n\nf_conta(10,20)\n\n[1] 70\n\n\né diferente de:\n\nf_conta(20,10)\n\n[1] 50\n\n\n\n\nA.5.13 Como obter ajuda no R\nListamos aqui 3 maneiras para buscar ajuda no R:\n\nHelp/documentação do R (comandos help(nome_da_funcao) ou ?nome_da_funcao). Como exemplo:\n\n\nhelp(mean) \n?mean\n\n\nGoogle: especificar a linguagem é de suma importância na pesquisa, além de deixar o problema ou a função bem claro.\n\n\n\n\n\n\nPesquisa no Google\n\n\n\n\n\nComunidade: O Stack Overflow e o Stack Overflow em Português são sites de perguntas e respostas amplamente utilizados por todas as linguagens de programação.\n\n\n\nA.5.14 Pacotes\nComo dito quando falamos “Sobre o R”, o R apresenta funções na sua base e também em forma de pacotes (conjunto de funções bem documentado), que precisam ser instalados (uma vez no seu computador) e carregados na sessão de utilização do R (carregado em toda sessão aberta).\nDificilmente uma análise será feita apenas com as funções básicas do R e dificilmente não vai existir um pacote com as funções que você precisa. Por esse motivo, falamos a seguir em como instalar e carregar pacotes.\n\nA.5.14.1 Instalação de pacotes\n\nVia CRAN:\n\n\ninstall.packages(\"nome-do-pacote\")\n\nExemplo: Instalação do pacote dplyr.\n\ninstall.packages(\"dplyr\")\n\nNote que o nome do pacote está entre aspas.\n\nVia Github: Para instalar via Github precisa primeiramente instalar o pacote devtools.\n\n\ndevtools::install_github(\"nome-do-repo/nome-do-pacote\")\n\nExemplo:\n\ndevtools::install_github(\"tidyverse/dplyr\")\n\n\n\nA.5.14.2 Carregar pacotes\nUma vez que um pacote de interesse está instalado em sua máquina, para carregá-lo na sessão atual do R é só rodar a seguinte linha de comando:\n\nlibrary(nome-do-pacote)\n\nVeja que para carregar o pacote não se usa aspas.\nComo exemplo, o carregamento do pacote dplyr:\n\nlibrary(dplyr)\n\nSó é necessário instalar o pacote uma vez, mas é necessário carregá-lo toda vez que começar uma nova sessão.\nDado que o pacote está carregado ao rodar a função library(), todas as funções desse pacote podem ser usadas sem problemas.\nCaso você não queira carregar o pacote e apenas usar uma função específica do pacote, você pode usar nome-do-pacote::nome-da-funcao. Por exemplo:\n\ndplyr::distinct(...)\n\nTendo carregado o pacote dplyr anteriormente (pela função library()), não seria necessário colocar dplyr:: antes da função distinct do pacote.\n\n\n\nA.5.15 Materiais complementares\nLivros e Artigos:\n\nCritical Thinking in Clinical Research. Felipe Fregni & Ben M. W. Illigens. 2018.\nCHAPTER 3: Selecting the Study Population. In: Critical Thinking in Clinical Research by Felipe Fregni and Ben Illigens. Oxford University Press 2018.\nFandino W. Formulating a good research question: Pearls and pitfalls. Indian J Anaesth. 2019;63(8):611–616. doi:10.4103/ija.IJA_198_19\nRiva JJ, Malik KM, Burnie SJ, Endicott AR, Busse JW. What is your research question? An introduction to the PICOT format for clinicians. J Can Chiropr Assoc. 2012;56(3):167–171.\nExternal validity, generalizability, and knowledge utilization. Ferguson L1. J Nurs Scholarsh. 2004;36(1):16-22.\nPeter M Rothwell; Commentary: External validity of results of randomized trials: disentangling a complex concept, International Journal of Epidemiology, Volume 39, Issue 1, 1 February 2010, Pages 94–96, https://doi.org/10.1093/ije/dyp305\n\nSites:\n\nhttps://www.bmj.com/about-bmj/resources-readers/publications/statistics-square-one/1-data-display-and-summary\nhttp://www.sthda.com/english/wiki/statistical-tests-and-assumptions"
  },
  {
    "objectID": "tutorialr.html#vetores",
    "href": "tutorialr.html#vetores",
    "title": "Appendix A — Tutorial de R",
    "section": "A.6 Vetores",
    "text": "A.6 Vetores\nComo atribuir vários valores a um objeto? Para entrar com vários números (ou nomes, ou qualquer outro grupo de coisas), precisamos usar uma função para dizer ao programa que os valores serão combinados em um único vetor.\n\nx <- c(2,3,4)\nx\n\n[1] 2 3 4\n\ny <- seq(1,10)\ny\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nz <- rep(1,10)\nz\n\n [1] 1 1 1 1 1 1 1 1 1 1\n\na <- 1:10\na\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nbicho <-c(\"macaco\",\"pato\",\"galinha\",\"porco\")\nbicho\n\n[1] \"macaco\"  \"pato\"    \"galinha\" \"porco\"  \n\n\nE se quisermos visualizar o conteúdo da posição 2 no vetor bicho?\n\nbicho[2]\n\n[1] \"pato\"\n\n\nAs operações vetoriais podem ser realizadas de maneira bastante intuitiva. Como exemplos:\n\nx <- c(2,3,4)\nx\n\n[1] 2 3 4\n\nops <- x-1\nops\n\n[1] 1 2 3\n\nk <- x*2\nk\n\n[1] 4 6 8\n\n\nVamos agora considerar um vetor de pesos em kg e altura em metros de 6 pessoas.\n\npeso <- c(62, 70, 52, 98, 90, 70)\npeso\n\n[1] 62 70 52 98 90 70\n\naltura <- c(1.70, 1.82, 1.75, 1.94, 1.84, 1.61)\naltura\n\n[1] 1.70 1.82 1.75 1.94 1.84 1.61\n\n\nVale mencionar que o separador de decimais no R é . (ponto)!\nComo calcularia o IMC? Lembrando que o IMC é dado pelo peso (em kg) dividido pela altura (em metros) ao quadrado.\n\nimc <- peso/(altura^2)\nimc\n\n[1] 21.45329 21.13271 16.97959 26.03890 26.58318 27.00513\n\n\nPara saber o tamanho do vetor, use a função length().\n\nlength(imc)\n\n[1] 6"
  },
  {
    "objectID": "tutorialr.html#matrizes",
    "href": "tutorialr.html#matrizes",
    "title": "Appendix A — Tutorial de R",
    "section": "A.7 Matrizes",
    "text": "A.7 Matrizes\nMatrizes são vetores numéricos com duas dimensões, que são simplesmente a linha e a coluna às quais o elemento pertence.\n\nx <- matrix(seq(1,16), nrow=4,ncol=4)\nx\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\n\nNote que os números de 1 a 16 foram dispostos na matriz coluna por coluna ou seja, preenchendo de cima para baixo e depois da esquerda para a direita.\nComo sei qual elemento está na segunda linha e terceira coluna da matriz x?\n\nx[2,3]\n\n[1] 10\n\nx[3,  ]   # seleciona a 3ª linha\n\n[1]  3  7 11 15\n\nx[ , 2]   # seleciona a 2ª coluna\n\n[1] 5 6 7 8\n\nx[1, 2]   # seleciona o elemento da primeira linha e segunda coluna\n\n[1] 5\n\n\nE se eu quiser substituir a primeira linha por (13,15,19,30)?\n\nx[1,] <- c(13,15,19,30)\n\nx\n\n     [,1] [,2] [,3] [,4]\n[1,]   13   15   19   30\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\n\nSeja o vetor d:\n\nd <- c(128,124,213,234)\n\nE se quisermos substituir a terceira coluna por d?\n\nx[,3] <- d\n\nQual a dimensão da matriz x?\nVimos que para vetor usamos o comando length(). Serve para matriz também? Vamos testar!\n\nlength(x)\n\n[1] 16\n\n\nNote que retorna o número de colunas vezes o número de linhas (4*4=16). Mas o que quero saber é o numero de linhas e de colunas. Para isso, o comando é dim().\n\ndim(x)\n\n[1] 4 4\n\n\nPara concatenar linhas em uma matriz, podemos usar o comando rbind():\n\nvet <- c(2,20,12,34)\nx2 <- rbind(x,vet)\nx2\n\n    [,1] [,2] [,3] [,4]\n      13   15  128   30\n       2    6  124   14\n       3    7  213   15\n       4    8  234   16\nvet    2   20   12   34\n\n\nPara concatenar colunas em uma matriz, podemos usar o comando cbind():\n\nv2 <- c(25,10,15,4) \nx3 <- cbind(x,v2)\nx3\n\n                  v2\n[1,] 13 15 128 30 25\n[2,]  2  6 124 14 10\n[3,]  3  7 213 15 15\n[4,]  4  8 234 16  4"
  },
  {
    "objectID": "tutorialr.html#fatores",
    "href": "tutorialr.html#fatores",
    "title": "Appendix A — Tutorial de R",
    "section": "A.8 Fatores",
    "text": "A.8 Fatores\nFatores podem ser vistos como vetores de inteiros que possuem rótulos (labels). Eles são úteis para representar uma variável categórica (nominal e ordinal).\n\nsexo <- c(\"M\", \"H\", \"H\", \"H\", \"M\", \"M\", \"H\")\nsex <- as.factor(sexo)\nsex\n\n[1] M H H H M M H\nLevels: H M\n\nlevels(sex)\n\n[1] \"H\" \"M\""
  },
  {
    "objectID": "tutorialr.html#data-frame",
    "href": "tutorialr.html#data-frame",
    "title": "Appendix A — Tutorial de R",
    "section": "A.9 Data frame",
    "text": "A.9 Data frame\nTrata-se de uma “tabela de dados” onde as colunas são as variáveis e as linhas são os registros. Essas colunas podem ser de classes diferentes.\nEssa é a grande diferença entre data.frame’s e matrizes (matriz é só numerica).\nPosso criar um data frame no R com os vetores, por exemplo:\n\nID <- seq(1,6)\npes <- c(62, 70, 52, 98, 90, 70)\nalt <- c(1.70, 1.82, 1.75, 1.94, 1.84, 1.61)\nimc <- pes/(alt^2)\ndados <- data.frame(ID=ID,peso=pes,altura=alt, imc=imc)\ndados\n\n  ID peso altura      imc\n1  1   62   1.70 21.45329\n2  2   70   1.82 21.13271\n3  3   52   1.75 16.97959\n4  4   98   1.94 26.03890\n5  5   90   1.84 26.58318\n6  6   70   1.61 27.00513\n\n\nPosso pensar que o data frame tem a mesma ideia de matriz. Quero olhar os dados de altura, que sei que está na coluna 3.\n\ndados[,3]\n\n[1] 1.70 1.82 1.75 1.94 1.84 1.61\n\n\nMas existe uma maneira mais fácil de selecionar a variável de interesse sem ter que saber em qual coluna ela está.\nPor ser um data frame, posso usar $ da seguinte maneira:\n\ndados$altura\n\n[1] 1.70 1.82 1.75 1.94 1.84 1.61\n\n\nPutz, esqueci de colocar a variável de grupo no data frame. Tenho que criar tudo de novo? Não:\n\ngr <- c(rep(1,3),rep(2,3))\ndados$grupo <- gr\n\ndados\n\n  ID peso altura      imc grupo\n1  1   62   1.70 21.45329     1\n2  2   70   1.82 21.13271     1\n3  3   52   1.75 16.97959     1\n4  4   98   1.94 26.03890     2\n5  5   90   1.84 26.58318     2\n6  6   70   1.61 27.00513     2\n\n\nVeja que no “dados$grupo” foi inserido o objeto “gr”. Se “gr” não tivesse o mesmo número de linhas do data frame retornaria um erro.\nFunções úteis para data.frame:\nAinda não falamos com muito detalhes sobre funções no R, faremos isso mais adiante. Mas por enquanto, considere que sejam nomes já salvos no R e que, ao colocar o objeto da base de dados (no nosso exemplo é dados) dentro dos parênteses, retorna algumas informações úteis sobre a base de dados. São algumas delas:\n\nhead() - Mostra as primeiras 6 linhas.\ntail() - Mostra as últimas 6 linhas.\ndim() - Número de linhas e de colunas.\nnames() - Os nomes das colunas (variáveis).\nstr() - Estrutura do data.frame. Mostra, entre outras coisas, as classes de cada coluna.\n\n\nhead(dados)\n\n  ID peso altura      imc grupo\n1  1   62   1.70 21.45329     1\n2  2   70   1.82 21.13271     1\n3  3   52   1.75 16.97959     1\n4  4   98   1.94 26.03890     2\n5  5   90   1.84 26.58318     2\n6  6   70   1.61 27.00513     2\n\ndim(dados)\n\n[1] 6 5\n\nnames(dados)\n\n[1] \"ID\"     \"peso\"   \"altura\" \"imc\"    \"grupo\" \n\nstr(dados)\n\n'data.frame':   6 obs. of  5 variables:\n $ ID    : int  1 2 3 4 5 6\n $ peso  : num  62 70 52 98 90 70\n $ altura: num  1.7 1.82 1.75 1.94 1.84 1.61\n $ imc   : num  21.5 21.1 17 26 26.6 ...\n $ grupo : num  1 1 1 2 2 2"
  },
  {
    "objectID": "tutorialr.html#operadores-lógicos",
    "href": "tutorialr.html#operadores-lógicos",
    "title": "Appendix A — Tutorial de R",
    "section": "A.10 Operadores lógicos",
    "text": "A.10 Operadores lógicos\nA operação lógica nada mais é do que um teste que retorna verdadeiro (TRUE) ou falso (FALSE). Esses dois valores recebem uma classe especial: logical.\n\nIgual a: ==\n\nVamos testar se um valor é igual ao outro.\nExemplo:\n\n10==11\n\n[1] FALSE\n\n11==11\n\n[1] TRUE\n\n\nNo primeiro retornou FALSE, pois realmente 10 não é igual a 11 e no segundo caso acima retornou TRUE, pois realmente 11 é igual a 11.\nDe maneira análoga funciona para os operadores abaixo:\n\nDiferente de: !=\n\nExemplo:\n\n10!=11\n\n[1] TRUE\n\n\n\nMaior que: >\nMaior ou igual: >=\nMenor que: <\nMenor ou igual: <=\n\nExemplos:\n\n10>5\n\n[1] TRUE\n\n10>=10\n\n[1] TRUE\n\n4<4\n\n[1] FALSE\n\n4<=4\n\n[1] TRUE\n\n\n\nUm outro operador muito útil é o %in%. Com ele, podemos verificar se um valor está dentro de um vetor.\n\n\nex <- 1:15\n3 %in% ex\n\n[1] TRUE\n\n\n\nE: & - será verdadeiro se os dois forem TRUE.\n\n\nx <- 15\nx > 10 & x < 30\n\n[1] TRUE\n\nx < 10 & x < 30\n\n[1] FALSE\n\n\n\nOU: | - será verdadeiro se um dos dois forem TRUE.\n\n\nx <- 15\nx > 10 | x < 30\n\n[1] TRUE\n\nx < 10 | x < 30\n\n[1] TRUE\n\n\n\nNegação: !\n\n\nx <- 15\n!x<30\n\n[1] FALSE"
  },
  {
    "objectID": "tutorialr.html#dados-faltantes-infinitos-e-indefinições-matemáticas",
    "href": "tutorialr.html#dados-faltantes-infinitos-e-indefinições-matemáticas",
    "title": "Appendix A — Tutorial de R",
    "section": "A.11 Dados faltantes, infinitos e indefinições matemáticas",
    "text": "A.11 Dados faltantes, infinitos e indefinições matemáticas\n\nNA (Not Available): dado faltante/indisponível. Exemplo:\n\n\nx <- c(1,6,9)\nx[4]\n\n[1] NA\n\n\nRetornou NA porque não há elemento na posição 4 do vetor x.\n\nNaN (Not a Number): indefinições matemáticas. Como 0/0 e log(-1). Exemplo:\n\n\nlog(-10)\n\n[1] NaN\n\n\n\nInf (Infinito): número muito grande ou o limite matemático. Aceita sinal negativo (-Inf). Exemplo:\n\n\n10^14321\n\n[1] Inf"
  },
  {
    "objectID": "tutorialr.html#condicionamento-if-e-else",
    "href": "tutorialr.html#condicionamento-if-e-else",
    "title": "Appendix A — Tutorial de R",
    "section": "A.12 Condicionamento: If e else",
    "text": "A.12 Condicionamento: If e else\nAs estruturas if e else servem para executar um código apenas se uma condição (teste lógico) for satisfeita.\n\na <- 224\nb <- 225\nif (a==b) { \n  v <- 10\n} else {\n  v <- 15\n  }\nv\n\n[1] 15\n\n\nVeja que o R só executa o conteúdo das chaves {} se a expressão dentro dos parênteses () retornar TRUE.\nNote que a condição de igualdade é representada por dois iguais (==). Como dito anteriormente, apenas um igual (=) é símbolo de atribuição (preferível <-).\nVeja outro exemplo:\n\na <- 224\nb <- 225\nif (a==b) { \n  v <- 10\n} else if (a > b) {\n  v <- 15\n  } else {\n    v <- 25\n    }\nv\n\n[1] 25\n\n\nVeja que nesse exemplo gostaria de usar mais de duas condições, e por isso usamos a estrutura intermediária else if."
  },
  {
    "objectID": "tutorialr.html#iterador-for",
    "href": "tutorialr.html#iterador-for",
    "title": "Appendix A — Tutorial de R",
    "section": "A.13 Iterador for",
    "text": "A.13 Iterador for\nO for serve para repetir uma mesma tarefa para um conjunto de valores diferentes. Cada repetição é chamada de iteração.\nComo exemplo, considere o vetor atribuído ao objeto m como segue:\n\nm <- c(1,20,50,60,100)\n\nQuero criar um novo vetor, p digamos, que seja formado por cada elemento de m dividido por sua posição.\n\np <- NULL\nfor (i in 1: length(m)){\n  p[i] <- m[i]/i\n}\np\n\n[1]  1.00000 10.00000 16.66667 15.00000 20.00000\n\n\nNote que primeiro definimos o objeto p, recebendo NULL. O NULL representa a ausência de um objeto e serve para já declarar algum objeto que receberá valor na sequência. No caso, ao rodar o for, o p é um vetor de tamanho 5 (tamanho do vetor m).\nNo exemplo, temos 5 iterações e para cada valor de i, correndo de 1 até 5 (tamanho de m), pegamos o valor de m na posição i e dividimos por sua posição. Assim, formamos o vetor p."
  },
  {
    "objectID": "tutorialr.html#funções",
    "href": "tutorialr.html#funções",
    "title": "Appendix A — Tutorial de R",
    "section": "A.14 Funções",
    "text": "A.14 Funções\nFunções no R são nomes que guardam um código de R. A ideia é que sempre que rodar a função com os seus argumentos, o código que ela guarda será executado e o resultado será retornado.\nJá usamos anteriormente algumas funções que estão na base do R. Por exemplo, quando usamos class() para entender a classe do objeto que o R está entendendo. Colocamos um argumento dentro do parênteses e o R retornou qual a classe do objeto em questão. Relembre o que falamos ao perguntar ao R qual a classe do vetor oi criado:\n\noi <- c(10,20,2,1,0.5)\nclass(oi)\n\n[1] \"numeric\"\n\n\nAgora vamos conversar sobre outra função já criada e disponibilizada na base do R: mean. Essa função retorna a média do vetor que está em seu argumento. Vamos calcular a média dos valores do vetor oi:\n\nmean(oi)\n\n[1] 6.7\n\n\nConsidere que, por algum motivo, tenha no vetor oi uma observação faltante. No R, dado faltante é caracterizado por NA.\n\noi <- c(10,20,2,1,0.5,NA)\n\nPerceba que, apesar de NA ser um texto, não coloquei entre aspas porque quero falar para o R que naquela posição não tem valor e o R entende isso ao ler NA (sem aspas). Se colocar entre aspas, ele entenderá como sendo um texto e não mais como valor faltante.\n\nmean(oi)\n\n[1] NA\n\n\nComo não sabemos o valor do elemento na posição 6 do vetor oi, o R não teria como calcular a média de todos os 6 valores e por isso devolve NA. No entanto, queremos calcular a média dos elementos de oi ao retirar os valores faltantes, ou seja, queremos fazer: (10+20+2+1+0.5)/5. Então devemos falar para o R o que queremos, e para isso podemos utilizar o argumento na.rm = TRUE:\n\nmean(oi,na.rm = TRUE)\n\n[1] 6.7\n\n\nImportantes:\n\nSe a função tiver mais de um argumento, eles são sempre separados por vírgulas;\nCada função tem os seus próprios argumentos. Para saber quais são e como usar os argumentos de uma função, basta acessar a sua documentação. Uma forma de fazer isso é pela função help, cujo argumento é o nome da função que precisa de ajuda:\n\n\nhelp(mean)\n\nVeja que abrirá a documentação sobre a função mean no menu “Help” do RStudio, e lá é possível ver os argumentos e exemplos de uso da função em questão.\nAinda sobre funções já presentes no R, vamos considerar agora a função sample. Veja a documentação dessa função para ver o que ela faz:\n\nhelp(sample)\n\nA função sample retorna uma amostra de um vetor com tamanho especificado em um de seus argumentos com ou sem reposição. Ela apresenta quatro argumentos: sample(x, size, replace = FALSE, prob = NULL), em que: x é o vetor do qual será amostrado o número de elementos especificado no argumento size, seja com ou sem reposição (argumento replace) e com dadas probabilidades de seleção, especificadas em prob.\nQuero usar essa função para amostrar do objeto oi (x=oi) dois elementos (size=2) em uma seleção com reposição (replace = TRUE) e que a probabilidade de seleção seja a mesma para todos os elementos do vetor oi. No caso da probabilidade, como podemos ver na documentação da função sample, o default (padrão se o usuário não mudar o argumento) é ser a mesma probabilidade de seleção para todos os elementos. Assim, se o usuário nada especificar para esse argumento, o R entenderá o seu default. O mesmo vale para o argumento replace: caso fosse o interesse fazer a seleção sem reposição, não precisaríamos colocar esse argumento porque seu default é FALSE.\n\n\n\n\nsample(x=oi,size=2,replace=TRUE) #não colocamos argumento prob porque vamos usar o seu default (probs iguais).\n\n[1]  2 10\n\n\nTambém poderíamos usar a mesma função sem colocar o nome dos argumentos:\n\nsample(oi,2,TRUE) \n\n[1]  2 20\n\n\nMas, nesse caso, é importante que se respeite a ordem dos argumentos: o vetor tem que ser o primeiro, o segundo argumento é size e assim por diante.\nVale ressaltar que as duas últimas saídas não necessariamente serão as mesmas, porque é feito um sorteio aleatório de dois elementos de oi em cada uma delas.\nAlém de usar funções já prontas, podemos criar novas funções. Suponha que queremos criar uma função de dois argumentos que retorna o primeiro mais três vezes o segundo argumento. Criamos a função no que segue:\n\nf_conta <- function(x,y) {\n  out <- x+3*y\n  return(out)\n}\n\nA função acima tem:\n\no nome: f_conta;\nos argumentos: x e y;\no corpo out: <- x+3*y; e\no que retorna: return(out).\n\nSuponha que eu queira fazer a conta 10+3*20. Podemos fazer isso ao chamar a função criada f_conta.\n\nf_conta(x=10,y=20)\n\n[1] 70\n\n\nVeja que o cálculo acima retorna exatamente o mesmo que o seguinte:\n\nf_conta(y=20,x=10)\n\n[1] 70\n\n\nIsso acontece porque mudei a ordem dos argumentos, mas acompanhado com os nomes dos argumentos. Se eu não quiser colocar os nomes dos argumentos, precisa tomar cuidado para não errar a ordem deles. Pois:\n\nf_conta(10,20)\n\n[1] 70\n\n\né diferente de\n\nf_conta(20,10)\n\n[1] 50"
  },
  {
    "objectID": "tutorialr.html#como-obter-ajuda-no-r",
    "href": "tutorialr.html#como-obter-ajuda-no-r",
    "title": "Appendix A — Tutorial de R",
    "section": "A.15 Como obter ajuda no R",
    "text": "A.15 Como obter ajuda no R\nListamos aqui 3 maneiras para buscar ajuda no R:\n\nHelp/documentação do R (comandos help(nome_da_funcao) ou ?nome_da_funcao). Como exemplo,\n\n\nhelp(mean) #ou\n?mean\n\n\nGoogle Na Figura @ref(fig:help) está o exemplo de busca de ajuda no Google. Repare no ‘r’ no início da busca, isso pode ajudar.\n\n\n\n\n\n\nPesquisa no Google\n\n\n\n\n\nComunidade O Stack Overflow e o Stack Overflow em Português são sites de Pergunta e Resposta amplamente utilizados por todas as linguagens de programação, e o R é uma delas."
  },
  {
    "objectID": "tutorialr.html#pacotes",
    "href": "tutorialr.html#pacotes",
    "title": "Appendix A — Tutorial de R",
    "section": "A.16 Pacotes",
    "text": "A.16 Pacotes\nComo dito quando falamos “Sobre o R”, o R apresenta funções na sua base e também em forma de pacotes (conjunto de funções bem documentado), que precisam ser instalados (uma vez no seu computador) e carregados na sessão de utilização do R (carregado em toda sessão aberta).\nDificilmente você vai fazer uma análise apenas com as funções básicas do R e dificilmente não vai existir um pacote com as funções que você precisa. Por esse motivo, falamos a seguir em como instalar e carregar pacotes.\n\nA.16.1 Instalação de pacotes\n\nVia CRAN:\n\n\ninstall.packages(\"nome-do-pacote\")\n\nExemplo: Instalação do pacote dplyr.\n\ninstall.packages(\"dplyr\")\n\nNote que o nome do pacote está entre aspas.\n\nVia Github: Para instalar via Github, precisa primeiramente instalar o pacote devtools.\n\n\ndevtools::install_github(\"nome-do-repo/nome-do-pacote\")\n\nExemplo:\n\ndevtools::install_github(\"tidyverse/dplyr\")\n\n\n\nA.16.2 Carregar pacotes\nUma vez que um pacote de interesse está instalado em sua máquina, para carregá-lo na sessão atual do R é só rodar a seguinte linha de comando:\n\nlibrary(nome-do-pacote)\n\nVeja que para carregar o pacote não se usa aspas.\nComo exemplo, o carregamento do pacote dplyr:\n\nlibrary(dplyr)\n\nSó é necessário instalar o pacote uma vez, mas é necessário carregá-lo toda vez que começar uma nova sessão.\nDado que o pacote está carregado ao rodar a função library(), todas as funções desse pacote podem ser usadas sem problemas.\nCaso você não queira carregar o pacote e apenas usar uma função específica do pacote, você pode usar nome-do-pacote::nome-da-funcao. Por exemplo:\n\ndplyr::distinct(...)\n\nSe você tivesse carregado o pacote dplyr anteriormente (pela função library()), não seria necessário colocar dplyr:: antes da função distinct do pacote."
  },
  {
    "objectID": "tutorialr.html#materiais-complementares",
    "href": "tutorialr.html#materiais-complementares",
    "title": "Appendix A — Tutorial de R",
    "section": "A.17 Materiais complementares",
    "text": "A.17 Materiais complementares\n\nCritical Thinking in Clinical Research. Felipe Fregni & Ben M. W. Illigens. 2018.\nSites:\n\nhttps://www.bmj.com/about-bmj/resources-readers/publications/statistics-square-one/1-data-display-and-summary\nhttp://www.sthda.com/english/wiki/statistical-tests-and-assumptions\n\nCHAPTER 3: Selecting the Study Population. In: Critical Thinking in Clinical Research by Felipe Fregni and Ben Illigens. Oxford University Press 2018.\nFandino W. Formulating a good research question: Pearls and pitfalls. Indian J Anaesth. 2019;63(8):611–616. doi:10.4103/ija.IJA_198_19\nRiva JJ, Malik KM, Burnie SJ, Endicott AR, Busse JW. What is your research question? An introduction to the PICOT format for clinicians. J Can Chiropr Assoc. 2012;56(3):167–171.\nExternal validity, generalizability, and knowledge utilization. Ferguson L1. J Nurs Scholarsh. 2004;36(1):16-22.\nPeter M Rothwell; Commentary: External validity of results of randomized trials: disentangling a complex concept, International Journal of Epidemiology, Volume 39, Issue 1, 1 February 2010, Pages 94–96, https://doi.org/10.1093/ije/dyp305"
  },
  {
    "objectID": "descritiva.html#medidas-resumo",
    "href": "descritiva.html#medidas-resumo",
    "title": "4  Análise exploratória dos dados",
    "section": "4.1 Medidas-resumo",
    "text": "4.1 Medidas-resumo\nUma medida-resumo é uma construção matemático/estatística que tenta capturar em um único número um comportamento presente nos dados. Quatro grandes grupos de medidas podem ser considerados para resumir variáveis quantitativas, são elas: posição, dispersão, assimetria e curtose. Vejamos agora que medidas são essas e como interpretá-las.\n\n4.1.1 Medidas de posição\nAs medidas de posição, como o nome diz, indicam posições de interesse de valores da variável. Por exemplo, se idade é a variável de interesse investigada em um grupo de pessoas, e se quer trazer um informação resumida dela no grupo, apresentar a menor e a maior idade encontrada, valores típicos da idade no grupo, são exemplos de medidas de posição.\nDe maneira geral, vamos explorar aqui as seguintes medidas posição: valor mínimo, valor máximo, percentis e medidas de tendência central, tais como moda, média e mediana. Os valores mínimo e máximo de uma variável quantitativa estão relacionados, respectivamente, com o menor e o maior valor observado da variável analisada.\nMedidas que buscam descrever um valor típico que a variável apresenta são chamados de medidas de tendência ou posição central. Mas o que seria uma valor típico? Como podemos definir isso? A resposta não é única e, por isso, existem diferentes medidas de tendência central. Por exemplo, se o valor típico considerado for aquele que mais se repete no conjunto de dados para variável, o que temos é a moda. Se o valor típico for aquele que ocupa uma posição central no conjunto de dados, de tal forma que 50% dos dados observados estão abaixo desse valor e os demais 50% estão acima, o que temos é a mediana. Agora, se o valor típico considerado for pensado como um ponto de equilíbrio das observações da variável, então temos a média.\nPor definição, a medida estatística moda corresponde aos(s) valor(es) mais frequente(s) do conjunto de dados observados para uma variável. Conjunto de dados que não apresentam valores repetidos são considerados amodais. Um conjunto de dados é bimodal se tiver duas modas, indicando que não apenas um único valor, mas dois valores do conjunto de dados apresentam frequências igualmente mais altas que os demais valores. Usando de mesmo raciocínio, havendo três ou mais valores modais em um conjunto de dados, dizemos que o conjunto de dados é trimodal ou multimodal, respectivamente. Vale citar que a moda também pode ser obtida para variáveis qualitativas.\nA média é a medida obtida ao somar todos os valores da variável e dividí-la pela quantidade de dados observados. Matematicamente, considere \\(x_1\\), \\(x_2\\), …, \\(x_n\\) as observações de uma variável \\(X\\), assim a média é definida como:\n\\[\\begin{equation}\n\\bar{x} = \\frac{\\sum_{i = 1}^n x_i}{n}.\n\\end{equation}\\]\nPara entender essa medida como ponto de equilíbrio, vamos representar cada valor observado como pesos de mesma massa e distribuí-los sobre uma reta de massa desprezível nas posições referentes aos valores da variável em questão. Nosso objetivo agora é encontrar um ponto de apoio nessa reta de tal forma que ela e os pesos corretamente posicionados nela fiquem perfeitamente equilibrados, similar a uma balança. A média é o único local em que se pode localizar o ponto de apoio na reta de forma a obter um perfeito equilíbrio da reta e dos pesos. Para ilustrar essa ideia, apresentamos a seguir uma representação gráfica considerando o subconjunto da variável idade {22, 28, 29, 34, 34, 35, 36, 36, 37, 39}, cuja média é 33.\n\n\n\n\n\n\n\n(a) Ponto de equilíbrio na média\n\n\n\n\n\n\n\n\n\n(b) Ponto de equilíbrio fora da média\n\n\n\n\nFigura 4.1: Apresentando a média como ponto de equilíbrio\n\n\nNo início dessa seção, apresentamos a noção intuitiva do que representa o valor mediano, mas não como obtê-lo formalmente. A construção dessa medida passa por organizar os dados de maneira crescente e calcular a posição central dos dados via \\(\\frac{n+1}{2}\\), em que \\(n\\) representa o tamanho do conjunto de dados relacionada a variável de interesse. O valor mediano é o valor na amostra ordenada que ocupa a posição \\(\\frac{n+1}{2}\\).\nQuando \\(n\\) é ímpar, a expressão \\(\\frac{n+1}{2}\\) vai sempre gerar um valor inteiro, facilitando a obtenção da mediana. Por exemplo, o subconjunto a seguir é formado por nove valores retirados da variável idade, sendo eles: 21, 28, 24, 22, 31, 26, 22, 38, 16.\nOrdenando esse subconjunto, obtemos 16, 21, 22, 22, 24, 26, 28, 31, 38.\nComo \\(n=9\\), a posição em que se encontra a mediana será \\(\\frac{9+1}{2}=5\\). Assim, a mediana será 24, pois é o valor que está na quinta posição do subconjunto ordenado.\nSe \\(n\\) é par, a expressão \\(\\frac{n+1}{2}\\) gerará um valor não inteiro que apresenta apenas uma única casa decimal após a vírgula igual a 5. Por exemplo, se a variável idade apresenta apenas 8 valores então \\(n = 8\\) e a posição em que a mediana está localizada é dada por \\(\\frac{n+1}{2} = \\frac{8+1}{2} = 4,5\\). Como inferir um valor para a mediana quando a posição que ela ocupa é decimal? Note que a posição \\(4,5\\) está exatamente no meio das posições 4 e 5, então o valor mediano será definido como a média entre os valores que ocupam as posições 4 e 5.\nO subconjunto abaixo também consiste de valores retirados da variável idade, porém note que nesse exemplo há 8 valores, ou seja, \\(n=8\\).\n\\[ 27, 16, 31, 43, 26, 42, 17, 40. \\]\nAo ordenarmos, temos:\n\\[ 16, 17, 26, 27, 31, 40, 42, 43. \\]\nA mediana será o valor que está na posição \\(\\frac{8+1}{2} = 4,5\\). Logo, visto que a mediana está entre os valores que ocupam a quarta e quinta posição, corresponde à média entre esses valores, sendo \\(\\frac{27+31}{2}=29\\).\nCom ideia correlata a mediana, podemos apresentar medidas de posição não centrais, as quais denominamos quantis ou percentis. O percentil 20, por exemplo, é o valor da variável em que 20% das observações no conjunto de dados apresentam valores menores ou iguais a ele. Por consequência, as restantes 80% das observações possuem valores acima do percentil 20. De maneira geral, podemos definir o percentil de ordem \\(p\\) como o valor da variável em que \\(100p\\%\\) \\((0 < p < 1)\\) das observações estão à sua esquerda, ou seja, são menores ou iguais que ele.\nAlguns percentis destacam-se por serem muito utilizados na análise de dados, não só numericamente como graficamente. Esses percentis são conhecido como quartis e basicamente dividem o conjunto de dados em 4 partes de mesmo tamanho. O primeiro quartil (\\(Q_1\\)) é o percentil 25, o segundo quartil (\\(Q_2\\)) é o percentil 50 e o terceiro quartil (\\(Q_3\\)) é o percentil 75. Vale notar que o segundo quartil é a mediana. De posse desses valores, como veremos mais a frente nesse capítulo, iremos construir o gráfico do tipo \\(boxplot\\), bastante utilizado na análise de dados da saúde.\nAinda com respeito aos percentis, outro termo comum na literatura é o decil que refere-se a divisão em 10 partes de mesmo tamanho do conjunto de dados associado a variável analisada. O primeiro decil, por exemplo, é o percentil 10 e o sexto decil é o percentil 60.\nTodas as medidas de posição aqui apresentadas tem em comum terem a mesma unidade de medida dos valores da variável observada, o que traz bastante interpretabilidade.\n\n\n4.1.2 Medidas de dispersão\nPor mais que as medidas de posição apresentadas sejam muito úteis na análise dados, elas por si só não se bastam como medidas resumo das observações de uma variável em um conjunto de dados. É possível construir diferentes conjuntos de dados para uma mesma variável que apresentam os mesmo valores de medida central (média, mediana e moda), mas tem comportamentos absolutamente diferentes. Por exemplo, veja a figura a seguir.\n\n\n\n\n\n\n\n(a) Dados: 2 ,3, 5 , 5, 7, 8.\n\n\n\n\n\n\n\n(b) Dados: 5,5,5,5.\n\n\n\n\nFigura 4.2: Exemplos de conjuntos de dados com mesma média, moda e mediana.\n\n\nOs dois conjuntos de dados apresentam os mesmos valores de média, mediana e moda. O que diferencia os dois conjuntos? O quão diferentes ou parecidos são as observações entre si em cada conjunto da variável. Na Figura Figura 4.2 (b), notamos que os quatro valores observados são iguais entre si e que, portanto, as observações nesse conjunto não variam, diferente do que ocorre para os dados que geraram o gráfico da Figura Figura 4.2 (a). Medidas de dispersão ou variabilidade são as medidas responsáveis por quantificar o quão diferente são os dados entre si. De forma bastante intuitiva temos que se os dados observados da variável não variam, então a medida de dispersão dela é zero e, caso haja diferenças entre os valores observados, então essa medida vai ser um valor positivo. Quanto maior a medida de variabilidade, mais diferente são os dados observados da variável entre si.\nNão existe uma única medida de dispersão na literatura, aqui vamos considerar as seguintes medidas: amplitude, intervalo interquartil, variância, desvio padrão e coeficiente de variação.\nDe fácil obtenção e interpretabilidade, a amplitude é a diferença entre o valor máximo e o valor mínimo da variável analisada no conjunto de dados e nos dá uma ideia do intervalo de variação dos dados. Uma desvantagem é que essa medida é absolutamente influenciada pela presença de valores discrepantes ou \\(outliers\\). O intervalo interquartil é uma medida mais robusta do que a amplitude intervalar e é calculada como a diferença entre o terceiro e o primeiro quartil, ou seja, é a amplitude entre os 50% dos dados centrais.\nPor mais informativas que sejam as medidas de amplitude e intervalo interquartil, queremos uma medida de dispersão que não considere apenas dois valores da amostra (mínimo e máximo ou primeiro e terceiro quartis) e sim todos os dados. Uma medida bastante intuitiva seria considerar a soma dos desvios de cada uma das observações em torno da média. Mas aí temos um problema: a soma dos desvios da média é sempre zero! Isso acontece porque sempre há desvios positivos e negativos que quando somados se anulam. Uma solução para essa questão é considerar alguma função que considere apenas o valor do desvio e não o seu sinal. Uma função candidata é a função quadrática (lembre que, por exemplo, \\((−2)^2=4\\)). Nessa construção surge a variância: soma dos desvios quadrados dividida pelo total de observações (\\(n\\)), ou seja, a média dos desvios quadrados. Assim, a variância quantifica o quanto os dados estão dispersos da média, em média.\nMatematicamente, considere \\(x_1\\), \\(x_2\\), …, \\(x_n\\) as observações de uma variável \\(X\\) e \\(\\bar{x}\\) a média observada dessa variável. A variância seria calculada como:\n\\[\n\\mbox{Var(X)} = \\frac{\\sum_{i = 1}^n (x_i - \\bar{x})^2}{n}.\n\\tag{4.1}\\]\nPor mais intuitiva que seja essa construção, programas como o R e similares utilizam em sua análise uma versão modificada do cálculo da variância acima apresentado, em que a soma dos desvios quadrados é dividida por \\(n-1\\), não por \\(n\\). Justificativas para isso se devem a propriedades inferenciais. A maioria dos conjuntos de dados considerados nos estudos referem-se a análise de amostras de uma população e não a análise de todos os elementos de uma população. Ao mesmo tempo, um dos principais objetivos da análise estatística é fazer análises para a população e não apenas para a amostra considerada no estudo. Basicamente, se temos interesse de conhecer o valor médio de uma variável na população (\\(\\mu\\)), na impossibilidade de analisar todos os elementos dela e obter a medida, o fazemos de forma aproximada investigando o valor médio dessa variável na amostra (\\(\\bar{x}\\)). Esse mesmo raciocínio ocorre para a variância, na impossibilidade de obter a variância da variável para todos os elementos da população (\\(\\sigma^2\\)), analisamos essa medida via amostra, o caso é que é possível mostrar que para amostras de tamanho pequeno, a variância apresentada em (Equação 4.1) não aproxima-se bem do valor de \\(\\sigma^2\\). Matematicamente, é possível mostrar que tal dificuldade é contornada fazendo uso do divisor igual a \\(n-1\\) em (Equação 4.1). Na literatura esse cálculo muitas vezes é denominado como variância amostral e representado pelo símbolo \\(S^2\\) de tal forma que\n\\[\nS^2 = \\frac{\\sum_{i = 1}^n (x_i - \\bar{x})^2}{n-1}.\n\\tag{4.2}\\]\nVale ressaltar também que a medida que se considera tamanhos de amostra maiores, calcular a variância com divisor \\(n\\) ou \\(n-1\\) torna-se indiferente.\nComo a unidade de medida da variância é o quadrado da unidade de medida da variável correspondente, convém definir outra medida de dispersão que mantenha a unidade de medida original. Uma medida com essa propriedade é a raiz quadrada da variância, conhecida por desvio padrão.\nCaso o interesse seja calcular e comparar a dispersão entre variáveis com unidades dimensionais de natureza diferente, por exemplo, comprimento (em metros) e massa (em kg), não convém utilizar as medidas de dispersão apresentadas anteriormente pois todas as medidas apresentadas carregam consigo a unidade de medida considerada para a variável. Nesse caso, podemos fazer uso do coeficiente de variação (CV) para cada uma das variáveis analisadas, já que o CV é uma medida de dispersão relativa adimensional, calculada via razão entre o desvio-padrão e a média observada para a variável e quanto maior o seu valor, maior a dispersão dos dados em termos relativos a média.\n\n\n4.1.3 Medidas de assimetria e curtose\nAlém das medidas de posição e variabilidade, existe um conjunto de medidas dedicadas a explorar a forma da distribuição de frequências dos dados. Especificamente aqui estudaremos algumas: coeficientes de assimetria e de curtose e variações destas.\nComo boa parte dos estudos na área de saúde é realizado através de amostras da variável de interesse na população, vamos precisar definir os momentos amostrais centrais que serão ferramenta fundamental para a construção dos coeficientes de assimetria, curtose e seus derivados. Por definição, o momento amostral centrado (na média) de ordem \\(r\\) é dado por\n\\[\nm_r = \\frac{\\sum_{i = 1}^n (x_i - \\bar{x})^r}{n}, \\; r = 1, 2, \\cdots.\n\\]\n\nA versão populacional do momento centrado de ordem \\(r\\) é expressa por \\(\\mu_r = \\frac{\\sum_{i = 1}^n (x_i - \\mu)^r}{N}\\), em que \\(r = 1, 2, \\cdots \\;\\) e \\(\\mu\\) e \\(N\\) referem-se, respectivamente, a média da variável de interesse e a quantidade de elementos investigados na população.\n\nDessa forma, o coeficiente de assimetria amostral é dado por \\(\\frac{m_3}{m_2^{3/2}}\\). Populações cuja a distribuição da variável é simétrica apresentam coeficiente de assimetria igual a zero. Distribuições assimétricas à direita apresentam valores positivos de coeficiente de assimetria para a variável analisada populacionalmente, assim como distribuições assimétricas à esquerda apresentam coeficiente de assimetria negativo.\n\nAnalogamente, \\(\\frac{\\mu_3}{\\mu_2^{3/2}}\\) é o coeficiente de correlação populacional.\nPopulações cuja a distribuição da variável é simétrica apresentam coeficiente de assimetria igual a zero. Distribuições assimétricas à direita apresentam valores positivos de coeficiente de assimetria para a variável analisada populacionalmente, assim como distribuições assimétricas à esquerda apresentam coeficiente de assimetria negativo.\n\n\n\n\n\n\n\n\n(a) Simétrico\n\n\n\n\n\n\n\n(b) Simétrico\n\n\n\n\n\n\n\n\n\n(c) Assimétrico à esquerda\n\n\n\n\n\n\n\n(d) Assimétrico à direita\n\n\n\n\nFigura 4.3: Histogramas e funções de densidade\n\n\nCoeficientes de assimetria amostrais diferentes de zero devem ser interpretados com cautela, uma vez que por se tratar de uma amostra não significa que necessariamente o comportamento da variável na população seja assimétrico. Testes estatísticos devem ser realizados para avaliar a hipotese de simetria da variável na população.\nAinda com respeito a forma da distribuição da variável, podemos avaliar o comportamento em suas caudas através do coeficiente de curtose amostral que se define por \\(\\frac{m_4}{m_2^{2}}\\). Distribuições de variáveis com valor de curtose igual a 3 são denominadas mesocúrticas. Tomada muitas vezes como referência, a distribuição normal apresenta coeficiente de curtose igual a três. Distribuições com coeficiente de curtose menores que 3 são denominadas platicúrticas e apresentam caudas mais leves (“finas”) do que a da distribuição normal. Distribuições com coeficiente de curtose maiores que 3 são denominadas leptocúrticas e apresentam caudas mais pesadas (“grossas”) do que a da distribuição normal. A distribuição t-Student é um exemplo de distribuição leptocúrtica.\nNa literatura é muito comum ser apresentado uma variante do coeficiente de curtose denominada excesso de curtose. Esse excesso é avaliado em relação a curtose do modelo normal por isso seu valor é calculado fazendo o coeficiente de curtose subtraído de 3. Dessa forma, o excesso de curtose em distribuições mesocúrticas é igual a zero, em distribuições leptocúrticas é maior que zero e em distribuições platicúrticas é menor que zero.\n\n\n\nFigura 4.4: Exemplo de funções de densidade com diferentes medidas de curtose.\n\n\nRessalva similar feita ao coeficiente de assimetria deve ser considerado para o coeficiente de curtose ou de excesso de curtose. Um coeficiente de curtose amostral diferente de três ou, de forma equivalente, com excesso de curtose amostral diferente de zero, não implica necessariamente que a distribuição da variável na população possui caudas mais leves ou mais pesadas do que a da distribuição normal. Para que se possa fazer tal afirmação é necessária a realização de testes estatísticos inferenciais. Os coeficientes amostrais de assimetria e curtose tão somente nos dão uma medida da forma da distribuição de frequências e \\(insights\\) do comportamento da variável na população, que devem ser verificados via análise inferencial estatística.\nNo R, para obter essas medidas resumo vamos utilizar a função descr também do pacote summarytools. No comando abaixo pedimos ao R as medidas descritivas da variável quantitativa “idade”.\n\n\n\n\ndescr(dados$idade)\n\nDescriptive Statistics  \ndados$idade  \nN: 11523  \n\n                       idade\n----------------- ----------\n             Mean      30.25\n          Std.Dev       7.04\n              Min      10.00\n               Q1      25.00\n           Median      30.00\n               Q3      35.00\n              Max      55.00\n              MAD       7.41\n              IQR      10.00\n               CV       0.23\n         Skewness       0.17\n      SE.Skewness       0.02\n         Kurtosis      -0.10\n          N.Valid   11514.00\n        Pct.Valid      99.92\n\n\nNote que os nomes de algumas das estatísticas apresentadas pela função descr estão em inglês. \\(Mean\\) refere-se ao valor médio da variável analisada, \\(Std.Dev\\) corresponde ao desvio-padrão, IQR é o símbolo para o intervalo interquartil, MAD é o desvio-médio absoluto, \\(Skewness\\) é o coeficiente de assimetria, \\(SE.Skewness\\) é o erro-padrão do coeficiente de assimetria, \\(Kurtosis\\) é o coeficiente de excesso de curtose e \\(N.Valid\\) e \\(Pct.Valid\\) correspondem, respectivamente, ao número de observações válidas e seu percentual no conjunto de dados considerado para a variável.\nEspecificamente para a variável idade, podemos notar que das 11523 observações, apenas 11514 (99.92 %) foram consideradas válidas. Isso acontece porque nesse conjunto de dados, 9 pessoas não declararam a idade, ficando com a casela vazia (NA). Todas as medidas-resumo foram calculadas considerando apenas as observações válidas. Sendo assim, algumas análises que podem ser realizadas para a variável idade através da função descr são que a idade média dentre as observações válidas foi de 30,25 anos, com desvio-padrão de 7,04 anos. A menor idade observada foi de 10 anos e a máxima foi de 55 anos. 50% das mulheres analisadas tem idade inferior a 30 anos (mediana) e 25% delas tem idade superior a 35 anos (Q3). O coeficiente de assimetria foi 0.17 (com erro-padrão de 0.02), indicando que a distribuição de frequências da variável idade é levemente assimétrica à direita. O coeficiente de excesso de curtose foi -0.10 e o intervalo interquartil (Q3 - Q1) foi 10.\nSe quiser que a tabela apresente apenas algumas medidas-resumo pré-selecionadas, podemos informar ao R por meio do argumento stats. Ainda, se quisermos que na tabela as medidas resumo fiquem na coluna, usamos o argumento transpose = TRUE, como segue:\n\ndescr(dados$idade,stats = c(\"min\", \"mean\", \"med\",\"sd\",\"max\"), transpose = TRUE) #sd é o desvio padrão (standard deviation)\n\nDescriptive Statistics  \ndados$idade  \nN: 11523  \n\n                Min    Mean   Median   Std.Dev     Max\n----------- ------- ------- -------- --------- -------\n      idade   10.00   30.25    30.00      7.04   55.00\n\n\nCaso se tenha interesse em apresentar a natureza da variável e um \\(preview\\) gráfico da distribuição de frequências, podemos fazer uso da função dfSummary. O argumento method = \"render\" para a função print permite uma melhor apresentação visual dos gráficos em documentos do tipo R \\(Markdown\\).\nprint(dfSummary(dados$idade), method = \"render\")\n\n\n\nData Frame Summary\ndados\nDimensions: 11523 x 1\n  Duplicates: 11476\n\n\n  \n    \n      No\n      Variable\n      Stats / Values\n      Freqs (% of Valid)\n      Graph\n      Valid\n      Missing\n    \n  \n  \n    \n      1\n      idade\n[numeric]\n      Mean (sd) : 30.2 (7)min ≤ med ≤ max:10 ≤ 30 ≤ 55IQR (CV) : 10 (0.2)\n      46 distinct values\n      \n      11514\n(99.9%)\n      9\n(0.1%)\n    \n  \n\nGenerated by summarytools 1.0.1 (R version 4.2.1)2023-01-21\n\n\nAlém do gráfico, uma informação adicional apresentada é que as 11514 observações válidas da variável idade estão distribuídas em 46 distintos valores.\nOutro pacote bastante interessante para medidas descritivas é o modelsummary. Destacamos algumas funções desse pacote:\n\ndatasummary_skim: retorna as medidas descritivas das variáveis do banco de dados a depender do tipo identificado no argumento type= (categorical ou numeric);\ndatasummary: retorna as medidas descritivas das variáveis a depender de como monta os argumentos da função, permitindo retornar as medidas descritivas das variáveis quantitativas de interesse por categorias de outra(s) variável(is).\n\n\n\n\nPara explorar a funcionalidade desse pacote e suas funções, vamos filtrar o banco de dados original considerando apenas as informações das mulheres gestantes e puérperas internadas em UTI.\n\ndados_uti <- dados[!is.na(dados$dias_uti),]\n\nVamos selecionar algumas variáveis do banco de dados dados_uti e organizá-las em um novo \\(data.frame\\).\nlibrary(dplyr)\ndados_uti_res <- select(dados_uti,idade,cardiopati, faixa_et, evolucao, dias_uti)\nPara esses dados, vamos fazer algumas análises via pacote modelsummary. Assim,\nlibrary(modelsummary)\nAo usar a função datasummary_skim, vamos obter as medidas descritivas das variáveis quantitativas (argumento type = \"numeric\") e das variáveis qualitativas (argumento type = \"categorical\"), respectivamente:\ndatasummary_skim(dados_uti_res,\n  type = \"numeric\",\n  histogram = FALSE)\n\n\n\n \n  \n      \n    Unique (#) \n    Missing (%) \n    Mean \n    SD \n    Min \n    Median \n    Max \n  \n \n\n  \n    idade \n    42 \n    0 \n    31.2 \n    6.6 \n    10.0 \n    31.0 \n    55.0 \n  \n  \n    dias_uti \n    75 \n    0 \n    12.0 \n    13.7 \n    0.0 \n    8.0 \n    200.0 \n  \n\n\n\n\ndatasummary_skim(dados_uti_res,\n  type = \"categorical\", na.rm = FALSE)\n\n\n\n \n  \n      \n       \n    N \n    % \n  \n \n\n  \n    cardiopati \n    sim \n    182 \n    7.8 \n  \n  \n     \n    nao \n    791 \n    34.0 \n  \n  \n     \n    ignorado \n    17 \n    0.7 \n  \n  \n    faixa_et \n    <20 \n    98 \n    4.2 \n  \n  \n     \n    >=34 \n    908 \n    39.1 \n  \n  \n     \n    20-34 \n    1317 \n    56.7 \n  \n  \n     \n    NA \n    1 \n    0.0 \n  \n  \n    evolucao \n    cura \n    1645 \n    70.8 \n  \n  \n     \n    obito \n    623 \n    26.8 \n  \n  \n     \n    obito por outras causas \n    7 \n    0.3 \n  \n  \n     \n    ignorado \n    31 \n    1.3 \n  \n\n\n\n\nComo a variável faixa etária (faixa_et) foi declarada como fator, a função datasummary_skim apresenta 1 valor NA, indicando que apenas uma mulher que esteve em UTI não teve determinada sua faixa etária/idade. Para que as demais variáveis categóricas apresentem essa informação e não as deixe omitida, como no caso da variável cardiopatia, vamos precisar declarar essas variáveis como caracter e não como fator. Esse procedimento também será adotado para as demais variáveis categóricas.\ndados_uti_res$cardiopati <- as.character(dados_uti_res$cardiopati)\ndados_uti_res$evolucao <- as.character(dados_uti_res$evolucao)\n\ndatasummary_skim(dados_uti_res,\n  type = \"categorical\", na.rm = FALSE)\n\n\n\n \n  \n      \n       \n    N \n    % \n  \n \n\n  \n    cardiopati \n    ignorado \n    17 \n    0.7 \n  \n  \n     \n    nao \n    791 \n    34.0 \n  \n  \n     \n    sim \n    182 \n    7.8 \n  \n  \n     \n    NA \n    1334 \n    57.4 \n  \n  \n    faixa_et \n    <20 \n    98 \n    4.2 \n  \n  \n     \n    >=34 \n    908 \n    39.1 \n  \n  \n     \n    20-34 \n    1317 \n    56.7 \n  \n  \n     \n    NA \n    1 \n    0.0 \n  \n  \n    evolucao \n    cura \n    1645 \n    70.8 \n  \n  \n     \n    ignorado \n    31 \n    1.3 \n  \n  \n     \n    obito \n    623 \n    26.8 \n  \n  \n     \n    obito por outras causas \n    7 \n    0.3 \n  \n  \n     \n    NA \n    18 \n    0.8 \n  \n\n\n\n\nUma das funções mais interessantes do pacote modelsummaryé a datasummary, pois ela nos permite analisar variáveis quantitativas separada pelas categorias (grupos) de uma variável qualitativa. Por exemplo, suponha que tenhamos interesse em analisar o tempo de internação em UTI, estratificado pelos grupos faixa-etária e evolução do caso, fazendo uso das seguintes medidas descritivas: média, mediana, desvio padrão, mínimo, máximo e tamanho da amostra válido (sem considerar observações faltantes para a variável em questão). O primeiro passo é declarar as medidas-resumo de interesse como funções. O argumento na.rm = TRUE indica que o cálculo da função deve ser realizado excluindo os valores faltantes da variável.\nmedia <- function(x)   mean(x, na.rm = TRUE)\nmediana <- function(x) median(x, na.rm = TRUE)\ndp <- function(x) sd(x, na.rm = TRUE)\nminimo <- function(x) min(x, na.rm = TRUE)\nmaximo <- function(x) max(x, na.rm = TRUE)\nn <- function(x) sum(!is.na(x))\ndatasummary( (evolucao + faixa_et) ~\n              dias_uti*(n+media+dp+minimo+mediana+maximo), data = dados_uti_res)\n\n\n\n \n  \n      \n       \n    n \n    media \n    dp \n    minimo \n    mediana \n    maximo \n  \n \n\n  \n    evolucao \n    cura \n    1645 \n    10.78 \n    12.01 \n    0.00 \n    6.00 \n    107.00 \n  \n  \n     \n    ignorado \n    31 \n    7.94 \n    10.19 \n    0.00 \n    4.00 \n    40.00 \n  \n  \n     \n    obito \n    623 \n    15.18 \n    15.46 \n    0.00 \n    12.00 \n    200.00 \n  \n  \n     \n    obito por outras causas \n    7 \n    51.71 \n    64.62 \n    2.00 \n    25.00 \n    183.00 \n  \n  \n    faixa_et \n    <20 \n    98 \n    10.55 \n    11.07 \n    0.00 \n    6.00 \n    58.00 \n  \n  \n     \n    >=34 \n    908 \n    12.91 \n    14.66 \n    0.00 \n    8.00 \n    200.00 \n  \n  \n     \n    20-34 \n    1317 \n    11.55 \n    13.15 \n    0.00 \n    8.00 \n    183.00 \n  \n\n\n\n\nAgora veja como fica se eu considerar as medidas descritivas de mais de uma variável quantitativas por duas variáveis qualitativas, selecionando apenas as medidas descritivas, média, desvio-padrão e número de casos observados:\ndatasummary((evolucao + cardiopati)  ~\n              (dias_uti + idade)*(n+media+dp), data = dados_uti_res)\n\n\n\n \n\n\ndias_uti\nidade\n\n  \n      \n       \n    n \n    media \n    dp \n    n \n    media \n    dp \n  \n \n\n  \n    evolucao \n    cura \n    1645 \n    10.78 \n    12.01 \n    1645 \n    31.05 \n    6.57 \n  \n  \n     \n    ignorado \n    31 \n    7.94 \n    10.19 \n    31 \n    31.29 \n    7.66 \n  \n  \n     \n    obito \n    623 \n    15.18 \n    15.46 \n    622 \n    31.61 \n    6.70 \n  \n  \n     \n    obito por outras causas \n    7 \n    51.71 \n    64.62 \n    7 \n    32.14 \n    7.65 \n  \n  \n    cardiopati \n    ignorado \n    17 \n    8.76 \n    9.62 \n    17 \n    34.00 \n    6.20 \n  \n  \n     \n    nao \n    791 \n    12.74 \n    13.30 \n    791 \n    30.96 \n    6.82 \n  \n  \n     \n    sim \n    182 \n    14.12 \n    14.28 \n    182 \n    33.66 \n    6.86"
  },
  {
    "objectID": "descritiva.html#tabelas-cruzadas---duas-variáveis-qualitativas",
    "href": "descritiva.html#tabelas-cruzadas---duas-variáveis-qualitativas",
    "title": "4  Análise exploratória dos dados",
    "section": "4.2 Tabelas cruzadas - duas variáveis qualitativas",
    "text": "4.2 Tabelas cruzadas - duas variáveis qualitativas\nTabelas cruzadas ou tabelas de contingência são tabelas que apresentam frequências de duas ou mais variáveis qualitativas conjuntamente.\nNo R, para obter tabelas cruzadas, vamos utilizar a função ´ctable´ também do pacote ´summarytools´. No comando abaixo, pedimos ao R uma tabela cruzada entre as variáveis qualitativas evolução (evolucao) e faixa etária (faixa_et) no banco de dados otiginal.\nctable(dados$evolucao,y=dados$obesidade,prop=\"t\")\nCross-Tabulation, Total Proportions\nevolucao * obesidade\nData Frame: dados\n\n\n\n\nobesidade\nsim\nnao\nignorado\n\nTotal\n\n\nevolucao\n\n\n\n\n\n\n\n\ncura\n\n555 (4.82%)\n2897 (25.1%)\n95 (0.82%)\n5943 (51.58%)\n9490 ( 82.4%)\n\n\nobito\n\n199 (1.73%)\n446 ( 3.9%)\n14 (0.12%)\n587 ( 5.09%)\n1246 ( 10.8%)\n\n\nobito por outras causas\n\n3 (0.03%)\n13 ( 0.1%)\n0 (0.00%)\n6 ( 0.05%)\n22 ( 0.2%)\n\n\nignorado\n\n10 (0.09%)\n71 ( 0.6%)\n0 (0.00%)\n206 ( 1.79%)\n287 ( 2.5%)\n\n\n\n\n23 (0.20%)\n129 ( 1.1%)\n4 (0.03%)\n322 ( 2.79%)\n478 ( 4.1%)\n\n\nTotal\n\n790 (6.86%)\n3556 (30.9%)\n113 (0.98%)\n7064 (61.30%)\n11523 (100.0%)\n\n\n\nO argumento prop indica a forma como deve ser calculada a proporção. Por padrão, a proporção é sempre calculada tendo-se como referencial o total em linha, ou seja, prop = \"r\". Outras opções são prop = \"t\", indicando que a proporção é em relação ao número total de observações e prop = \"c\" se o referencial for o total por coluna.\nctable(dados$evolucao,y=dados$obesidade,prop=\"r\")\nCross-Tabulation, Row Proportions\nevolucao * obesidade\nData Frame: dados\n\n\n\n\nobesidade\nsim\nnao\nignorado\n\nTotal\n\n\nevolucao\n\n\n\n\n\n\n\n\ncura\n\n555 ( 5.8%)\n2897 (30.5%)\n95 (1.0%)\n5943 (62.6%)\n9490 (100.0%)\n\n\nobito\n\n199 (16.0%)\n446 (35.8%)\n14 (1.1%)\n587 (47.1%)\n1246 (100.0%)\n\n\nobito por outras causas\n\n3 (13.6%)\n13 (59.1%)\n0 (0.0%)\n6 (27.3%)\n22 (100.0%)\n\n\nignorado\n\n10 ( 3.5%)\n71 (24.7%)\n0 (0.0%)\n206 (71.8%)\n287 (100.0%)\n\n\n\n\n23 ( 4.8%)\n129 (27.0%)\n4 (0.8%)\n322 (67.4%)\n478 (100.0%)\n\n\nTotal\n\n790 ( 6.9%)\n3556 (30.9%)\n113 (1.0%)\n7064 (61.3%)\n11523 (100.0%)\n\n\n\nctable(dados$evolucao,y=dados$obesidade,prop=\"c\")\nCross-Tabulation, Column Proportions\nevolucao * obesidade\nData Frame: dados\n\n\n\n\nobesidade\nsim\nnao\nignorado\n\nTotal\n\n\nevolucao\n\n\n\n\n\n\n\n\ncura\n\n555 ( 70.3%)\n2897 ( 81.5%)\n95 ( 84.1%)\n5943 ( 84.13%)\n9490 ( 82.4%)\n\n\nobito\n\n199 ( 25.2%)\n446 ( 12.5%)\n14 ( 12.4%)\n587 ( 8.31%)\n1246 ( 10.8%)\n\n\nobito por outras causas\n\n3 ( 0.4%)\n13 ( 0.4%)\n0 ( 0.0%)\n6 ( 0.08%)\n22 ( 0.2%)\n\n\nignorado\n\n10 ( 1.3%)\n71 ( 2.0%)\n0 ( 0.0%)\n206 ( 2.92%)\n287 ( 2.5%)\n\n\n\n\n23 ( 2.9%)\n129 ( 3.6%)\n4 ( 3.5%)\n322 ( 4.56%)\n478 ( 4.1%)\n\n\nTotal\n\n790 (100.0%)\n3556 (100.0%)\n113 (100.0%)\n7064 (100.00%)\n11523 (100.0%)\n\n\n\nNote que em todas as tabelas de contingência há a existência de linha e coluna sem nome, isso acontece pois esta linha e/ou coluna está resumindo os valores faltantes (NA). Por exemplo, a distribuição de frequências da variável evolução para os que não preencheram o \\(status\\) de obesidade nos diz que 5943 (84.13%) foram curados, 587 (8.31%) faleceram, 6 (0.08%) viram a óbito por motivos outros que não COVID-19, 206 (2.92%) ignoraram essa informação (preencheram com 9) e 322 (4.56%) deixaram em branco não só a informação da obesidade, mas também o desfecho final da evolução. Para obter a tabela de contingência apenas dos casos válidos simultâneos em ambas as variáveis, insira o argumento useNA = \"no\"\".\nctable(dados$evolucao,y=dados$obesidade, prop=\"c\", useNA = \"no\")\nCross-Tabulation, Column Proportions\nevolucao * obesidade\nData Frame: dados\n\n\n\n\nobesidade\nsim\nnao\nignorado\nTotal\n\n\nevolucao\n\n\n\n\n\n\n\ncura\n\n555 ( 72.4%)\n2897 ( 84.5%)\n95 ( 87.2%)\n3547 ( 82.4%)\n\n\nobito\n\n199 ( 25.9%)\n446 ( 13.0%)\n14 ( 12.8%)\n659 ( 15.3%)\n\n\nobito por outras causas\n\n3 ( 0.4%)\n13 ( 0.4%)\n0 ( 0.0%)\n16 ( 0.4%)\n\n\nignorado\n\n10 ( 1.3%)\n71 ( 2.1%)\n0 ( 0.0%)\n81 ( 1.9%)\n\n\nTotal\n\n767 (100.0%)\n3427 (100.0%)\n109 (100.0%)\n4303 (100.0%)\n\n\n\nCaso não haja interesse em se apresentar as proporções, basta considerar o argumento prop=\"none\", da seguinte forma:\nctable(dados$evolucao,y=dados$obesidade,prop=\"none\")\nCross-Tabulation\nevolucao * obesidade\nData Frame: dados\n\n\n\n\nobesidade\nsim\nnao\nignorado\n\nTotal\n\n\nevolucao\n\n\n\n\n\n\n\n\ncura\n\n555\n2897\n95\n5943\n9490\n\n\nobito\n\n199\n446\n14\n587\n1246\n\n\nobito por outras causas\n\n3\n13\n0\n6\n22\n\n\nignorado\n\n10\n71\n0\n206\n287\n\n\n\n\n23\n129\n4\n322\n478\n\n\nTotal\n\n790\n3556\n113\n7064\n11523\n\n\n\nPara tabelas de contingência com mais de duas variáveis, podemos adotar o seguinte procedimento:\nwith(dados, stby(data = list(x = evolucao, y = obesidade), \n                   INDICES = faixa_et, FUN = ctable))\nCross-Tabulation, Row Proportions\nevolucao * obesidade\nData Frame: dados\nGroup: faixa_et = <20\n\n\n\n\nobesidade\nsim\nnao\nignorado\n\nTotal\n\n\nevolucao\n\n\n\n\n\n\n\n\ncura\n\n12 (2.0%)\n214 (35.0%)\n2 (0.3%)\n383 (62.7%)\n611 (100.0%)\n\n\nobito\n\n3 (6.5%)\n22 (47.8%)\n0 (0.0%)\n21 (45.7%)\n46 (100.0%)\n\n\nobito por outras causas\n\n0 (0.0%)\n2 (66.7%)\n0 (0.0%)\n1 (33.3%)\n3 (100.0%)\n\n\nignorado\n\n0 (0.0%)\n7 (20.0%)\n0 (0.0%)\n28 (80.0%)\n35 (100.0%)\n\n\n\n\n0 (0.0%)\n2 (10.5%)\n0 (0.0%)\n17 (89.5%)\n19 (100.0%)\n\n\nTotal\n\n15 (2.1%)\n247 (34.6%)\n2 (0.3%)\n450 (63.0%)\n714 (100.0%)\n\n\n\nGroup: faixa_et = >=34\n\n\n\n\nobesidade\nsim\nnao\nignorado\n\nTotal\n\n\nevolucao\n\n\n\n\n\n\n\n\ncura\n\n231 ( 7.5%)\n972 (31.5%)\n37 (1.2%)\n1842 (59.8%)\n3082 (100.0%)\n\n\nobito\n\n73 (13.9%)\n182 (34.7%)\n6 (1.1%)\n263 (50.2%)\n524 (100.0%)\n\n\nobito por outras causas\n\n1 (12.5%)\n6 (75.0%)\n0 (0.0%)\n1 (12.5%)\n8 (100.0%)\n\n\nignorado\n\n1 ( 1.2%)\n22 (25.9%)\n0 (0.0%)\n62 (72.9%)\n85 (100.0%)\n\n\n\n\n12 ( 7.4%)\n44 (27.0%)\n0 (0.0%)\n107 (65.6%)\n163 (100.0%)\n\n\nTotal\n\n318 ( 8.2%)\n1226 (31.7%)\n43 (1.1%)\n2275 (58.9%)\n3862 (100.0%)\n\n\n\nGroup: faixa_et = 20-34\n\n\n\n\nobesidade\nsim\nnao\nignorado\n\nTotal\n\n\nevolucao\n\n\n\n\n\n\n\n\ncura\n\n310 ( 5.4%)\n1710 (29.5%)\n56 (1.0%)\n3715 (64.2%)\n5791 (100.0%)\n\n\nobito\n\n123 (18.2%)\n242 (35.9%)\n8 (1.2%)\n302 (44.7%)\n675 (100.0%)\n\n\nobito por outras causas\n\n2 (18.2%)\n5 (45.5%)\n0 (0.0%)\n4 (36.4%)\n11 (100.0%)\n\n\nignorado\n\n9 ( 5.4%)\n42 (25.1%)\n0 (0.0%)\n116 (69.5%)\n167 (100.0%)\n\n\n\n\n11 ( 3.7%)\n82 (27.9%)\n4 (1.4%)\n197 (67.0%)\n294 (100.0%)\n\n\nTotal\n\n455 ( 6.6%)\n2081 (30.0%)\n68 (1.0%)\n4334 (62.5%)\n6938 (100.0%)"
  },
  {
    "objectID": "descritiva.html#gráficos",
    "href": "descritiva.html#gráficos",
    "title": "4  Análise exploratória dos dados",
    "section": "4.3 Gráficos",
    "text": "4.3 Gráficos\nUm gráfico pode ser a maneira mais adequada para resumir e apresentar um conjunto de dados. Tem a vantagem de facilitar a compreensão de uma determinada situação que queira ser descrita, permitindo uma interpretação rápida e visual das suas principais características.\nA visualização dos dados é uma etapa importantíssima da análise estatística, pois é também a partir dela que criamos a intuição necessária para escolher o teste ou modelo mais adequado para o nosso problema.\n\n4.3.1 Pacote ggplot2\nUm pacote maravilhoso para gráficos no R é o ggplot2. A ideia por trás desse pacote é um gráfico pode ser entendido como um mapeamento dos dados a partir de atributos estéticos (cores, formas, tamanho) de formas geométricas (pontos, linhas, barras).\nlibrary(ggplot2)\n\n4.3.1.1 Atributos estéticos\nA função aes descreve como as variáveis são mapeadas em aspectos visuais. Para isso, vamos precisar indicar qual variável será representada no eixo x, qual será representada no eixo y, a cor e o tamanho dos componentes geométricos, etc. de formas geométricas a serem pré-definidas pelos geoms. A escolha da forma geométrica vai depender da natureza das variáveis a serem analisadas e será discutido na sequencia. Além disso, os aspectos que podem ou devem ser mapeados vão depender do tipo de gráfico que estamos querendo construir. Basicamente, no pacote ´ggplot2´ temos as seguintes formas geométricas:\n\ngeom_point() gera gráficos de dispersão transformando pares (x,y) em pontos.\ngeom_line: para retas definidas por pares (x,y);\ngeom_abline: para retas definidas por um intercepto e uma inclinação;\ngeom_hline: para retas horizontais;\ngeom_bar: para barras;\ngeom_histogram: para histogramas;\ngeom_boxplot: para boxplots;\ngeom_density: para densidades;\ngeom_area: para áreas.\n\nPara cada uma das formas geométricas podemos estabelecer aspectos visuais que podem melhorar a visualização dos dados. Aspectos visuais mais utilizados:\n\ncolor: altera a cor de formas que não têm área (pontos e retas);\nfill: altera a cor de formas com área (barras, caixas, densidades, áreas);\nsize: altera o tamanho de formas;\ntype: altera o tipo da forma, geralmente usada para pontos;\nlinetype: altera o tipo da linha.\n\nPara exemplificar os diferentes tipos de gráficos associando-os a variáveis de diferentes naturezas, vamos considerar o banco de dados de COVID-19 em gestantes e puérperas. De maneira geral, é necessário seguir alguns passos gerais para a construção de qualquer gráfico via ggplot2, a saber:\n\nPasso 1: sempre iniciar a construção chamando a função ggplot.\nPasso 2: especificar na função ggplot o objeto que acomoda o banco de dados e apresenta a variável de interesse para a qual se quer fazer o gráfico. Esse objeto deve ser do tipo \\(dataframe\\).\nPasso 3: informar as variáveis a serem consideradas no eixo horizontal e vertical via função aes e demais funções estéticas dependentes das variáveis.\n\nPasso 4: informar o tipo de gráfico que se quer fazer (barra, histograma, \\(boxplot\\), etc).\n\n\n\n4.3.1.2 Gráficos para variáveis qualitativas e quantitativas discretas com poucos valores diferentes\nUm dos gráficos mais utilizados para a apresentação visual de variáveis qualitativas e quantitativas discretas com poucas observações diferentes é o gráfico de barras. Para construí-lo, é necessário utilizar no Passo 4 a função geom_bar.\nA seguir apresentamos um exemplo de gráfico de barras para a variável qualitativa evolução dos casos relacionado a gestantes e puérperas hospitalizadas por COVID-19.\nggplot(dados, aes(x = evolucao)) +\n  geom_bar(fill = \"blue\") +\n  labs(x = \"Tipos de evolução\", y = \"Número de casos\")\n\n\n\nNote que a função labs é responsável não só por inserir os títulos nos eixos, como poder visto no gráfico anterior, mas também títulos e subtítulos. Essa função pode ser sempre utilizada na construção de gráficos via pacote ggplot2, independente do tipo de gráfico a ser apresentado. Por exemplo,\nggplot(dados, aes(x = evolucao)) +\n  geom_bar(fill = \"blue\") +\n  labs(x = \"Tipos de evolução\", y = \"Número de casos\", title = \"Evolução dos casos hospitalizados por COVID-19\", subtitle = \"Mulheres gestantes e puérperas\")\n\n\n\nNo código a seguir apresentamos como apresentar as barras organizadas de maneira decrescente. Note que há uma mudança na ordem das barras referente a óbitos e óbitos por outras causas. Além disso, independente da disposição escolhida para as barras, a categoria que representa as mulheres que não tiveram sua evolução preenchida na notificação (NA) sempre é apresentada como última barra, ainda que tenha uma alta frequência em relação as outras categorias.\nggplot(dados, aes(x = reorder(evolucao, evolucao, function(x)-length(x)))) +\n  geom_bar(fill = \"blue\") +\n  labs(x = \"Tipos de evolução\", y = \"Número de casos\", title = \"Evolução dos casos hospitalizados por COVID-19\", subtitle = \"Mulheres gestantes e puérperas\")\n\n\n\nCaso o interesse seja nas barras dispostas de maneira crescente, com exceção do NA, basta reordenar a variável da seguinte forma:\nggplot(dados, aes(x = reorder(evolucao, evolucao, function(x) length(x)))) +\n  geom_bar(fill = \"blue\") +\n  labs(x = \"Tipos de evolução\", y = \"Número de casos\", title = \"Evolução dos casos hospitalizados por COVID-19\", subtitle = \"Mulheres gestantes e puérperas\")\n\n\n\nA variável evolução (evolucao) pode ser classificada como qualitativa nominal e, portanto, estamos livres para escolher a ordem com que as categorias são apresentadas. Vamos ver agora o caso da variável faixa-etária (faixa_et) que, intrinsecamente, é uma variável qualitativa ordinal. Se utilizássemos o mesmo código considerado inicialmente para a variável evolução, obteríamos o seguinte gráfico:\nggplot(dados, aes(x = faixa_et)) +\n  geom_bar(fill = \"purple\") +\n  labs(x = \"Faixa etária\", y = \"Número de casos\", title = \"Faixa etária das hospitalizadas por COVID-19\", subtitle = \"Mulheres gestantes e puérperas\")\n\n\n\nNote que a barra para as mulheres com pelo menos 34 anos e a barra que representa as mulheres com idade de 20 (incluso) a 34 anos estão em posições trocadas, não respeitando a ordenação natural da variável.\n# Especificando a ordem dos níveis do fator \ndados$faixa_et = factor(dados$faixa_et, levels = c('<20', '20-34', '>=34'))\n\n# Gerando o gráfico\nggplot(dados, aes(x = faixa_et)) +\n  geom_bar(fill = \"purple\") +\n  labs(x = \"Faixa etária\", y = \"Número de casos\", title = \"Faixa etária das hospitalizadas por COVID-19\", subtitle = \"Mulheres gestantes e puérperas\")\n\n\n\nTodos os gráficos de barra apresentados anteriormente apresentaram no eixo vertical a contagem de indivíduos por categoria. vejamos agora o código para apresentar o gráfico de barras com as frequências relativas.\nggplot(dados, aes(x = faixa_et, y = (..count..)/sum(..count..))) +  \n  geom_bar(fill=\"purple\") + \n  labs(x = \"Faixa etária\", y = \"Frequência relativa\", title = \"Faixa etária das hospitalizadas por COVID-19\", subtitle = \"Mulheres gestantes e puérperas\")\n\n\n\nSe o interesse é apresentar o gráfico em termos percentuais, basta acrescentar a função scale_y_continuous com o argumento labels=scales::percent.\nggplot(dados, aes(x = faixa_et, y = (..count..)/sum(..count..))) +  \n  geom_bar(fill=\"purple\") + \n  scale_y_continuous(labels=scales::percent) +\n  labs(x = \"Faixa etária\", y = \"Porcentagem\", title = \"Faixa etária das hospitalizadas por COVID-19\", subtitle = \"Mulheres gestantes e puérperas\")\n\n\n\nPara inserir o percentual de cada categoria no gráfico, incluímos no código anterior a função geom_text, com o argumento lab declarando o cálculo da frequência arredondado a duas casas decimais. O argumento vjust indica a que altura se quer que o texto com o percentual apareça no gráfico. Quanto mais negativo for o valor, mais acima da barra estará o texto com o percentual. Se vjust = 0 apresenta o texto encima da barra e, quanto mais positivo for o valor de vjust escolhido, mais interno da barra ficará o texto.\nggplot(dados, aes(x = faixa_et, y = (..count..)/sum(..count..))) +  \n  geom_bar(fill=\"purple\") + \n  geom_text(aes(label = round((((..count..)/sum(..count..))*100), 2)), stat= \"count\", vjust = -0.1)+\n  scale_y_continuous(labels=scales::percent) +\n  labs(x = \"Faixa etária\", y = \"Porcentagem\", title = \"Faixa etária das hospitalizadas por COVID-19\", subtitle = \"Mulheres gestantes e puérperas\")\n\n\n\nO argumento width da função geom_bar permite controlar a espessura da barra através de valores variando de 0 a 1, sendo que o tamanho 1 representa o maior tamanho.\nggplot(dados, aes(x = faixa_et, y = (..count..)/sum(..count..))) +  \n  geom_bar(fill=\"purple\", width=0.2) + \n  geom_text(aes(label = round((((..count..)/sum(..count..))*100), 2)), stat= \"count\", vjust = -0.1)+\n  scale_y_continuous(labels=scales::percent) +\n  labs(x = \"Faixa etária\", y = \"Porcentagem\", title = \"Faixa etária das hospitalizadas por COVID-19\", subtitle = \"Mulheres gestantes e puérperas\")\n\n\n\nPara mudar a disposição das barras de vertical para horizontal, basta acrescentar basta inserir a função coord_flip(). Para diminuir o tamanho da letra, ajustamos na função geom_text alterando os valores do argumento size.\nggplot(dados, aes(x = faixa_et, y = (..count..)/sum(..count..))) +  \n  geom_bar(fill=\"purple\") + \n  geom_text(aes(label = round((((..count..)/sum(..count..))*100), 2)), stat= \"count\", hjust = 0, size  = 3) +\n  scale_y_continuous(labels=scales::percent) +\n  labs(x = \"Faixa etária\", y = \"Porcentagem\", title = \"Faixa etária das hospitalizadas por COVID-19\", subtitle = \"Mulheres gestantes e puérperas\")+\n  coord_flip()\n\n\n\nVejamos agora como construir um gráfico de barras com duas variáveis qualitativas conjuntamente. Para exemplificar, vamos considerar as variáveis faixa etária (faixa_et) e cardiopatia (cardiopat). Nosso interesse é analisar a distribuição da faixa-etária estratificada pelas categorias da variável cardiopatia que, como vimos antes, podem assumir os resultados “sim”, “não”, “ignorado” e “NA”.\nggplot(dados, aes(x = faixa_et, group = cardiopati)) +  \n  geom_bar(aes(y = ..prop..), stat = \"count\", fill=\"green4\") + \n  labs(x = \"Faixa etária\", y = \"Porcentagem\", title = \"Faixa etária das hospitalizadas por COVID-19 pela presença de cardiopatia\", subtitle = \"Mulheres gestantes e puérperas\")+\n  scale_y_continuous(labels=scales::percent) +\n  facet_grid(~cardiopati)\n\n\n\nO próximo código apresenta o gráfico anterior com as porcentagens inseridas na figura.\nggplot(dados, aes(x = faixa_et, group = cardiopati)) +  \n  geom_bar(aes(y = ..prop..), stat = \"count\", fill=\"green4\") + \n  geom_text(aes(label = scales::percent(..prop.., accuracy = 0.1), y= ..prop..), stat = \"count\", vjust = -.1) +\n  labs(x = \"Faixa etária\", y = \"Porcentagem\", title = \"Faixa etária das hospitalizadas por COVID-19 pela presença de cardiopatia\", subtitle = \"Mulheres gestantes e puérperas\")+\n  scale_y_continuous(labels=scales::percent) +\n  facet_grid(~cardiopati)\n\n\n\nVamos agora colocar cada categoria com a sua própria cor, a fim de facilitar a comparação. Para isso, vamos considerar o argumento fill = factor(..x..) na função geom_bar. Como as categorias da variável faixa-etária são autoexplicativas, o termo theme(legend.position=\"none\") for inserido na construção do gráfico para se evitar a criação de uma nova legenda para as cores relacionadas as faixas de idade, evitando assim repetição de informação.\nggplot(dados, aes(x=faixa_et, group = cardiopati))  + \n  geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat=\"count\") +\n  geom_text(aes(label = scales::percent(..prop.., accuracy = 0.1), y= ..prop..), stat= \"count\", vjust = -.1) +\n  labs(x = \"Faixa etária\", y = \"Porcentagem\", title = \"Faixa etária das hospitalizadas por COVID-19 pela presença de cardiopatia\", subtitle = \"Mulheres gestantes e puérperas\")+\n  theme(legend.position=\"none\")+\n  scale_y_continuous(labels=scales::percent) +\n  facet_grid(~cardiopati)\n\n\n\nA escala de cores utilizada por padrão pela função geom_bar nem sempre atende a todos os públicos. O pacote viridis do R apresenta escalas de cores projetadas para melhorar a legibilidade dos gráficos para leitores com formas comuns de daltonismo e/ou deficiência em visão de cores. Para usá-lo, devemos inserir a função scale_fill_manual(values = c(viridis(4))), com o valor 4 representando as 4 categorias da faixa etária.\nlibrary(viridis)\n\nggplot(dados, aes(x=faixa_et, group = cardiopati))  + \n  geom_bar(aes(y = ..prop.., fill = factor(..x..)), stat=\"count\") +\n  geom_text(aes(label = scales::percent(..prop.., accuracy = 0.1), y= ..prop..), stat= \"count\", vjust = -.1) +\n  labs(x = \"Faixa etária\", y = \"Porcentagem\", title = \"Faixa etária das hospitalizadas por COVID-19 pela presença de cardiopatia\", subtitle = \"Mulheres gestantes e puérperas\")+\n  theme(legend.position=\"none\")+\n  scale_y_continuous(labels=scales::percent) +\n  scale_fill_manual(values = c(viridis(4))) +\n  facet_grid(~cardiopati)\n\n\n\nVários dos gráficos aqui mencionados podem construídos fazendo usos de outras funções e código do pacote do ggplot2. Especificamente sobre o gráfico de barras, na página (http://www.sthda.com/english/wiki/ggplot2-barplots-quick-start-guide-r-software-and-data-visualization#barplot-of-counts) podemos encontrar outras interessantes customizações gráficas que podem ser implementadas via pacote ggplot2.\n\n\n4.3.1.3 Gráficos para variáveis quantitativas\nTodos os códigos apresentados anteriormente podem ser usados quando a variável de interesse é quantitativa discreta com poucos valores diferentes. No caso de haver muitos diferentes valores para a variável quantitativa discreta, gráficos do tipo histograma costumam ser mais informativos. Vamos apresentar agora ferramentas para a construção de gráficos para esse tipo de variável e para variáveis quantitativas contínuas. Todos os gráficos a serem construídos daqui para frente farão uso da paleta viridis. Vejamos a construção do histograma de densidades para a variável idade.\nA função considerada agora é geom_histogram. O argumento y = ..density.. indica que queremos apresentar o histograma de densidades, bins = 15 refere-se ao número de barras contíguas que queremos que o gráfico apresente, ´fill´ designa a cor a preencher o gráfico e color é a cor da linha das barras.\nggplot(dados, aes(x=idade))  + \n  geom_histogram(aes(y = ..density..), bins = 15, fill = viridis(1), color = \"black\") +\n  labs(x = \"Idade\", y = \"Densidade\", title = \"Histograma de densidades das idades de hospitalizadas por COVID-19\", subtitle = \"Mulheres gestantes e puérperas\")\n\n\n\nEnquanto medida, densidade corresponde a razão entre o número de casos contabilizados em intervalo e a amplitude do intervalo. Uma das vantagens em considerar o histograma de densidades e não o histograma de frequências é que a área total sob o gráfico corresponde a 1, deixando o gráfico na mesma escala de funções de densidade. Por exemplo, na figura a seguir inserimos uma versão alisada empírica do histograma. O argumento alpha na função geom_density controla o nível de transparência das cores preenchidas no histograma alisado e varia de 0 a 1, com 1 representando a cor sólida.\nggplot(dados, aes(x=idade))  + \n  geom_histogram(aes(y = ..density..), bins = 15, fill = viridis(1), color = \"black\") +\n  geom_density(fill = \"grey55\", color = \"grey80\", alpha = 0.2) +\n  labs(x = \"Idade\", y = \"Densidade\", title = \"Histograma de densidades das idades de hospitalizadas por COVID-19 \", subtitle = \"Mulheres gestantes e puérperas\")\n\n\n\nNo código a seguir apresentamos uma maneira de construir o histograma de densidades de uma variável quantitativa nas diferentes categorias de uma variável qualitativa. Aqui a variável qualitativa refere-se a informações sobre o \\(status\\) de cardiopatia e a variável quantitativa considerada foi a idade. Para facilitar a comparação das diferentes faixas de valores da variável quantitativa entre as categorias, vamos inserir uma escala inserir uma escala de cores entre as faixas de valores, deixando o gráfico com um aspecto bastante atrativo e informativo. O argumento considerado na função geom_density é fill = ..x.., informando que o preenchimento do histograma será realizado nas faixas de valores da variável quantitativa. Para a escala de cores, inserimos a função scale_fill_gradientn(colours = c(viridis(15))), em que o valor 15 corresponde ao número de barras contíguas (bins = 15) considerado no histograma.\nggplot(dados, aes(x=idade))  + \n  geom_histogram(aes(y = ..density.., fill=..x..), bins = 15, color = \"black\") +\n  geom_density(fill = \"grey55\", color = \"grey80\", alpha = 0.2) +\n  labs(x = \"Idade\", y = \"Densidade\", title = \"Histogramas de densidades das idades fixado status de cardiopatia \", subtitle = \"Gestantes e puérperas hospitalizadas por COVID-19\")+\n  scale_fill_gradientn(colours = c(viridis(15)))+\n  theme(legend.position=\"none\")+\n  facet_grid(~cardiopati)\n\n\n\nPara que os histogramas sejam dispostos um abaixo do outro, basta substituir a função facet_grid(~cardiopati) por facet_wrap(~cardiopati, ncol=1).\nggplot(dados, aes(x=idade))  + \n  geom_histogram(aes(y = ..density.., fill=..x..), bins = 15, color = \"black\") +\n  geom_density(fill = \"grey55\", color = \"grey80\", alpha = 0.2) +\n  labs(x = \"Idade\", y = \"Densidade\", title = \"Histogramas de densidades das idades fixado status de cardiopatia \", subtitle = \"Gestantes e puérperas hospitalizadas por COVID-19\")+\n  scale_fill_gradientn(colours = c(viridis(15)))+\n  theme(legend.position=\"none\")+\n  facet_wrap(~cardiopati, ncol=1)\n\n\n\nCaso se queira apresentar os histogramas alisados sobrepostos por categoria, pode-se usar o código proposto na sequência.\nggplot(dados, aes(x = idade, fill = cardiopati)) +\n  geom_density(alpha = 0.5) +\n  labs(x = \"Idade\", y = \"Densidade\", title = \"Histogramas alisados das idades pelo status de cardiopatia\", subtitle = \"Gestantes e puérperas hospitalizadas por COVID-19\") +\n  scale_fill_manual(values = c(viridis(3)), name = \"Cardiopatia\")\n\n\n\nUm outro gráfico muito utilizado na apresentação de uma variável quantitativa é o boxplot que apresenta, visualmente, os valores mínimo, primeiro quartil (Q1), mediana ou segundo quartil (Q2), terceiro quartil (Q3), máximo e possíveis \\(outliers\\). Baseado nessas medidas, temos uma ideia do comportamento da variável quantitativa em termos de posição, dispersão, assimetria e dados discrepantes. A posição central é dada pela mediana e a dispersão pelo intervalo interquartil. As posições relativas entre Q1, Q2 e Q3 nos dão uma ideia da simetria ou assimetria da distribuição.\n\n\n\n\n\nOs valores \\(Q_1\\), \\(Q_2\\) e \\(Q_3\\) já foram apresentados anteriormente. No gráfico, o segundo quartil (ou seja, a mediana) é representada pela linha que corta a caixa do boxplot. Já o primeiro quartil (\\(Q_1\\)) é a base da caixa e o terceiro quartil (\\(Q_3\\)), o topo. O intervalo interquartil está representado na altura da caixa. A escolha do tamanho da base da caixa é arbitrária, devendo-se tão somente garantir que as linhas \\(Q_1\\), \\(Q_2\\) e \\(Q3\\) estão localizadas na altura em que os valores dos quartis foram obtidos.\nAs linhas em azul são linhas imaginárias (normalmente não aparecem graficadas nos gráficos) e representam valores que distinguem valores \\(outliers\\) dos demais. Valores \\(outliers\\) são valores considerados discrepantes dentro do conjunto de dados de uma variável. Para a representação no boxplot, são considerados \\(outliers\\), observações com valores maiores que o Limite Superior (LS) ou com valores menores que o Limite Inferior (LI), tal que \\(LI = Q_1 - 1.5 (Q_3 - Q_1)\\) e \\(LS = Q_3 + 1.5 (Q_3 - Q_1)\\). Ainda na figura, observamos a presença de um \\(\\mbox{Mínimo}^*\\) e \\(\\mbox{Máximo}^*\\) que nem sempre representam o menor e a maior, respectivamente, observações na amostra. Por definição, \\(\\mbox{Mínimo}^*\\) é o menor valor maior que o Limite Inferior (LI), ou seja, é o menor valor observado no conjunto de dados desconsiderado os valores \\(outliers\\). Analogamente, \\(\\mbox{Máximo}^*\\) é o maior valor menor que o Limite Superior (LS), ou seja, é o maior valor observado no conjunto de dados desconsiderado os valores \\(outliers\\).\nNo pacote ggplot2, esse gráfico é construído com a função geom_boxplot que apresenta argumentos similares aos gráficos de barras e histograma.\nggplot(dados, aes(y=idade))  + \n  geom_boxplot(fill = viridis(1), color = \"black\") +\n  labs(x = \"\", y = \"Idade\", title = \"Boxplot das idades de hospitalizadas por COVID-19 \", subtitle = \"Mulheres gestantes e puérperas\")\n\n\n\nO boxplot, assim como o histograma, também pode ser utilizado para apresentar o comportamento de variáveis quantitativas em função das categorias de variáveis qualitativas.\nggplot(dados, aes(y=idade, x = cardiopati))  + \n  geom_boxplot(fill = viridis(1), color = \"black\") +\n  labs(x = \"\", y = \"Idade\", title = \"Boxplot das idades fixado status de cardiopatia\", subtitle = \"Gestantes e puérperas hospitalizadas por COVID-19\")\n\n\n\nPara que cada categoria apresente sua própria cor, basta declarar qual a variável que será considerada para colorir os boxplots em suas categorias via argumento fill em ggplot e indicar quais as cores serão utilizadas. Como a variável cardiopatia (cardiopati) tem 4 categorias, informamos as cores na função geom_boxplot usando o termo fill = viridis(4). Além disso, caso se tenha interesse em destacar as observações \\(outliers\\) com outras cores, pode ser usado o argumento outlier.color na função geom_boxplot. Por exemplo, na figura abaixo, vamos destacar os \\(outliers\\) em vermelho.\nggplot(dados, aes(y=idade, x = cardiopati, fill = cardiopati))  + \n  geom_boxplot(fill = viridis(4), color = \"black\", outlier.color = \"red\") +\n  labs(x = \"\", y = \"Idade\", title = \"Boxplot das idades fixado status de cardiopatia\", subtitle = \"Gestantes e puérperas hospitalizadas por COVID-19\")\n\n\n\nNo código a seguir, vamos apresentar o boxplot da variável quantitativa idade pela variável qualitativa \\(status\\) de cardiopatia, estratificado nas diferentes categorias de evolução do caso. Para clareza do texto no gráfico, a legenda da variável cardiopatia foi colocada abaixo dele, assim como o texto no eixo horizontal foi disposto de forma inclinada, através da função theme(legend.position=\"bottom\", axis.text.x=element_text(angle=30, hjust=0.8)).\nggplot(dados, aes(y=idade, x = cardiopati, fill = cardiopati))  + \n  geom_boxplot(color = \"black\") +\n  labs(x = \"\", y = \"Idade\", title = \"Boxplot das idades pelo status de cardiopatia, fixada a evolução\", subtitle = \"Gestantes e puérperas hospitalizadas por COVID-19\")+\n  theme(legend.position=\"bottom\", axis.text.x=element_text(angle=30, hjust=0.8)) +\n  scale_fill_manual(values = c(viridis(4)), name = \"Cardiopatia\")+\n  facet_grid(~evolucao)\n\n\n\nNosso objetivo agora é explorar a construção de gráficos quando temos duas variáveis quantitativas através do diagrama de dispersão. Para exemplificar a construção, vamos considerar as variáveis do banco de dados dados_uti_res que contém as variáveis idade e quantidade de dias em uti (dias_uti).\nggplot(dados_uti_res, aes(x=idade, y = dias_uti))  + \n  geom_point(colour = viridis(1)) +\n  labs(x = \"Idade\", y = \"Dias em UTI \", title = \"Gráfico de dispersão da idade pelo tempo em UTI\", subtitle = \"Gestantes e puérperas hospitalizadas por COVID-19\")\n\n\n\nO pacote ggExtra consegue inserir no gráfico de dispersão gerado pelo ggplot2 histogramas, histogramas alisados e boxplot das variáveis marginais. Para isso, basta utilizar a função ggMarginal informando o nome do objeto em que está guardado o gráfico de dispersão e o tipo de gráfico marginal a ser inserido.\np <- ggplot(dados_uti_res, aes(x=idade, y = dias_uti))  + \n  geom_point(colour = viridis(1)) +\n  labs(x = \"Idade\", y = \"Dias em UTI \", title = \"Gráfico de dispersão da idade pelo tempo em UTI\", subtitle = \"Gestantes e puérperas hospitalizadas por COVID-19\")\n\nlibrary(ggExtra)\n\n# histograma marginal\nggMarginal(p, type=\"histogram\")\n\n\n\n# histograma alisado marginal\nggMarginal(p, type=\"density\")\n\n\n\n# Boxplot marginal\nggMarginal(p, type=\"boxplot\")\n\n\n\nPodemos construir gráficos de dispersão estratificados por categorias de uma variável qualitativa. No código abaixo, vamos utilizar o \\(status\\) de cardiopatia e, para isso, usamos o argumento color = cardiopati na função geom_point.\nggplot(dados_uti_res, aes(x=idade, y = dias_uti))  + \n  geom_point(aes(color = cardiopati)) +\n  scale_colour_viridis_d(\"Cardiopatia\", na.value = \"grey50\")+\n  labs(x = \"Idade\", y = \"Dias em UTI \", title = \"Gráfico de dispersão da idade pelo tempo em UTI, fixado status de cardiopatia\", subtitle = \"Gestantes e puérperas hospitalizadas por COVID-19\")\n\n\n\nComo pontos de diferentes cores estão sobrepondo, uma visualização possível para facilitar a análise pode ser feita separando os diagramas de dispersão em diferentes planos cartesianos de mesma escala.\nggplot(dados_uti_res, aes(x=idade, y = dias_uti))  + \n  geom_point(aes(color = cardiopati)) +\n  scale_colour_viridis_d(\"Cardiopatia\", na.value = \"grey50\")+\n  labs(x = \"Idade\", y = \"Dias em UTI \", title = \"Gráfico de dispersão da idade pelo tempo em UTI, fixado status de cardiopatia\", subtitle = \"Gestantes e puérperas hospitalizadas por COVID-19\")+\n  facet_wrap(~cardiopati, ncol=1)\n\n\n\n\n\n\n4.3.2 Pacote esquisse\nO pacote esquisse disponibiliza um \\(dashboard\\) interativo para criação de gráficos por meio do pacote ggplot2.\nlibrary(esquisse)\nAo rodar a função esquisser(), um janela é aberta (veja Figura 4.5), em que usuário deve escolher a base de dados a trabalhar. Feito isso, uma outra janela será aberta apresentando todas as variáveis presentes no banco de dados escolhido (veja Figura 4.6), permitindo assim fazer os gráficos. Preparamos um tutorial para a utilização do pacote esquisse que pode ser acessado aqui (https://www.youtube.com/watch?XXXXXXXXXXXXX) .\n\n\n\nFigura 4.5: Primeira tela do esquisser.\n\n\n\n\n\nFigura 4.6: Segunda tela do esquisser.\n\n\n\n\n4.3.3 Materiais complementares\nLivros e Artigos:\n\nMercier F, Consalvo N, Frey N, Phipps A, Ribba B. From waterfall plots to spaghetti plots in early oncology clinical development. Pharm Stat. 2019;18(5):526-532. doi:10.1002/pst.1944\nGillespie TW. Understanding waterfall plots. J Adv Pract Oncol. 2012;3(2):106-111.\nSonnad SS. Describing data: statistical and graphical methods. Radiology. 2002;225(3):622-628. doi:10.1148/radiol.2253012154\nIn J, Lee S. Statistical data presentation. Korean J Anesthesiol. 2017;70(3):267-276. doi:10.4097/kjae.2017.70.3.267\nMorettin P, Singer J. Estatística e Ciência de Dados. 1nd ed. LTC; 2022.\n\n\\(Sites\\):\n\nhttps://r-graph-gallery.com/index.html\n\nhttp://www.sthda.com/english/wiki/data-visualization\nhttps://www.cedricscherer.com/2019/08/05/a-ggplot2-tutorial-for-beautiful-plotting-in-r/"
  }
]